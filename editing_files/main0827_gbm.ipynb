{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge shap\n",
    "# pip install xgboost\n",
    "# pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>병원 개/폐업 분류예측 프로젝트</h1></center><br>\n",
    "\n",
    "---\n",
    "<h4>1. 주제 및 목표</h4>\n",
    "- 병원 폐업 여부를 예측하여 대출 승인여부 결정\n",
    "\n",
    "<h4>2. 배경</h4>\n",
    "- 한국 핀테크 기업 모우다(MOUDA): 상환기간 동안의 계속 경영 여부를 예측하여 병원들에게 금융 기회를 제공\n",
    "- 일반적으로 병원 대출 시 신용점수 또는 담보물을 위주로 평가를 진행했던 기존 금융기관과의 차별점\n",
    "- 신용 점수가 낮거나 담보를 가지지 못하는 우수 병원들에게도 금융 기회를 제공하자는 취지\n",
    "\n",
    "<h4>3. 활용 데이터</h4>\n",
    "- 의료기관의 폐업 여부가 포함된 최근 2개년의 재무정보와 병원 기본정보 \n",
    "- (출처) Dacon 병원 개/폐업 분류 예측 경진대회 (https://dacon.io/competitions/official/9565/data/)\n",
    "- 데이터 설명\n",
    "> - <병원 기본정보>\n",
    "> - inst_id: 병원 고유 번호<br>\n",
    "> - OC: 영업/폐업 분류<br>\n",
    "> - sido: 병원의 광역 지역 정보<br>\n",
    "> - sgg: 병원의 시군구 자료<br>\n",
    "> - openDate: 병원 설립일<br> \n",
    "> - bedcount: 병원이 갖추고 있는 병상의 수<br>\n",
    "> - instkind: 병원, 의원, 요양병원, 한의원, 종합병원 등 병원의 종류<br><br>\n",
    "> - <재무정보> 1: 2017 회계년도, 2: 2016 회계년도\n",
    "> - revenue1(2): 매출액<br>\n",
    "> - salescost1(2): 매출원가<br>\n",
    "> - sga1(2): 판매비와 관리비<br>\n",
    "> - salary1(2): 급여<br>\n",
    "> - noi1(2): 영업외수익<br>\n",
    "> - noe1(2): 영업외비용<br>\n",
    "> - Interest1(2): 이자비용<br>\n",
    "> - ctax1(2): 법인세비용<br>\n",
    "> - Profit1(2): 당기순이익<br>\n",
    "> - liquidAsset1(2): 유동자산<br>\n",
    "> - quickAsset1(2): 당좌자산<br>\n",
    "> - receivableS1(2): 미수금(단기)<br>\n",
    "> - inventoryAsset1(2): 재고자산<br>\n",
    "> - nonCAsset1(2): 비유동자산<br>\n",
    "> - tanAsset1(2): 유형자산<br>\n",
    "> - OnonCAseet1(2): 기타 비유동자산<br>\n",
    "> - receivableL1(2): 장기미수금<br>\n",
    "> - debt1(2): 부채총계<br>\n",
    "> - liquidLiabilities1(2): 유동부채<br>\n",
    "> - shortLoan1(2): 단기차입금<br>\n",
    "> - NCLiabilities1(2): 비유동부채<br>\n",
    "> - longLoan1(2): 장기차입금<br>\n",
    "> - netAsset1(2): 순자산총계<br>\n",
    "> - surplus1(2): 이익잉여금\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the train and test files\n",
    "os.chdir('C:\\\\Users\\\\student\\\\python')\n",
    "train_prod_df = pd.read_csv('train.csv') # 학습데이터\n",
    "test_prod_df = pd.read_csv('test.csv') # 테스트데이터 (결과값 비어있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "      <th>sido</th>\n",
       "      <th>sgg</th>\n",
       "      <th>openDate</th>\n",
       "      <th>bedCount</th>\n",
       "      <th>instkind</th>\n",
       "      <th>revenue1</th>\n",
       "      <th>salescost1</th>\n",
       "      <th>sga1</th>\n",
       "      <th>...</th>\n",
       "      <th>debt2</th>\n",
       "      <th>liquidLiabilities2</th>\n",
       "      <th>shortLoan2</th>\n",
       "      <th>NCLiabilities2</th>\n",
       "      <th>longLoan2</th>\n",
       "      <th>netAsset2</th>\n",
       "      <th>surplus2</th>\n",
       "      <th>employee1</th>\n",
       "      <th>employee2</th>\n",
       "      <th>ownerChange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>open</td>\n",
       "      <td>choongnam</td>\n",
       "      <td>73</td>\n",
       "      <td>20071228</td>\n",
       "      <td>175.0</td>\n",
       "      <td>nursing_hospital</td>\n",
       "      <td>4.217530e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.961135e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>7.589937e+08</td>\n",
       "      <td>2.228769e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.361169e+08</td>\n",
       "      <td>3.900000e+08</td>\n",
       "      <td>2.619290e+09</td>\n",
       "      <td>1.271224e+09</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>open</td>\n",
       "      <td>gyeongnam</td>\n",
       "      <td>32</td>\n",
       "      <td>19970401</td>\n",
       "      <td>410.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>801.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>open</td>\n",
       "      <td>gyeonggi</td>\n",
       "      <td>89</td>\n",
       "      <td>20161228</td>\n",
       "      <td>468.0</td>\n",
       "      <td>nursing_hospital</td>\n",
       "      <td>1.004522e+09</td>\n",
       "      <td>515483669.0</td>\n",
       "      <td>4.472197e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>234.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>open</td>\n",
       "      <td>incheon</td>\n",
       "      <td>141</td>\n",
       "      <td>20000814</td>\n",
       "      <td>353.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>7.250734e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.067740e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.775501e+10</td>\n",
       "      <td>1.701860e+10</td>\n",
       "      <td>9.219427e+09</td>\n",
       "      <td>2.073641e+10</td>\n",
       "      <td>1.510000e+10</td>\n",
       "      <td>1.295427e+10</td>\n",
       "      <td>7.740829e+09</td>\n",
       "      <td>663.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>open</td>\n",
       "      <td>gyeongnam</td>\n",
       "      <td>32</td>\n",
       "      <td>20050901</td>\n",
       "      <td>196.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>4.904354e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.765605e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.143259e+10</td>\n",
       "      <td>3.007259e+10</td>\n",
       "      <td>1.759375e+10</td>\n",
       "      <td>2.136001e+10</td>\n",
       "      <td>1.410803e+10</td>\n",
       "      <td>5.561941e+06</td>\n",
       "      <td>9.025550e+09</td>\n",
       "      <td>206.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inst_id    OC       sido  sgg  openDate  bedCount          instkind  \\\n",
       "0        1  open  choongnam   73  20071228     175.0  nursing_hospital   \n",
       "1        3  open  gyeongnam   32  19970401     410.0  general_hospital   \n",
       "2        4  open   gyeonggi   89  20161228     468.0  nursing_hospital   \n",
       "3        7  open    incheon  141  20000814     353.0  general_hospital   \n",
       "4        9  open  gyeongnam   32  20050901     196.0  general_hospital   \n",
       "\n",
       "       revenue1   salescost1          sga1  ...         debt2  \\\n",
       "0  4.217530e+09          0.0  3.961135e+09  ...  7.589937e+08   \n",
       "1           NaN          NaN           NaN  ...           NaN   \n",
       "2  1.004522e+09  515483669.0  4.472197e+08  ...  0.000000e+00   \n",
       "3  7.250734e+10          0.0  7.067740e+10  ...  3.775501e+10   \n",
       "4  4.904354e+10          0.0  4.765605e+10  ...  5.143259e+10   \n",
       "\n",
       "   liquidLiabilities2    shortLoan2  NCLiabilities2     longLoan2  \\\n",
       "0        2.228769e+08  0.000000e+00    5.361169e+08  3.900000e+08   \n",
       "1                 NaN           NaN             NaN           NaN   \n",
       "2        0.000000e+00  0.000000e+00    0.000000e+00  0.000000e+00   \n",
       "3        1.701860e+10  9.219427e+09    2.073641e+10  1.510000e+10   \n",
       "4        3.007259e+10  1.759375e+10    2.136001e+10  1.410803e+10   \n",
       "\n",
       "      netAsset2      surplus2  employee1  employee2  ownerChange  \n",
       "0  2.619290e+09  1.271224e+09       62.0       64.0         same  \n",
       "1           NaN           NaN      801.0      813.0         same  \n",
       "2  0.000000e+00  0.000000e+00      234.0        1.0         same  \n",
       "3  1.295427e+10  7.740829e+09      663.0      663.0         same  \n",
       "4  5.561941e+06  9.025550e+09      206.0      197.0         same  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prod_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "      <th>sido</th>\n",
       "      <th>sgg</th>\n",
       "      <th>openDate</th>\n",
       "      <th>bedCount</th>\n",
       "      <th>instkind</th>\n",
       "      <th>revenue1</th>\n",
       "      <th>salescost1</th>\n",
       "      <th>sga1</th>\n",
       "      <th>...</th>\n",
       "      <th>debt2</th>\n",
       "      <th>liquidLiabilities2</th>\n",
       "      <th>shortLoan2</th>\n",
       "      <th>NCLiabilities2</th>\n",
       "      <th>longLoan2</th>\n",
       "      <th>netAsset2</th>\n",
       "      <th>surplus2</th>\n",
       "      <th>employee1</th>\n",
       "      <th>employee2</th>\n",
       "      <th>ownerChange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>incheon</td>\n",
       "      <td>139</td>\n",
       "      <td>19981125.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>6.682486e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.565709e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.540643e+10</td>\n",
       "      <td>5.068443e+10</td>\n",
       "      <td>3.714334e+10</td>\n",
       "      <td>4.720000e+09</td>\n",
       "      <td>4.690000e+09</td>\n",
       "      <td>1.608540e+10</td>\n",
       "      <td>8.944587e+09</td>\n",
       "      <td>693</td>\n",
       "      <td>693</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jeju</td>\n",
       "      <td>149</td>\n",
       "      <td>20160309.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>hospital</td>\n",
       "      <td>3.495758e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.259270e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>6.730838e+10</td>\n",
       "      <td>4.209828e+10</td>\n",
       "      <td>2.420000e+10</td>\n",
       "      <td>2.521009e+10</td>\n",
       "      <td>1.830000e+10</td>\n",
       "      <td>3.789135e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>379</td>\n",
       "      <td>371</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jeonnam</td>\n",
       "      <td>103</td>\n",
       "      <td>19890427.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>2.326031e+10</td>\n",
       "      <td>2.542571e+09</td>\n",
       "      <td>2.308749e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.777589e+10</td>\n",
       "      <td>2.182278e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.638540e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>busan</td>\n",
       "      <td>71</td>\n",
       "      <td>20100226.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.211517e+10</td>\n",
       "      <td>9.556237e+09</td>\n",
       "      <td>4.251867e+09</td>\n",
       "      <td>2.558931e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.914284e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jeonbuk</td>\n",
       "      <td>26</td>\n",
       "      <td>20040604.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>5.037025e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.855803e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>4.395973e+10</td>\n",
       "      <td>7.535567e+09</td>\n",
       "      <td>3.298427e+09</td>\n",
       "      <td>3.642417e+10</td>\n",
       "      <td>2.134712e+10</td>\n",
       "      <td>2.574488e+10</td>\n",
       "      <td>1.507269e+10</td>\n",
       "      <td>437</td>\n",
       "      <td>385</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inst_id  OC     sido  sgg    openDate  bedCount          instkind  \\\n",
       "0        2 NaN  incheon  139  19981125.0     300.0  general_hospital   \n",
       "1        5 NaN     jeju  149  20160309.0      44.0          hospital   \n",
       "2        6 NaN  jeonnam  103  19890427.0     276.0  general_hospital   \n",
       "3        8 NaN    busan   71  20100226.0     363.0  general_hospital   \n",
       "4       10 NaN  jeonbuk   26  20040604.0     213.0  general_hospital   \n",
       "\n",
       "       revenue1    salescost1          sga1  ...         debt2  \\\n",
       "0  6.682486e+10  0.000000e+00  6.565709e+10  ...  5.540643e+10   \n",
       "1  3.495758e+10  0.000000e+00  3.259270e+10  ...  6.730838e+10   \n",
       "2  2.326031e+10  2.542571e+09  2.308749e+10  ...  0.000000e+00   \n",
       "3  0.000000e+00  0.000000e+00  0.000000e+00  ...  1.211517e+10   \n",
       "4  5.037025e+10  0.000000e+00  4.855803e+10  ...  4.395973e+10   \n",
       "\n",
       "   liquidLiabilities2    shortLoan2  NCLiabilities2     longLoan2  \\\n",
       "0        5.068443e+10  3.714334e+10    4.720000e+09  4.690000e+09   \n",
       "1        4.209828e+10  2.420000e+10    2.521009e+10  1.830000e+10   \n",
       "2        2.777589e+10  2.182278e+10    0.000000e+00  0.000000e+00   \n",
       "3        9.556237e+09  4.251867e+09    2.558931e+09  0.000000e+00   \n",
       "4        7.535567e+09  3.298427e+09    3.642417e+10  2.134712e+10   \n",
       "\n",
       "      netAsset2      surplus2  employee1  employee2  ownerChange  \n",
       "0  1.608540e+10  8.944587e+09        693        693         same  \n",
       "1  3.789135e+09  0.000000e+00        379        371         same  \n",
       "2  0.000000e+00  1.638540e+10        NaN        NaN          NaN  \n",
       "3  3.914284e+10  0.000000e+00        760        760         same  \n",
       "4  2.574488e+10  1.507269e+10        437        385         same  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prod_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert 'employee' to numeric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the comma in the employee1 and 2 columns in the test dataset and replace it with empty space and convert it to float format.\n",
    "test_prod_df.employee1 = test_prod_df.employee1.astype('str').str.replace(\",\", \"\").astype('float')\n",
    "test_prod_df.employee2 = test_prod_df.employee2.astype('str').str.replace(\",\", \"\").astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the employee1 and 2 column as float in the train set as done for the test dataset\n",
    "train_prod_df.employee1 = train_prod_df.employee1.astype('float')\n",
    "train_prod_df.employee2 = train_prod_df.employee2.astype('float')\n",
    "train_prod_df.OC= train_prod_df.OC.astype('str').str.replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the empty values\n",
    "- Factor columns: Not_sure\n",
    "- Numeric columns: -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the train and test dataset\n",
    "train_test_prod = train_prod_df.append(test_prod_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428, 58)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_prod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the object and numeric columns seperately \n",
    "factor_columns = train_test_prod.select_dtypes(include = ['object']).columns\n",
    "numeric_columns = train_test_prod.columns.difference(factor_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OC', 'sido', 'instkind', 'ownerChange'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NCLiabilities1', 'NCLiabilities2', 'OnonCAsset1', 'OnonCAsset2',\n",
       "       'bedCount', 'ctax1', 'ctax2', 'debt1', 'debt2', 'employee1',\n",
       "       'employee2', 'inst_id', 'interest1', 'interest2', 'inventoryAsset1',\n",
       "       'inventoryAsset2', 'liquidAsset1', 'liquidAsset2', 'liquidLiabilities1',\n",
       "       'liquidLiabilities2', 'longLoan1', 'longLoan2', 'netAsset1',\n",
       "       'netAsset2', 'noe1', 'noe2', 'noi1', 'noi2', 'nonCAsset1', 'nonCAsset2',\n",
       "       'openDate', 'profit1', 'profit2', 'quickAsset1', 'quickAsset2',\n",
       "       'receivableL1', 'receivableL2', 'receivableS1', 'receivableS2',\n",
       "       'revenue1', 'revenue2', 'salary1', 'salary2', 'salescost1',\n",
       "       'salescost2', 'sga1', 'sga2', 'sgg', 'shortLoan1', 'shortLoan2',\n",
       "       'surplus1', 'surplus2', 'tanAsset1', 'tanAsset2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After analysis realized that the bed counts of these two hospitals may have had wrong entries.\n",
    "#Filling up the empty instkind and bedCount for hospital id 430 and 413\n",
    "train_test_prod.loc[train_test_prod.inst_id == 430, ['instkind']] = 'dental_clinic'\n",
    "train_test_prod.loc[train_test_prod.inst_id == 430, ['bedCount']] = 0\n",
    "train_test_prod.loc[train_test_prod.inst_id == 413, ['bedCount']] = -999\n",
    "\n",
    "#Fill the empty values in the object columns as \"Not sure\"\n",
    "train_test_prod[factor_columns] = train_test_prod[factor_columns].fillna('Not_sure')\n",
    "#Fill all the empty values in the numeric columns as -999\n",
    "train_test_prod[numeric_columns] = train_test_prod[numeric_columns].fillna(-999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the whole data into train and test set\n",
    "- dependent column: OC (0:close, 1:open)\n",
    "- independent columns: others\n",
    "\n",
    "\n",
    "- train_prod_X: train set with independent columns\n",
    "- train_prod_Y: train set with dependent column\n",
    "- test_prod_X: test set with independent columns\n",
    "- test_prod_Y: the objective of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#Convert all the object columns to numeric since the ML algorithms don't accept object features directly \n",
    "fac_le = LabelEncoder()\n",
    "train_test_prod[factor_columns] = train_test_prod.loc[:,factor_columns].apply(lambda x : fac_le.fit_transform(x))\n",
    "\n",
    "#Splitting back data to train prod and test prod\n",
    "#값이 있으면 train 데이터셋 값이 비어있으면 test 데이터셋 \n",
    "train_prod = train_test_prod.loc[train_test_prod.OC != 0,]\n",
    "test_prod = train_test_prod.loc[train_test_prod.OC == 0,]\n",
    "\n",
    "# 1,2 를 0,1로 바꾸기 (0이 폐업(close) 1이 폐업X(open))\n",
    "train_prod['OC'] = train_prod['OC'] - 1\n",
    "\n",
    "#Obtain the submission ID to create the submission file later\n",
    "sub_id = test_prod.inst_id\n",
    "\n",
    "#Get the dependent and independent column\n",
    "dep = 'OC'\n",
    "indep = train_prod.columns.difference([dep])\n",
    "\n",
    "train_prod_X = train_prod[indep]\n",
    "train_prod_Y = train_prod[dep]\n",
    "test_prod_X = test_prod[indep]\n",
    "#test_prod_Y = test_prod[dep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification Model(1) - Random Forest\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;분류/회귀예측에 이용되는 앙상블 기법 중 하나로, 대표적인 배깅 모형에 해당함<br><br>&nbsp;&nbsp;&nbsp;&nbsp;다수의 결정 트리를 구성한 뒤 평균 또는 과반수 투표 등을 이용하여 하나의 랜덤 포레스트로 결합함  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;A. Hyperparameter tuning of Random forest<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;B. Check the over-fitting of tuned model<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;C. Calculate the cut-off value for classification<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;D. Compare default model to tuned model<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Hyperparameter tuning of Random forest (using 3-fold cross validation)\n",
    "- n_estimators: The number of trees in the forest.\n",
    "- max_features: The number of features to consider when looking for the best split.\n",
    "- max_depth: The maximum depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 300, num = 10)] # Number of trees in random forest\n",
    "max_features = ['auto', 'sqrt'] # Number of features to consider at every split\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)] # Maximum number of levels in tree\n",
    "max_depth.append(None)\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 240 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:   43.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100,\n",
       "                                       110, None],\n",
       "                         'max_features': ['auto', 'sqrt'],\n",
       "                         'n_estimators': [10, 42, 74, 106, 138, 171, 203, 235,\n",
       "                                          267, 300]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "np.random.seed(42)\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = GridSearchCV(estimator = rf, param_grid = random_grid, scoring = 'accuracy', cv = 3, verbose=2, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_prod_X, train_prod_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the best hyperparameter combination and train the random forest model with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'max_features': 'auto', 'n_estimators': 74}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.959459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.783784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.567568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.824324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.932432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>424</td>\n",
       "      <td>0.378378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>425</td>\n",
       "      <td>0.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>429</td>\n",
       "      <td>0.581081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>430</td>\n",
       "      <td>0.824324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>431</td>\n",
       "      <td>0.567568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     inst_id        OC\n",
       "0          2  0.959459\n",
       "1          5  0.783784\n",
       "2          6  0.567568\n",
       "3          8  0.824324\n",
       "4         10  0.932432\n",
       "..       ...       ...\n",
       "122      424  0.378378\n",
       "123      425  0.702703\n",
       "124      429  0.581081\n",
       "125      430  0.824324\n",
       "126      431  0.567568\n",
       "\n",
       "[127 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################################\n",
    "############ Random Forest with hyper-parameter tuning\n",
    "############################################################################\n",
    "estimators = rf_random.best_params_['n_estimators']\n",
    "max_depth_tune = rf_random.best_params_['max_depth']\n",
    "max_features_tune = rf_random.best_params_['max_features']\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "# 하이퍼파라미터 적용\n",
    "RF_prod_tune = RandomForestClassifier(n_estimators = estimators,\n",
    "                                max_depth = max_depth_tune,\n",
    "                                max_features = max_features_tune) \n",
    "\n",
    "# 훈련\n",
    "RF_prod_tune.fit(train_prod_X, train_prod_Y) \n",
    "\n",
    "# 결과: class가 0 or 1 \n",
    "RF_prod_predicted_tune = RF_prod_tune.predict(test_prod_X) \n",
    "\n",
    "# 결과: class 1에 속할 확률\n",
    "RF_prod_prediction_tune = RF_prod_tune.predict_proba(test_prod_X)[:,1] \n",
    "\n",
    "# 튜닝 후 예측 결과 출력\n",
    "sub_RF_tune = pd.DataFrame({'inst_id' : sub_id , 'OC' : RF_prod_prediction_tune })\n",
    "sub_RF_tune = sub_RF_tune[['inst_id', 'OC']]\n",
    "sub_RF_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Check the over-fitting of tuned model (using 5-fold cross validation)\n",
    "#### 하이퍼파라미터 튜닝 범위가 무작위로 설정되었기 때문에 튜닝 결과가 훈련 데이터에 과대적합되었을 가능성이 존재함<br><br>교차 검증을 통해 과대적합 여부를 확인한 결과, 모든 fold에서 적절한 분류 성능을 보이고 있었음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95081967 0.95       0.95       0.95       0.96666667]\n",
      "mean :  0.9534972677595629\n"
     ]
    }
   ],
   "source": [
    "# model, train, target, cross validation\n",
    "np.random.seed(10)\n",
    "scores = cross_val_score(RF_prod_tune, train_prod_X, train_prod_Y, cv=5) \n",
    "print(scores)\n",
    "print('mean : ',scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Calculate the cut-off value for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct the test set with real answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# 예측결과 0(close) 라벨링 \n",
    "close_idx = [5, 6, 24, 30 ,64, 123, 229, 258, 293, 341, 425, 429, 431]\n",
    "test_prod_labeled = test_prod[['inst_id', 'OC']] # 결과 라벨링 된 테스트 데이터프레임\n",
    "test_prod_labeled['OC'] = [0 if id in close_idx else 1 for id in test_prod['inst_id']] # 라벨링\n",
    "y_true = list(test_prod_labeled['OC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the optimal cut-off value (0.5~0.8 by 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 5\n",
    "end = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " cut-off value :  0.5\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.25      0.08      0.12        13\n",
      "       close       0.90      0.97      0.94       114\n",
      "\n",
      "    accuracy                           0.88       127\n",
      "   macro avg       0.58      0.53      0.53       127\n",
      "weighted avg       0.84      0.88      0.85       127\n",
      "\n",
      "0.8818897637795275\n",
      "============================================================\n",
      " cut-off value :  0.6\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.67      0.46      0.55        13\n",
      "       close       0.94      0.97      0.96       114\n",
      "\n",
      "    accuracy                           0.92       127\n",
      "   macro avg       0.80      0.72      0.75       127\n",
      "weighted avg       0.91      0.92      0.91       127\n",
      "\n",
      "0.9212598425196851\n",
      "============================================================\n",
      " cut-off value :  0.7\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.73      0.62      0.67        13\n",
      "       close       0.96      0.97      0.97       114\n",
      "\n",
      "    accuracy                           0.94       127\n",
      "   macro avg       0.84      0.79      0.82       127\n",
      "weighted avg       0.93      0.94      0.93       127\n",
      "\n",
      "0.937007874015748\n",
      "============================================================\n",
      " cut-off value :  0.8\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.62      1.00      0.76        13\n",
      "       close       1.00      0.93      0.96       114\n",
      "\n",
      "    accuracy                           0.94       127\n",
      "   macro avg       0.81      0.96      0.86       127\n",
      "weighted avg       0.96      0.94      0.94       127\n",
      "\n",
      "0.937007874015748\n"
     ]
    }
   ],
   "source": [
    "max_accuracy = -1\n",
    "coval_max = -1\n",
    "\n",
    "for i in range(start,end):\n",
    "    print('='*60)\n",
    "    coval = i/10\n",
    "    print(\" cut-off value : \" ,coval)\n",
    "    print('-'*22)\n",
    "\n",
    "    sub_RF_tune_ths = sub_RF_tune[['inst_id', 'OC']]\n",
    "    sub_RF_tune_ths['OC'] = [1 if oc>=coval else 0 for oc in sub_RF_tune_ths['OC']] # 확률값을 1,0으로 변환\n",
    "    y_prod = list(sub_RF_tune_ths['OC'])\n",
    "    \n",
    "    print(classification_report(y_true, y_prod, target_names=['open', 'close']))\n",
    "    print(accuracy_score(y_true,y_prod))\n",
    "        \n",
    "    if max_accuracy < accuracy_score(y_true,y_prod):\n",
    "        max_accuracy = accuracy_score(y_true,y_prod)\n",
    "        coval_max = coval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal cut-off value (according to 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_rf = coval_max\n",
    "cutoff_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Compare default model to tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defalut model\n",
    "- n_estimators: default\n",
    "- max_features: defalut\n",
    "- max_depth: defalut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ Random Forest\n",
    "############################################################################\n",
    "np.random.seed(100)\n",
    "RF_prod = RandomForestClassifier()\n",
    "RF_prod_model = RF_prod.fit(train_prod_X, train_prod_Y)\n",
    "RF_prod_prediction = RF_prod.predict_proba(test_prod_X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare 2 models with optimal cut-off value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_RF = pd.DataFrame({'inst_id' : sub_id , 'OC' : RF_prod_prediction })\n",
    "sub_RF = sub_RF[['inst_id', 'OC']]\n",
    "sub_RF['OC'] = [1 if oc>=cutoff_rf else 0 for oc in sub_RF['OC']]\n",
    "y_prod = list(sub_RF['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_RF_customized = sub_RF_tune[['inst_id', 'OC']]\n",
    "sub_RF_customized['OC'] = [1 if oc >= cutoff_rf else 0 for oc in sub_RF_customized['OC']] # 확률값을 1,0으로 변환\n",
    "y_prod_customized = list(sub_RF_customized['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Before tuned============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.75      0.69      0.72        13\n",
      "     class 1       0.97      0.97      0.97       114\n",
      "\n",
      "    accuracy                           0.94       127\n",
      "   macro avg       0.86      0.83      0.84       127\n",
      "weighted avg       0.94      0.94      0.94       127\n",
      "\n",
      "0.9448818897637795\n",
      "============After tuned============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.73      0.62      0.67        13\n",
      "     class 1       0.96      0.97      0.97       114\n",
      "\n",
      "    accuracy                           0.94       127\n",
      "   macro avg       0.84      0.79      0.82       127\n",
      "weighted avg       0.93      0.94      0.93       127\n",
      "\n",
      "0.937007874015748\n"
     ]
    }
   ],
   "source": [
    "# Before tuned\n",
    "print('============Before tuned============')\n",
    "print(classification_report(y_true, y_prod, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod))\n",
    "# After tuned\n",
    "print('============After tuned============')\n",
    "print(classification_report(y_true, y_prod_customized, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod_customized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification Model(2) - GBM\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;분류/회귀예측에 이용되는 앙상블 기법 중 하나로, 대표적인 부스팅 모형에 해당함<br><br>&nbsp;&nbsp;&nbsp;&nbsp;기존 타겟값과 그 residual을 예측하는 모형을 반복적으로 구성하고 결합함으로써 모형의 예측력을 높여가는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;A. Hyperparameter tuning of GBM<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;B. Check the over-fitting of tuned model<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;C. Calculate the cut-off value for classification<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;D. Compare default model to tuned model<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Hyperparameter tuning of GBM (using 5-fold cross validation)\n",
    "- n_estimators: The number of boosting stages to perform.\n",
    "- max_features: The number of features to consider when looking for the best split.\n",
    "- max_depth: The maximum depth of the individual estimators.\n",
    "- min_sample_split: The minimum number of samples required to split an internal node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'OC'\n",
    "IDcol = 'inst_id'\n",
    "\n",
    "predictors = [x for x in train_prod_X.columns if x not in [target, IDcol]]\n",
    "param_test1 = {'n_estimators':range(60,140,10), 'min_samples_split':range(2,5,1),'max_depth':range(5,9),'max_features':['sqrt','auto']}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, subsample=1.0,random_state=42), \n",
    "param_grid = param_test1, scoring='accuracy',n_jobs=-1, cv=5,  refit=True)\n",
    "\n",
    "gsearch1.fit(train_prod_X[predictors],train_prod_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the best hyperparameter combination and train the GBM model with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ GBM with hyper-parameter tuning\n",
    "############################################################################\n",
    "np.random.seed(42)\n",
    "estimators = gsearch1.best_estimator_.n_estimators\n",
    "max_depth=gsearch1.best_estimator_.max_depth\n",
    "max_features=gsearch1.best_estimator_.max_features\n",
    "min_samples_leaf=gsearch1.best_estimator_.min_samples_leaf\n",
    "n_estimators=gsearch1.best_estimator_.n_estimators\n",
    "random_state=gsearch1.best_estimator_.random_state\n",
    "\n",
    "GBM_prod_tune = GradientBoostingClassifier(n_estimators = estimators ,max_depth=max_depth, max_features=max_features,min_samples_leaf=min_samples_leaf,random_state = random_state )\n",
    "GBM_prod_model_tune = GBM_prod_tune.fit(train_prod_X, train_prod_Y)\n",
    "GBM_prod_prediction_tune = GBM_prod_tune.predict_proba(test_prod_X)[:,1]\n",
    "\n",
    "sub_GBM_tune = pd.DataFrame({'inst_id' : sub_id , 'OC' : GBM_prod_prediction_tune })\n",
    "sub_GBM_tune = sub_GBM_tune[['inst_id', 'OC']]\n",
    "sub_GBM_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Check the over-fitting of tuned model (using 5-fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM 함수를 만들고 교차 검증을 수행하는데 도움을 주는 함수\n",
    "def modelfit(alg, dtrain, predictors, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    global train_prod_Y\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors],train_prod_Y)\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    #Perform cross-validation:\n",
    "    if performCV:\n",
    "        cv_score = cross_val_score(alg, dtrain[predictors], train_prod_Y, cv=cv_folds, scoring='roc_auc')\n",
    "    \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % accuracy_score(train_prod_Y.values, dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % roc_auc_score(train_prod_Y, dtrain_predprob))\n",
    "    \n",
    "    if performCV:\n",
    "        print (\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "        \n",
    "    #Print Feature Importance:\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train_prod.columns if x not in [target,IDcol]]\n",
    "modelfit(GBM_prod_tune, train_prod_X, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Calculate the cut-off value for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the optimal cut-off value (0.5~0.8 by 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_accuracy = -1\n",
    "coval_max = -1\n",
    "\n",
    "for i in range(start,end):\n",
    "    print('='*60)\n",
    "    coval = i/10\n",
    "    print(\" cut-off value : \" ,coval)\n",
    "    print('-'*22)\n",
    "\n",
    "    sub_GBM_tune_ths = sub_GBM_tune[['inst_id', 'OC']]\n",
    "    sub_GBM_tune_ths['OC'] = [1 if oc>=coval else 0 for oc in sub_GBM_tune_ths['OC']]\n",
    "    y_prod_tune = list(sub_GBM_tune_ths['OC'])\n",
    "    print(classification_report(y_true, y_prod_tune, target_names=['open', 'close']))\n",
    "    print(accuracy_score(y_true,y_prod_tune))\n",
    "\n",
    "    if max_accuracy < accuracy_score(y_true,y_prod_tune):\n",
    "        max_accuracy = accuracy_score(y_true,y_prod_tune)\n",
    "        coval_max = coval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal cut-off value (according to 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_GBM = coval_max\n",
    "cutoff_GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Compare orginal model to tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defalut model\n",
    "- n_estimators: default\n",
    "- max_features: default\n",
    "- max_depth: default\n",
    "- min_sample_split: default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ GBM\n",
    "############################################################################\n",
    "np.random.seed(100)\n",
    "GBM_prod = GradientBoostingClassifier()\n",
    "GBM_prod_model = GBM_prod.fit(train_prod_X, train_prod_Y)\n",
    "GBM_prod_prediction = GBM_prod.predict_proba(test_prod_X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare 2 models with optimal cut-off value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_GBM = pd.DataFrame({'inst_id' : sub_id , 'OC' : GBM_prod_prediction })\n",
    "sub_GBM = sub_GBM[['inst_id', 'OC']]\n",
    "sub_GBM['OC'] = [1 if oc>=cutoff_GBM else 0 for oc in sub_GBM['OC']]\n",
    "y_prod = list(sub_GBM['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_GBM_customized = sub_GBM_tune[['inst_id', 'OC']]\n",
    "sub_GBM_customized['OC'] = [1 if oc >= cutoff_GBM else 0 for oc in sub_GBM_customized['OC']] # 확률값을 1,0으로 변환\n",
    "y_prod_customized = list(sub_GBM_customized['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before tuned\n",
    "print('============Before tuned============')\n",
    "print(classification_report(y_true, y_prod, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod))\n",
    "# After tuned\n",
    "print('============After tuned============')\n",
    "print(classification_report(y_true, y_prod_customized, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod_customized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification Model(3) -XGBOOST\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;GBM보다 속도와 성능이 향상된 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Hyperparameter tuning of XGBOOST (using 3-fold cross validation)\n",
    "- eta: The learning rate.\n",
    "- num_boost_round: The number of boosting rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_prod = xgb.DMatrix(data = train_prod_X, label = train_prod_Y)\n",
    "dtest_prod = xgb.DMatrix(data = test_prod_X)\n",
    "\n",
    "#Custom error function for the XGB model\n",
    "threshold = 0.5\n",
    "def eval_error(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = (preds > threshold ).astype('float')\n",
    "    return \"accuracy\", accuracy_score(labels, preds)\n",
    "    \n",
    "\n",
    "param_tmp = {'eta': [0.1, 0.2, 0.3, 0.4]}\n",
    "nrounds = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x000001CD18711348>,\n",
       "             error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weigh...\n",
       "                                     n_estimators=100, n_jobs=None, nthread=1,\n",
       "                                     num_parallel_tree=None,\n",
       "                                     objective='binary:logistic',\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'eta': [0.1, 0.2, 0.3, 0.4]}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring='accuracy',\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier = XGBClassifier(objective='binary:logistic',nthread=1)\n",
    "skf = StratifiedKFold(n_splits=3, shuffle = True, random_state = 42)\n",
    "\n",
    "grid_search_XGB = GridSearchCV(xgb_classifier, param_grid = param_tmp, scoring='accuracy', n_jobs=4, cv=skf.split(train_prod_X, train_prod_Y), verbose=2)\n",
    "grid_search_XGB.fit(train_prod_X, train_prod_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the best hyperparameter combination and train the GBM model with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta': 0.3}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_XGB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ XGBOOST - tuning\n",
    "############################################################################\n",
    "np.random.seed(100)\n",
    "best_param = {'eta': grid_search_XGB.best_params_['eta']}\n",
    "\n",
    "xgb_model_tune = xgb.train(best_param, \n",
    "                      dtrain_prod, \n",
    "                      num_boost_round = nrounds ,\n",
    "                      feval = eval_error,\n",
    "                      #maximize = True,\n",
    "                      #early_stopping_rounds = 10,\n",
    "                      )\n",
    "\n",
    "XGB_prediction = xgb_model_tune.predict(dtest_prod)\n",
    "sub_XGB_tune= pd.DataFrame({'inst_id' : sub_id , 'OC' : XGB_prediction })\n",
    "sub_XGB_tune= sub_XGB_tune[['inst_id', 'OC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PLotting the feature importance\n",
    "xgb_Imp_tune = pd.DataFrame({'Features' : list(xgb_model_tune.get_score().keys()), \n",
    "                        'Importance' : list(xgb_model_tune.get_score().values())}).sort_values(['Importance'])\n",
    "plt.figure()\n",
    "sns.barplot(xgb_Imp_tune.Importance, xgb_Imp_tune.Features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Check the over-fitting of tuned model (using 5-fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95081967 0.95       0.95       0.95       0.95      ]\n",
      "mean :  0.9501639344262296\n"
     ]
    }
   ],
   "source": [
    "# model, train, target, cross validation\n",
    "np.random.seed(10)\n",
    "xgb_model_tune_clf = XGBClassifier(objective='binary:logistic',\n",
    "                                   learning_rate=grid_search_XGB.best_params_['eta'] )\n",
    "\n",
    "scores = cross_val_score(xgb_model_tune_clf, train_prod_X, train_prod_Y, cv=5) \n",
    "print(scores)\n",
    "print('mean : ',scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Calculate the cut-off value for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the optimal cut-off value (0.5~0.8 by 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " cut-off value :  0.5\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.75      0.92      0.83        13\n",
      "       close       0.99      0.96      0.98       114\n",
      "\n",
      "    accuracy                           0.96       127\n",
      "   macro avg       0.87      0.94      0.90       127\n",
      "weighted avg       0.97      0.96      0.96       127\n",
      "\n",
      "0.9606299212598425\n",
      "============================================================\n",
      " cut-off value :  0.6\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.67      0.92      0.77        13\n",
      "       close       0.99      0.95      0.97       114\n",
      "\n",
      "    accuracy                           0.94       127\n",
      "   macro avg       0.83      0.94      0.87       127\n",
      "weighted avg       0.96      0.94      0.95       127\n",
      "\n",
      "0.9448818897637795\n",
      "============================================================\n",
      " cut-off value :  0.7\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.57      1.00      0.72        13\n",
      "       close       1.00      0.91      0.95       114\n",
      "\n",
      "    accuracy                           0.92       127\n",
      "   macro avg       0.78      0.96      0.84       127\n",
      "weighted avg       0.96      0.92      0.93       127\n",
      "\n",
      "0.9212598425196851\n",
      "============================================================\n",
      " cut-off value :  0.8\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.10      1.00      0.19        13\n",
      "       close       0.00      0.00      0.00       114\n",
      "\n",
      "    accuracy                           0.10       127\n",
      "   macro avg       0.05      0.50      0.09       127\n",
      "weighted avg       0.01      0.10      0.02       127\n",
      "\n",
      "0.10236220472440945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "max_accuracy = -1\n",
    "coval_max = -1\n",
    "for i in range(start,end):\n",
    "    print('='*60)\n",
    "    coval = i/10\n",
    "    print(\" cut-off value : \" ,coval)\n",
    "    print('-'*22)\n",
    "\n",
    "    sub_XGB_tune_ths = sub_XGB_tune[['inst_id', 'OC']]\n",
    "    sub_XGB_tune_ths['OC'] = [1 if oc>=coval else 0 for oc in sub_XGB_tune_ths['OC']]\n",
    "    y_prod = list(sub_XGB_tune_ths['OC'])\n",
    "    print(classification_report(y_true, y_prod, target_names=['open', 'close']))\n",
    "    acc= accuracy_score(y_true,y_prod)\n",
    "    print(acc)\n",
    "    if max_accuracy < acc:\n",
    "        max_accuracy = acc\n",
    "        coval_max = coval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal cut-off value (according to 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_XGB = coval_max\n",
    "cutoff_XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Compare orginal model to tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defalut model\n",
    "- eta: default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ XGBOOST\n",
    "############################################################################\n",
    "XGB_prod = XGBClassifier()\n",
    "XGB_prod.fit(train_prod_X, train_prod_Y)\n",
    "XGB_prod_prediction = XGB_prod.predict_proba(test_prod_X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare 2 models with optimal cut-off value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_XGB= pd.DataFrame({'inst_id' : sub_id , 'OC' : XGB_prediction })\n",
    "sub_XGB= sub_XGB[['inst_id', 'OC']]\n",
    "sub_XGB['OC'] = [1 if oc>=cutoff_XGB else 0 for oc in sub_XGB['OC']]\n",
    "y_prod = list(sub_XGB['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_XGB_customized = sub_XGB_tune[['inst_id', 'OC']]\n",
    "sub_XGB_customized['OC'] = [1 if oc >= cutoff_XGB else 0 for oc in sub_XGB_customized['OC']] # 확률값을 1,0으로 변환\n",
    "y_prod_customized = list(sub_XGB_customized['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Before tuned============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.75      0.92      0.83        13\n",
      "     class 1       0.99      0.96      0.98       114\n",
      "\n",
      "    accuracy                           0.96       127\n",
      "   macro avg       0.87      0.94      0.90       127\n",
      "weighted avg       0.97      0.96      0.96       127\n",
      "\n",
      "0.9606299212598425\n",
      "============After tuned============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.75      0.92      0.83        13\n",
      "     class 1       0.99      0.96      0.98       114\n",
      "\n",
      "    accuracy                           0.96       127\n",
      "   macro avg       0.87      0.94      0.90       127\n",
      "weighted avg       0.97      0.96      0.96       127\n",
      "\n",
      "0.9606299212598425\n"
     ]
    }
   ],
   "source": [
    "# Before tuned\n",
    "print('============Before tuned============')\n",
    "print(classification_report(y_true, y_prod, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod))\n",
    "# After tuned\n",
    "print('============After tuned============')\n",
    "print(classification_report(y_true, y_prod_customized, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod_customized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고사이트   \n",
    "1. Random forest   \n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "2. GBM   \n",
    "https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "\n",
    "3. xgboost   \n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
