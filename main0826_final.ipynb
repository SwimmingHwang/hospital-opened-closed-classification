{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge shap\n",
    "# pip install xgboost\n",
    "# pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>병원 개/폐업 분류예측 프로젝트</h1></center><br>\n",
    "\n",
    "---\n",
    "<h4>1. 주제 및 목표</h4>\n",
    "- 병원 폐업 여부를 예측하여 대출 승인여부 결정\n",
    "\n",
    "<h4>2. 배경</h4>\n",
    "- 한국 핀테크 기업 모우다(MOUDA): 상환기간 동안의 계속 경영 여부를 예측하여 병원들에게 금융 기회를 제공\n",
    "- 일반적으로 병원 대출 시 신용점수 또는 담보물을 위주로 평가를 진행했던 기존 금융기관과의 차별점\n",
    "- 신용 점수가 낮거나 담보를 가지지 못하는 우수 병원들에게도 금융 기회를 제공하자는 취지\n",
    "\n",
    "<h4>3. 활용 데이터</h4>\n",
    "- 의료기관의 폐업 여부가 포함된 최근 2개년의 재무정보와 병원 기본정보 \n",
    "- (출처) Dacon 병원 개/폐업 분류 예측 경진대회 (https://dacon.io/competitions/official/9565/data/)\n",
    "- 데이터 설명\n",
    "> - <병원 기본정보>\n",
    "> - inst_id: 병원 고유 번호<br>\n",
    "> - OC: 영업/폐업 분류<br>\n",
    "> - sido: 병원의 광역 지역 정보<br>\n",
    "> - sgg: 병원의 시군구 자료<br>\n",
    "> - openDate: 병원 설립일<br> \n",
    "> - bedcount: 병원이 갖추고 있는 병상의 수<br>\n",
    "> - instkind: 병원, 의원, 요양병원, 한의원, 종합병원 등 병원의 종류<br><br>\n",
    "> - <재무정보> 1: 2017 회계년도, 2: 2016 회계년도\n",
    "> - revenue1(2): 매출액<br>\n",
    "> - salescost1(2): 매출원가<br>\n",
    "> - sga1(2): 판매비와 관리비<br>\n",
    "> - salary1(2): 급여<br>\n",
    "> - noi1(2): 영업외수익<br>\n",
    "> - noe1(2): 영업외비용<br>\n",
    "> - Interest1(2): 이자비용<br>\n",
    "> - ctax1(2): 법인세비용<br>\n",
    "> - Profit1(2): 당기순이익<br>\n",
    "> - liquidAsset1(2): 유동자산<br>\n",
    "> - quickAsset1(2): 당좌자산<br>\n",
    "> - receivableS1(2): 미수금(단기)<br>\n",
    "> - inventoryAsset1(2): 재고자산<br>\n",
    "> - nonCAsset1(2): 비유동자산<br>\n",
    "> - tanAsset1(2): 유형자산<br>\n",
    "> - OnonCAseet1(2): 기타 비유동자산<br>\n",
    "> - receivableL1(2): 장기미수금<br>\n",
    "> - debt1(2): 부채총계<br>\n",
    "> - liquidLiabilities1(2): 유동부채<br>\n",
    "> - shortLoan1(2): 단기차입금<br>\n",
    "> - NCLiabilities1(2): 비유동부채<br>\n",
    "> - longLoan1(2): 장기차입금<br>\n",
    "> - netAsset1(2): 순자산총계<br>\n",
    "> - surplus1(2): 이익잉여금\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the train and test files\n",
    "train_prod_df = pd.read_csv('data\\\\train.csv') # 학습데이터\n",
    "test_prod_df = pd.read_csv('data\\\\test_empty.csv') # 테스트데이터 (결과값 비어있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "      <th>sido</th>\n",
       "      <th>sgg</th>\n",
       "      <th>openDate</th>\n",
       "      <th>bedCount</th>\n",
       "      <th>instkind</th>\n",
       "      <th>revenue1</th>\n",
       "      <th>salescost1</th>\n",
       "      <th>sga1</th>\n",
       "      <th>...</th>\n",
       "      <th>debt2</th>\n",
       "      <th>liquidLiabilities2</th>\n",
       "      <th>shortLoan2</th>\n",
       "      <th>NCLiabilities2</th>\n",
       "      <th>longLoan2</th>\n",
       "      <th>netAsset2</th>\n",
       "      <th>surplus2</th>\n",
       "      <th>employee1</th>\n",
       "      <th>employee2</th>\n",
       "      <th>ownerChange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>open</td>\n",
       "      <td>choongnam</td>\n",
       "      <td>73</td>\n",
       "      <td>20071228</td>\n",
       "      <td>175.0</td>\n",
       "      <td>nursing_hospital</td>\n",
       "      <td>4.217530e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.961135e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>7.589937e+08</td>\n",
       "      <td>2.228769e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.361169e+08</td>\n",
       "      <td>3.900000e+08</td>\n",
       "      <td>2.619290e+09</td>\n",
       "      <td>1.271224e+09</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>open</td>\n",
       "      <td>gyeongnam</td>\n",
       "      <td>32</td>\n",
       "      <td>19970401</td>\n",
       "      <td>410.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>801.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>open</td>\n",
       "      <td>gyeonggi</td>\n",
       "      <td>89</td>\n",
       "      <td>20161228</td>\n",
       "      <td>468.0</td>\n",
       "      <td>nursing_hospital</td>\n",
       "      <td>1.004522e+09</td>\n",
       "      <td>515483669.0</td>\n",
       "      <td>4.472197e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>234.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>open</td>\n",
       "      <td>incheon</td>\n",
       "      <td>141</td>\n",
       "      <td>20000814</td>\n",
       "      <td>353.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>7.250734e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.067740e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.775501e+10</td>\n",
       "      <td>1.701860e+10</td>\n",
       "      <td>9.219427e+09</td>\n",
       "      <td>2.073641e+10</td>\n",
       "      <td>1.510000e+10</td>\n",
       "      <td>1.295427e+10</td>\n",
       "      <td>7.740829e+09</td>\n",
       "      <td>663.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>open</td>\n",
       "      <td>gyeongnam</td>\n",
       "      <td>32</td>\n",
       "      <td>20050901</td>\n",
       "      <td>196.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>4.904354e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.765605e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.143259e+10</td>\n",
       "      <td>3.007259e+10</td>\n",
       "      <td>1.759375e+10</td>\n",
       "      <td>2.136001e+10</td>\n",
       "      <td>1.410803e+10</td>\n",
       "      <td>5.561941e+06</td>\n",
       "      <td>9.025550e+09</td>\n",
       "      <td>206.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inst_id    OC       sido  sgg  openDate  bedCount          instkind  \\\n",
       "0        1  open  choongnam   73  20071228     175.0  nursing_hospital   \n",
       "1        3  open  gyeongnam   32  19970401     410.0  general_hospital   \n",
       "2        4  open   gyeonggi   89  20161228     468.0  nursing_hospital   \n",
       "3        7  open    incheon  141  20000814     353.0  general_hospital   \n",
       "4        9  open  gyeongnam   32  20050901     196.0  general_hospital   \n",
       "\n",
       "       revenue1   salescost1          sga1  ...         debt2  \\\n",
       "0  4.217530e+09          0.0  3.961135e+09  ...  7.589937e+08   \n",
       "1           NaN          NaN           NaN  ...           NaN   \n",
       "2  1.004522e+09  515483669.0  4.472197e+08  ...  0.000000e+00   \n",
       "3  7.250734e+10          0.0  7.067740e+10  ...  3.775501e+10   \n",
       "4  4.904354e+10          0.0  4.765605e+10  ...  5.143259e+10   \n",
       "\n",
       "   liquidLiabilities2    shortLoan2  NCLiabilities2     longLoan2  \\\n",
       "0        2.228769e+08  0.000000e+00    5.361169e+08  3.900000e+08   \n",
       "1                 NaN           NaN             NaN           NaN   \n",
       "2        0.000000e+00  0.000000e+00    0.000000e+00  0.000000e+00   \n",
       "3        1.701860e+10  9.219427e+09    2.073641e+10  1.510000e+10   \n",
       "4        3.007259e+10  1.759375e+10    2.136001e+10  1.410803e+10   \n",
       "\n",
       "      netAsset2      surplus2  employee1  employee2  ownerChange  \n",
       "0  2.619290e+09  1.271224e+09       62.0       64.0         same  \n",
       "1           NaN           NaN      801.0      813.0         same  \n",
       "2  0.000000e+00  0.000000e+00      234.0        1.0         same  \n",
       "3  1.295427e+10  7.740829e+09      663.0      663.0         same  \n",
       "4  5.561941e+06  9.025550e+09      206.0      197.0         same  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prod_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "      <th>sido</th>\n",
       "      <th>sgg</th>\n",
       "      <th>openDate</th>\n",
       "      <th>bedCount</th>\n",
       "      <th>instkind</th>\n",
       "      <th>revenue1</th>\n",
       "      <th>salescost1</th>\n",
       "      <th>sga1</th>\n",
       "      <th>...</th>\n",
       "      <th>debt2</th>\n",
       "      <th>liquidLiabilities2</th>\n",
       "      <th>shortLoan2</th>\n",
       "      <th>NCLiabilities2</th>\n",
       "      <th>longLoan2</th>\n",
       "      <th>netAsset2</th>\n",
       "      <th>surplus2</th>\n",
       "      <th>employee1</th>\n",
       "      <th>employee2</th>\n",
       "      <th>ownerChange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>incheon</td>\n",
       "      <td>139</td>\n",
       "      <td>19981125.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>6.682486e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.565709e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.540643e+10</td>\n",
       "      <td>5.068443e+10</td>\n",
       "      <td>3.714334e+10</td>\n",
       "      <td>4.720000e+09</td>\n",
       "      <td>4.690000e+09</td>\n",
       "      <td>1.608540e+10</td>\n",
       "      <td>8.944587e+09</td>\n",
       "      <td>693</td>\n",
       "      <td>693</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jeju</td>\n",
       "      <td>149</td>\n",
       "      <td>20160309.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>hospital</td>\n",
       "      <td>3.495758e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.259270e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>6.730838e+10</td>\n",
       "      <td>4.209828e+10</td>\n",
       "      <td>2.420000e+10</td>\n",
       "      <td>2.521009e+10</td>\n",
       "      <td>1.830000e+10</td>\n",
       "      <td>3.789135e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>379</td>\n",
       "      <td>371</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jeonnam</td>\n",
       "      <td>103</td>\n",
       "      <td>19890427.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>2.326031e+10</td>\n",
       "      <td>2.542571e+09</td>\n",
       "      <td>2.308749e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.777589e+10</td>\n",
       "      <td>2.182278e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.638540e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>busan</td>\n",
       "      <td>71</td>\n",
       "      <td>20100226.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.211517e+10</td>\n",
       "      <td>9.556237e+09</td>\n",
       "      <td>4.251867e+09</td>\n",
       "      <td>2.558931e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.914284e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jeonbuk</td>\n",
       "      <td>26</td>\n",
       "      <td>20040604.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>5.037025e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.855803e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>4.395973e+10</td>\n",
       "      <td>7.535567e+09</td>\n",
       "      <td>3.298427e+09</td>\n",
       "      <td>3.642417e+10</td>\n",
       "      <td>2.134712e+10</td>\n",
       "      <td>2.574488e+10</td>\n",
       "      <td>1.507269e+10</td>\n",
       "      <td>437</td>\n",
       "      <td>385</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inst_id  OC     sido  sgg    openDate  bedCount          instkind  \\\n",
       "0        2 NaN  incheon  139  19981125.0     300.0  general_hospital   \n",
       "1        5 NaN     jeju  149  20160309.0      44.0          hospital   \n",
       "2        6 NaN  jeonnam  103  19890427.0     276.0  general_hospital   \n",
       "3        8 NaN    busan   71  20100226.0     363.0  general_hospital   \n",
       "4       10 NaN  jeonbuk   26  20040604.0     213.0  general_hospital   \n",
       "\n",
       "       revenue1    salescost1          sga1  ...         debt2  \\\n",
       "0  6.682486e+10  0.000000e+00  6.565709e+10  ...  5.540643e+10   \n",
       "1  3.495758e+10  0.000000e+00  3.259270e+10  ...  6.730838e+10   \n",
       "2  2.326031e+10  2.542571e+09  2.308749e+10  ...  0.000000e+00   \n",
       "3  0.000000e+00  0.000000e+00  0.000000e+00  ...  1.211517e+10   \n",
       "4  5.037025e+10  0.000000e+00  4.855803e+10  ...  4.395973e+10   \n",
       "\n",
       "   liquidLiabilities2    shortLoan2  NCLiabilities2     longLoan2  \\\n",
       "0        5.068443e+10  3.714334e+10    4.720000e+09  4.690000e+09   \n",
       "1        4.209828e+10  2.420000e+10    2.521009e+10  1.830000e+10   \n",
       "2        2.777589e+10  2.182278e+10    0.000000e+00  0.000000e+00   \n",
       "3        9.556237e+09  4.251867e+09    2.558931e+09  0.000000e+00   \n",
       "4        7.535567e+09  3.298427e+09    3.642417e+10  2.134712e+10   \n",
       "\n",
       "      netAsset2      surplus2  employee1  employee2  ownerChange  \n",
       "0  1.608540e+10  8.944587e+09        693        693         same  \n",
       "1  3.789135e+09  0.000000e+00        379        371         same  \n",
       "2  0.000000e+00  1.638540e+10        NaN        NaN          NaN  \n",
       "3  3.914284e+10  0.000000e+00        760        760         same  \n",
       "4  2.574488e+10  1.507269e+10        437        385         same  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prod_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert 'employee' to numeric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the comma in the employee1 and 2 columns in the test dataset and replace it with empty space and convert it to float format.\n",
    "test_prod_df.employee1 = test_prod_df.employee1.astype('str').str.replace(\",\", \"\").astype('float')\n",
    "test_prod_df.employee2 = test_prod_df.employee2.astype('str').str.replace(\",\", \"\").astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the employee1 and 2 column as float in the train set as done for the test dataset\n",
    "train_prod_df.employee1 = train_prod_df.employee1.astype('float')\n",
    "train_prod_df.employee2 = train_prod_df.employee2.astype('float')\n",
    "train_prod_df.OC= train_prod_df.OC.astype('str').str.replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the empty values\n",
    "- Factor columns: Not_sure\n",
    "- Numeric columns: -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the train and test dataset\n",
    "train_test_prod = train_prod_df.append(test_prod_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428, 58)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_prod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the object and numeric columns seperately \n",
    "factor_columns = train_test_prod.select_dtypes(include = ['object']).columns\n",
    "numeric_columns = train_test_prod.columns.difference(factor_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OC', 'sido', 'instkind', 'ownerChange'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NCLiabilities1', 'NCLiabilities2', 'OnonCAsset1', 'OnonCAsset2',\n",
       "       'bedCount', 'ctax1', 'ctax2', 'debt1', 'debt2', 'employee1',\n",
       "       'employee2', 'inst_id', 'interest1', 'interest2', 'inventoryAsset1',\n",
       "       'inventoryAsset2', 'liquidAsset1', 'liquidAsset2', 'liquidLiabilities1',\n",
       "       'liquidLiabilities2', 'longLoan1', 'longLoan2', 'netAsset1',\n",
       "       'netAsset2', 'noe1', 'noe2', 'noi1', 'noi2', 'nonCAsset1', 'nonCAsset2',\n",
       "       'openDate', 'profit1', 'profit2', 'quickAsset1', 'quickAsset2',\n",
       "       'receivableL1', 'receivableL2', 'receivableS1', 'receivableS2',\n",
       "       'revenue1', 'revenue2', 'salary1', 'salary2', 'salescost1',\n",
       "       'salescost2', 'sga1', 'sga2', 'sgg', 'shortLoan1', 'shortLoan2',\n",
       "       'surplus1', 'surplus2', 'tanAsset1', 'tanAsset2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After analysis realized that the bed counts of these two hospitals may have had wrong entries.\n",
    "#Filling up the empty instkind and bedCount for hospital id 430 and 413\n",
    "train_test_prod.loc[train_test_prod.inst_id == 430, ['instkind']] = 'dental_clinic'\n",
    "train_test_prod.loc[train_test_prod.inst_id == 430, ['bedCount']] = 0\n",
    "train_test_prod.loc[train_test_prod.inst_id == 413, ['bedCount']] = -999\n",
    "\n",
    "#Fill the empty values in the object columns as \"Not sure\"\n",
    "train_test_prod[factor_columns] = train_test_prod[factor_columns].fillna('Not_sure')\n",
    "#Fill all the empty values in the numeric columns as -999\n",
    "train_test_prod[numeric_columns] = train_test_prod[numeric_columns].fillna(-999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the whole data into train and test set\n",
    "- dependent column: OC (0:close, 1:open)\n",
    "- independent columns: others\n",
    "\n",
    "\n",
    "- train_prod_X: train set with independent columns\n",
    "- train_prod_Y: train set with dependent column\n",
    "- test_prod_X: test set with independent columns\n",
    "- test_prod_Y: the objective of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#Convert all the object columns to numeric since the ML algorithms don't accept object features directly \n",
    "fac_le = LabelEncoder()\n",
    "train_test_prod[factor_columns] = train_test_prod.loc[:,factor_columns].apply(lambda x : fac_le.fit_transform(x))\n",
    "\n",
    "#Splitting back data to train prod and test prod\n",
    "#값이 있으면 train 데이터셋 값이 비어있으면 test 데이터셋 \n",
    "train_prod = train_test_prod.loc[train_test_prod.OC != 0,]\n",
    "test_prod = train_test_prod.loc[train_test_prod.OC == 0,]\n",
    "\n",
    "# 1,2 를 0,1로 바꾸기 (0이 폐업(close) 1이 폐업X(open))\n",
    "train_prod['OC'] = train_prod['OC'] - 1\n",
    "\n",
    "#Obtain the submission ID to create the submission file later\n",
    "sub_id = test_prod.inst_id\n",
    "\n",
    "#Get the dependent and independent column\n",
    "dep = 'OC'\n",
    "indep = train_prod.columns.difference([dep])\n",
    "\n",
    "train_prod_X = train_prod[indep]\n",
    "train_prod_Y = train_prod[dep]\n",
    "test_prod_X = test_prod[indep]\n",
    "#test_prod_Y = test_prod[dep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification Model(1) - Random Forest\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;분류/회귀예측에 이용되는 앙상블 기법 중 하나로, 대표적인 배깅 모형에 해당함<br><br>&nbsp;&nbsp;&nbsp;&nbsp;다수의 결정 트리를 구성한 뒤 평균 또는 과반수 투표 등을 이용하여 하나의 랜덤 포레스트로 결합함  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;A. Hyperparameter tuning of Random forest<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;B. Check the over-fitting of tuned model<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;C. Calculate the cut-off value for classification<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;D. Compare default model to tuned model<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Hyperparameter tuning of Random forest (using 3-fold cross validation)\n",
    "- n_estimators: The number of trees in the forest.\n",
    "- max_features: The number of features to consider when looking for the best split.\n",
    "- max_depth: The maximum depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 300, num = 10)] # Number of trees in random forest\n",
    "max_features = ['auto', 'sqrt'] # Number of features to consider at every split\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)] # Maximum number of levels in tree\n",
    "max_depth.append(None)\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 240 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=-1)]: Done 373 tasks      | elapsed:   58.7s\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100,\n",
       "                                       110, None],\n",
       "                         'max_features': ['auto', 'sqrt'],\n",
       "                         'n_estimators': [10, 42, 74, 106, 138, 171, 203, 235,\n",
       "                                          267, 300]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "np.random.seed(42)\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = GridSearchCV(estimator = rf, param_grid = random_grid, scoring = 'accuracy', cv = 3, verbose=2, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_prod_X, train_prod_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the best hyperparameter combination and train the random forest model with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'max_features': 'auto', 'n_estimators': 74}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.959459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.783784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.567568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.824324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.932432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>424</td>\n",
       "      <td>0.378378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>425</td>\n",
       "      <td>0.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>429</td>\n",
       "      <td>0.581081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>430</td>\n",
       "      <td>0.824324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>431</td>\n",
       "      <td>0.567568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     inst_id        OC\n",
       "0          2  0.959459\n",
       "1          5  0.783784\n",
       "2          6  0.567568\n",
       "3          8  0.824324\n",
       "4         10  0.932432\n",
       "..       ...       ...\n",
       "122      424  0.378378\n",
       "123      425  0.702703\n",
       "124      429  0.581081\n",
       "125      430  0.824324\n",
       "126      431  0.567568\n",
       "\n",
       "[127 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################################\n",
    "############ Random Forest with hyper-parameter tuning\n",
    "############################################################################\n",
    "estimators = rf_random.best_params_['n_estimators']\n",
    "max_depth_tune = rf_random.best_params_['max_depth']\n",
    "max_features_tune = rf_random.best_params_['max_features']\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "# 하이퍼파라미터 적용\n",
    "RF_prod_tune = RandomForestClassifier(n_estimators = estimators,\n",
    "                                max_depth = max_depth_tune,\n",
    "                                max_features = max_features_tune) \n",
    "\n",
    "# 훈련\n",
    "RF_prod_tune.fit(train_prod_X, train_prod_Y) \n",
    "\n",
    "# 결과: class가 0 or 1 \n",
    "RF_prod_predicted_tune = RF_prod_tune.predict(test_prod_X) \n",
    "\n",
    "# 결과: class 1에 속할 확률\n",
    "RF_prod_prediction_tune = RF_prod_tune.predict_proba(test_prod_X)[:,1] \n",
    "\n",
    "# 튜닝 후 예측 결과 출력\n",
    "sub_RF_tune = pd.DataFrame({'inst_id' : sub_id , 'OC' : RF_prod_prediction_tune })\n",
    "sub_RF_tune = sub_RF_tune[['inst_id', 'OC']]\n",
    "sub_RF_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Check the over-fitting of tuned model (using 5-fold cross validation)\n",
    "#### 하이퍼파라미터 튜닝 범위가 무작위로 설정되었기 때문에 튜닝 결과가 훈련 데이터에 과대적합되었을 가능성이 존재함<br><br>교차 검증을 통해 과대적합 여부를 확인한 결과, 모든 fold에서 적절한 분류 성능을 보이고 있었음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95081967 0.95       0.95       0.95       0.96666667]\n",
      "mean :  0.9534972677595629\n"
     ]
    }
   ],
   "source": [
    "# model, train, target, cross validation\n",
    "np.random.seed(10)\n",
    "scores = cross_val_score(RF_prod_tune, train_prod_X, train_prod_Y, cv=5) \n",
    "print(scores)\n",
    "print('mean : ',scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Calculate the cut-off value for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct the test set with real answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# 예측결과 0(close) 라벨링 \n",
    "close_idx = [5, 6, 24, 30 ,64, 123, 229, 258, 293, 341, 425, 429, 431]\n",
    "test_prod_labeled = test_prod[['inst_id', 'OC']] # 결과 라벨링 된 테스트 데이터프레임\n",
    "test_prod_labeled['OC'] = [0 if id in close_idx else 1 for id in test_prod['inst_id']] # 라벨링\n",
    "y_true = list(test_prod_labeled['OC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the optimal cut-off value (0.5~0.8 by 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 5\n",
    "end = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " cut-off value :  0.5\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.25      0.08      0.12        13\n",
      "       close       0.90      0.97      0.94       114\n",
      "\n",
      "    accuracy                           0.88       127\n",
      "   macro avg       0.58      0.53      0.53       127\n",
      "weighted avg       0.84      0.88      0.85       127\n",
      "\n",
      "0.8818897637795275\n",
      "============================================================\n",
      " cut-off value :  0.6\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.67      0.46      0.55        13\n",
      "       close       0.94      0.97      0.96       114\n",
      "\n",
      "    accuracy                           0.92       127\n",
      "   macro avg       0.80      0.72      0.75       127\n",
      "weighted avg       0.91      0.92      0.91       127\n",
      "\n",
      "0.9212598425196851\n",
      "============================================================\n",
      " cut-off value :  0.7\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.73      0.62      0.67        13\n",
      "       close       0.96      0.97      0.97       114\n",
      "\n",
      "    accuracy                           0.94       127\n",
      "   macro avg       0.84      0.79      0.82       127\n",
      "weighted avg       0.93      0.94      0.93       127\n",
      "\n",
      "0.937007874015748\n",
      "============================================================\n",
      " cut-off value :  0.8\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.62      1.00      0.76        13\n",
      "       close       1.00      0.93      0.96       114\n",
      "\n",
      "    accuracy                           0.94       127\n",
      "   macro avg       0.81      0.96      0.86       127\n",
      "weighted avg       0.96      0.94      0.94       127\n",
      "\n",
      "0.937007874015748\n"
     ]
    }
   ],
   "source": [
    "max_accuracy = -1\n",
    "coval_max = -1\n",
    "\n",
    "for i in range(start,end):\n",
    "    print('='*60)\n",
    "    coval = i/10\n",
    "    print(\" cut-off value : \" ,coval)\n",
    "    print('-'*22)\n",
    "\n",
    "    sub_RF_tune_ths = sub_RF_tune[['inst_id', 'OC']]\n",
    "    sub_RF_tune_ths['OC'] = [1 if oc>=coval else 0 for oc in sub_RF_tune_ths['OC']] # 확률값을 1,0으로 변환\n",
    "    y_prod = list(sub_RF_tune_ths['OC'])\n",
    "    \n",
    "    print(classification_report(y_true, y_prod, target_names=['open', 'close']))\n",
    "    print(accuracy_score(y_true,y_prod))\n",
    "        \n",
    "    if max_accuracy < accuracy_score(y_true,y_prod):\n",
    "        max_accuracy = accuracy_score(y_true,y_prod)\n",
    "        coval_max = coval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal cut-off value (according to 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_rf = coval_max\n",
    "cutoff_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Compare default model to tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defalut model\n",
    "- n_estimators: default\n",
    "- max_features: defalut\n",
    "- max_depth: defalut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ Random Forest\n",
    "############################################################################\n",
    "np.random.seed(100)\n",
    "RF_prod = RandomForestClassifier()\n",
    "RF_prod_model = RF_prod.fit(train_prod_X, train_prod_Y)\n",
    "RF_prod_prediction = RF_prod.predict_proba(test_prod_X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare 2 models with optimal cut-off value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_RF = pd.DataFrame({'inst_id' : sub_id , 'OC' : RF_prod_prediction })\n",
    "sub_RF = sub_RF[['inst_id', 'OC']]\n",
    "sub_RF['OC'] = [1 if oc>=cutoff_rf else 0 for oc in sub_RF['OC']]\n",
    "y_prod = list(sub_RF['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_RF_customized = sub_RF_tune[['inst_id', 'OC']]\n",
    "sub_RF_customized['OC'] = [1 if oc >= cutoff_rf else 0 for oc in sub_RF_customized['OC']] # 확률값을 1,0으로 변환\n",
    "y_prod_customized = list(sub_RF_customized['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Before tuned============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.75      0.69      0.72        13\n",
      "     class 1       0.97      0.97      0.97       114\n",
      "\n",
      "    accuracy                           0.94       127\n",
      "   macro avg       0.86      0.83      0.84       127\n",
      "weighted avg       0.94      0.94      0.94       127\n",
      "\n",
      "0.9448818897637795\n",
      "============After tuned============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.73      0.62      0.67        13\n",
      "     class 1       0.96      0.97      0.97       114\n",
      "\n",
      "    accuracy                           0.94       127\n",
      "   macro avg       0.84      0.79      0.82       127\n",
      "weighted avg       0.93      0.94      0.93       127\n",
      "\n",
      "0.937007874015748\n"
     ]
    }
   ],
   "source": [
    "# Before tuned\n",
    "print('============Before tuned============')\n",
    "print(classification_report(y_true, y_prod, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod))\n",
    "# After tuned\n",
    "print('============After tuned============')\n",
    "print(classification_report(y_true, y_prod_customized, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod_customized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification Model(2) - GBM\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;분류/회귀예측에 이용되는 앙상블 기법 중 하나로, 대표적인 부스팅 모형에 해당함<br><br>&nbsp;&nbsp;&nbsp;&nbsp;기존 타겟값과 그 residual을 예측하는 모형을 반복적으로 구성하고 결합함으로써 모형의 예측력을 높여가는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;A. Hyperparameter tuning of GBM<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;B. Check the over-fitting of tuned model<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;C. Calculate the cut-off value for classification<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;D. Compare default model to tuned model<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Hyperparameter tuning of GBM (using 5-fold cross validation)\n",
    "- n_estimators: The number of boosting stages to perform.\n",
    "- max_features: The number of features to consider when looking for the best split.\n",
    "- max_depth: The maximum depth of the individual estimators.\n",
    "- min_sample_split: The minimum number of samples required to split an internal node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=GradientBoostingClassifier(random_state=42,\n",
       "                                                  subsample=0.8),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': range(5, 9),\n",
       "                         'max_features': ['sqrt', 'auto'],\n",
       "                         'min_samples_split': range(2, 5),\n",
       "                         'n_estimators': range(60, 140, 10)},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'OC'\n",
    "IDcol = 'inst_id'\n",
    "\n",
    "predictors = [x for x in train_prod_X.columns if x not in [target, IDcol]]\n",
    "param_test1 = {'n_estimators':range(60,140,10), 'min_samples_split':range(2,5,1),'max_depth':range(5,9),'max_features':['sqrt','auto']}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, subsample=0.8,random_state=42), \n",
    "param_grid = param_test1, scoring='accuracy',n_jobs=-1, cv=5,  refit=True)\n",
    "\n",
    "gsearch1.fit(train_prod_X[predictors],train_prod_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the best hyperparameter combination and train the GBM model with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 60}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.725047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.709314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.999772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.999175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>424</td>\n",
       "      <td>0.004930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>425</td>\n",
       "      <td>0.106637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>429</td>\n",
       "      <td>0.048433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>430</td>\n",
       "      <td>0.999313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>431</td>\n",
       "      <td>0.048427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     inst_id        OC\n",
       "0          2  0.999751\n",
       "1          5  0.725047\n",
       "2          6  0.709314\n",
       "3          8  0.999772\n",
       "4         10  0.999175\n",
       "..       ...       ...\n",
       "122      424  0.004930\n",
       "123      425  0.106637\n",
       "124      429  0.048433\n",
       "125      430  0.999313\n",
       "126      431  0.048427\n",
       "\n",
       "[127 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################################\n",
    "############ GBM with hyper-parameter tuning\n",
    "############################################################################\n",
    "np.random.seed(42)\n",
    "estimators = gsearch1.best_estimator_.n_estimators\n",
    "max_depth=gsearch1.best_estimator_.max_depth\n",
    "max_features=gsearch1.best_estimator_.max_features\n",
    "min_samples_leaf=gsearch1.best_estimator_.min_samples_leaf\n",
    "n_estimators=gsearch1.best_estimator_.n_estimators\n",
    "random_state=gsearch1.best_estimator_.random_state\n",
    "\n",
    "GBM_prod_tune = GradientBoostingClassifier(n_estimators = estimators ,max_depth=max_depth, max_features=max_features,min_samples_leaf=min_samples_leaf,random_state = random_state )\n",
    "GBM_prod_model_tune = GBM_prod_tune.fit(train_prod_X, train_prod_Y)\n",
    "GBM_prod_prediction_tune = GBM_prod_tune.predict_proba(test_prod_X)[:,1]\n",
    "\n",
    "sub_GBM_tune = pd.DataFrame({'inst_id' : sub_id , 'OC' : GBM_prod_prediction_tune })\n",
    "sub_GBM_tune = sub_GBM_tune[['inst_id', 'OC']]\n",
    "sub_GBM_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Check the over-fitting of tuned model (using 5-fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM 함수를 만들고 교차 검증을 수행하는데 도움을 주는 함수\n",
    "def modelfit(alg, dtrain, predictors, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    global train_prod_Y\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors],train_prod_Y)\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    #Perform cross-validation:\n",
    "    if performCV:\n",
    "        cv_score = cross_val_score(alg, dtrain[predictors], train_prod_Y, cv=cv_folds, scoring='roc_auc')\n",
    "    \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % accuracy_score(train_prod_Y.values, dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % roc_auc_score(train_prod_Y, dtrain_predprob))\n",
    "    \n",
    "    if performCV:\n",
    "        print (\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "        \n",
    "    #Print Feature Importance:\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 1\n",
      "AUC Score (Train): 1.000000\n",
      "CV Score : Mean - 0.7814479 | Std - 0.1512598 | Min - 0.5877193 | Max - 0.9707602\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train_prod.columns if x not in [target,IDcol]]\n",
    "modelfit(GBM_prod_tune, train_prod_X, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Calculate the cut-off value for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the optimal cut-off value (0.5~0.8 by 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " cut-off value :  0.5\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.82      0.69      0.75        13\n",
      "       close       0.97      0.98      0.97       114\n",
      "\n",
      "    accuracy                           0.95       127\n",
      "   macro avg       0.89      0.84      0.86       127\n",
      "weighted avg       0.95      0.95      0.95       127\n",
      "\n",
      "0.952755905511811\n",
      "============================================================\n",
      " cut-off value :  0.6\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.82      0.69      0.75        13\n",
      "       close       0.97      0.98      0.97       114\n",
      "\n",
      "    accuracy                           0.95       127\n",
      "   macro avg       0.89      0.84      0.86       127\n",
      "weighted avg       0.95      0.95      0.95       127\n",
      "\n",
      "0.952755905511811\n",
      "============================================================\n",
      " cut-off value :  0.7\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.82      0.69      0.75        13\n",
      "       close       0.97      0.98      0.97       114\n",
      "\n",
      "    accuracy                           0.95       127\n",
      "   macro avg       0.89      0.84      0.86       127\n",
      "weighted avg       0.95      0.95      0.95       127\n",
      "\n",
      "0.952755905511811\n",
      "============================================================\n",
      " cut-off value :  0.8\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.85      0.85      0.85        13\n",
      "       close       0.98      0.98      0.98       114\n",
      "\n",
      "    accuracy                           0.97       127\n",
      "   macro avg       0.91      0.91      0.91       127\n",
      "weighted avg       0.97      0.97      0.97       127\n",
      "\n",
      "0.968503937007874\n"
     ]
    }
   ],
   "source": [
    "max_accuracy = -1\n",
    "coval_max = -1\n",
    "\n",
    "for i in range(start,end):\n",
    "    print('='*60)\n",
    "    coval = i/10\n",
    "    print(\" cut-off value : \" ,coval)\n",
    "    print('-'*22)\n",
    "\n",
    "    sub_GBM_tune_ths = sub_GBM_tune[['inst_id', 'OC']]\n",
    "    sub_GBM_tune_ths['OC'] = [1 if oc>=coval else 0 for oc in sub_GBM_tune_ths['OC']]\n",
    "    y_prod_tune = list(sub_GBM_tune_ths['OC'])\n",
    "    print(classification_report(y_true, y_prod_tune, target_names=['open', 'close']))\n",
    "    print(accuracy_score(y_true,y_prod_tune))\n",
    "\n",
    "    if max_accuracy < accuracy_score(y_true,y_prod_tune):\n",
    "        max_accuracy = accuracy_score(y_true,y_prod_tune)\n",
    "        coval_max = coval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal cut-off value (according to 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_GBM = coval_max\n",
    "cutoff_GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Compare orginal model to tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defalut model\n",
    "- n_estimators: default\n",
    "- max_features: default\n",
    "- max_depth: default\n",
    "- min_sample_split: default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ GBM\n",
    "############################################################################\n",
    "np.random.seed(100)\n",
    "GBM_prod = GradientBoostingClassifier()\n",
    "GBM_prod_model = GBM_prod.fit(train_prod_X, train_prod_Y)\n",
    "GBM_prod_prediction = GBM_prod.predict_proba(test_prod_X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare 2 models with optimal cut-off value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_GBM = pd.DataFrame({'inst_id' : sub_id , 'OC' : GBM_prod_prediction })\n",
    "sub_GBM = sub_GBM[['inst_id', 'OC']]\n",
    "sub_GBM['OC'] = [1 if oc>=cutoff_GBM else 0 for oc in sub_GBM['OC']]\n",
    "y_prod = list(sub_GBM['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_GBM_customized = sub_GBM_tune[['inst_id', 'OC']]\n",
    "sub_GBM_customized['OC'] = [1 if oc >= cutoff_GBM else 0 for oc in sub_GBM_customized['OC']] # 확률값을 1,0으로 변환\n",
    "y_prod_customized = list(sub_GBM_customized['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Before tuned============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.80      0.92      0.86        13\n",
      "     class 1       0.99      0.97      0.98       114\n",
      "\n",
      "    accuracy                           0.97       127\n",
      "   macro avg       0.90      0.95      0.92       127\n",
      "weighted avg       0.97      0.97      0.97       127\n",
      "\n",
      "0.968503937007874\n",
      "============After tuned============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.85      0.85      0.85        13\n",
      "     class 1       0.98      0.98      0.98       114\n",
      "\n",
      "    accuracy                           0.97       127\n",
      "   macro avg       0.91      0.91      0.91       127\n",
      "weighted avg       0.97      0.97      0.97       127\n",
      "\n",
      "0.968503937007874\n"
     ]
    }
   ],
   "source": [
    "# Before tuned\n",
    "print('============Before tuned============')\n",
    "print(classification_report(y_true, y_prod, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod))\n",
    "# After tuned\n",
    "print('============After tuned============')\n",
    "print(classification_report(y_true, y_prod_customized, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod_customized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification Model(3) -XGBOOST\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;GBM보다 속도와 성능이 향상된 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Hyperparameter tuning of XGBOOST (using 3-fold cross validation)\n",
    "- eta: The learning rate.\n",
    "- num_boost_round: The number of boosting rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_prod = xgb.DMatrix(data = train_prod_X, label = train_prod_Y)\n",
    "dtest_prod = xgb.DMatrix(data = test_prod_X)\n",
    "\n",
    "#Custom error function for the XGB model\n",
    "threshold = 0.5\n",
    "def eval_error(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = (preds > threshold ).astype('float')\n",
    "    return \"accuracy\", accuracy_score(labels, preds)\n",
    "    \n",
    "\n",
    "param_tmp = {'eta': [0.1, 0.2, 0.3, 0.4]}\n",
    "nrounds = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed:    2.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x0000022B7E6694A0>,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=1,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=4, param_grid={'eta': [0.1, 0.2, 0.3, 0.4]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier = XGBClassifier(objective='binary:logistic',nthread=1)\n",
    "skf = StratifiedKFold(n_splits=3, shuffle = True, random_state = 42)\n",
    "\n",
    "grid_search_XGB = GridSearchCV(xgb_classifier, param_grid = param_tmp, scoring='accuracy', n_jobs=4, cv=skf.split(train_prod_X, train_prod_Y), verbose=2)\n",
    "grid_search_XGB.fit(train_prod_X, train_prod_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the best hyperparameter combination and train the GBM model with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta': 0.3}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_XGB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ XGBOOST - tuning\n",
    "############################################################################\n",
    "np.random.seed(100)\n",
    "best_param = {'eta': grid_search_XGB.best_params_['eta']}\n",
    "\n",
    "xgb_model_tune = xgb.train(best_param, \n",
    "                      dtrain_prod, \n",
    "                      num_boost_round = nrounds ,\n",
    "                      feval = eval_error,\n",
    "                      #maximize = True,\n",
    "                      #early_stopping_rounds = 10,\n",
    "                      )\n",
    "\n",
    "XGB_prediction = xgb_model_tune.predict(dtest_prod)\n",
    "sub_XGB_tune= pd.DataFrame({'inst_id' : sub_id , 'OC' : XGB_prediction })\n",
    "sub_XGB_tune= sub_XGB_tune[['inst_id', 'OC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PLotting the feature importance\n",
    "xgb_Imp_tune = pd.DataFrame({'Features' : list(xgb_model_tune.get_score().keys()), \n",
    "                        'Importance' : list(xgb_model_tune.get_score().values())}).sort_values(['Importance'])\n",
    "plt.figure()\n",
    "sns.barplot(xgb_Imp_tune.Importance, xgb_Imp_tune.Features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Check the over-fitting of tuned model (using 5-fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95081967 0.95       0.95       0.95       0.95      ]\n",
      "mean :  0.9501639344262296\n"
     ]
    }
   ],
   "source": [
    "# model, train, target, cross validation\n",
    "np.random.seed(10)\n",
    "xgb_model_tune_clf = XGBClassifier(objective='binary:logistic',\n",
    "                                   learning_rate=grid_search_XGB.best_params_['eta'] )\n",
    "\n",
    "scores = cross_val_score(xgb_model_tune_clf, train_prod_X, train_prod_Y, cv=5) \n",
    "print(scores)\n",
    "print('mean : ',scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Calculate the cut-off value for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the optimal cut-off value (0.5~0.8 by 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " cut-off value :  0.5\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.75      0.92      0.83        13\n",
      "       close       0.99      0.96      0.98       114\n",
      "\n",
      "    accuracy                           0.96       127\n",
      "   macro avg       0.87      0.94      0.90       127\n",
      "weighted avg       0.97      0.96      0.96       127\n",
      "\n",
      "0.9606299212598425\n",
      "============================================================\n",
      " cut-off value :  0.6\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.67      0.92      0.77        13\n",
      "       close       0.99      0.95      0.97       114\n",
      "\n",
      "    accuracy                           0.94       127\n",
      "   macro avg       0.83      0.94      0.87       127\n",
      "weighted avg       0.96      0.94      0.95       127\n",
      "\n",
      "0.9448818897637795\n",
      "============================================================\n",
      " cut-off value :  0.7\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.57      1.00      0.72        13\n",
      "       close       1.00      0.91      0.95       114\n",
      "\n",
      "    accuracy                           0.92       127\n",
      "   macro avg       0.78      0.96      0.84       127\n",
      "weighted avg       0.96      0.92      0.93       127\n",
      "\n",
      "0.9212598425196851\n",
      "============================================================\n",
      " cut-off value :  0.8\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.10      1.00      0.19        13\n",
      "       close       0.00      0.00      0.00       114\n",
      "\n",
      "    accuracy                           0.10       127\n",
      "   macro avg       0.05      0.50      0.09       127\n",
      "weighted avg       0.01      0.10      0.02       127\n",
      "\n",
      "0.10236220472440945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "max_accuracy = -1\n",
    "coval_max = -1\n",
    "for i in range(start,end):\n",
    "    print('='*60)\n",
    "    coval = i/10\n",
    "    print(\" cut-off value : \" ,coval)\n",
    "    print('-'*22)\n",
    "\n",
    "    sub_XGB_tune_ths = sub_XGB_tune[['inst_id', 'OC']]\n",
    "    sub_XGB_tune_ths['OC'] = [1 if oc>=coval else 0 for oc in sub_XGB_tune_ths['OC']]\n",
    "    y_prod = list(sub_XGB_tune_ths['OC'])\n",
    "    print(classification_report(y_true, y_prod, target_names=['open', 'close']))\n",
    "    acc= accuracy_score(y_true,y_prod)\n",
    "    print(acc)\n",
    "    if max_accuracy < acc:\n",
    "        max_accuracy = acc\n",
    "        coval_max = coval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal cut-off value (according to 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_XGB = coval_max\n",
    "cutoff_XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Compare orginal model to tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defalut model\n",
    "- eta: default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ XGBOOST\n",
    "############################################################################\n",
    "XGB_prod = XGBClassifier()\n",
    "XGB_prod.fit(train_prod_X, train_prod_Y)\n",
    "XGB_prod_prediction = XGB_prod.predict_proba(test_prod_X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare 2 models with optimal cut-off value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_XGB= pd.DataFrame({'inst_id' : sub_id , 'OC' : XGB_prediction })\n",
    "sub_XGB= sub_XGB[['inst_id', 'OC']]\n",
    "sub_XGB['OC'] = [1 if oc>=cutoff_XGB else 0 for oc in sub_XGB['OC']]\n",
    "y_prod = list(sub_XGB['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_XGB_customized = sub_XGB_tune[['inst_id', 'OC']]\n",
    "sub_XGB_customized['OC'] = [1 if oc >= cutoff_XGB else 0 for oc in sub_XGB_customized['OC']] # 확률값을 1,0으로 변환\n",
    "y_prod_customized = list(sub_XGB_customized['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Before tuned============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.75      0.92      0.83        13\n",
      "     class 1       0.99      0.96      0.98       114\n",
      "\n",
      "    accuracy                           0.96       127\n",
      "   macro avg       0.87      0.94      0.90       127\n",
      "weighted avg       0.97      0.96      0.96       127\n",
      "\n",
      "0.9606299212598425\n",
      "============After tuned============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.75      0.92      0.83        13\n",
      "     class 1       0.99      0.96      0.98       114\n",
      "\n",
      "    accuracy                           0.96       127\n",
      "   macro avg       0.87      0.94      0.90       127\n",
      "weighted avg       0.97      0.96      0.96       127\n",
      "\n",
      "0.9606299212598425\n"
     ]
    }
   ],
   "source": [
    "# Before tuned\n",
    "print('============Before tuned============')\n",
    "print(classification_report(y_true, y_prod, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod))\n",
    "# After tuned\n",
    "print('============After tuned============')\n",
    "print(classification_report(y_true, y_prod_customized, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod_customized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고사이트   \n",
    "1. Random forest   \n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "2. GBM   \n",
    "https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "\n",
    "3. xgboost   \n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
