{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge shap\n",
    "# pip install xgboost\n",
    "# pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>병원 개/폐업 분류예측 프로젝트</h1></center><br>\n",
    "\n",
    "---\n",
    "<h4>1. 주제 및 목표</h4>\n",
    "- 병원 폐업 여부를 예측하여 대출 승인여부 결정\n",
    "\n",
    "<h4>2. 배경</h4>\n",
    "- 한국 핀테크 기업 모우다(MOUDA): 상환기간 동안의 계속 경영 여부를 예측하여 병원들에게 금융 기회를 제공\n",
    "- 일반적으로 병원 대출 시 신용점수 또는 담보물을 위주로 평가를 진행했던 기존 금융기관과의 차별점\n",
    "- 신용 점수가 낮거나 담보를 가지지 못하는 우수 병원들에게도 금융 기회를 제공하자는 취지\n",
    "\n",
    "<h4>3. 활용 데이터</h4>\n",
    "- 의료기관의 폐업 여부가 포함된 최근 2개년의 재무정보와 병원 기본정보 \n",
    "- (출처) Dacon 병원 개/폐업 분류 예측 경진대회 (https://dacon.io/competitions/official/9565/data/)\n",
    "- 데이터 설명\n",
    "> - <병원 기본정보>\n",
    "> - inst_id: 병원 고유 번호<br>\n",
    "> - OC: 영업/폐업 분류<br>\n",
    "> - sido: 병원의 광역 지역 정보<br>\n",
    "> - sgg: 병원의 시군구 자료<br>\n",
    "> - openDate: 병원 설립일<br> \n",
    "> - bedcount: 병원이 갖추고 있는 병상의 수<br>\n",
    "> - instkind: 병원, 의원, 요양병원, 한의원, 종합병원 등 병원의 종류<br><br>\n",
    "> - <재무정보> 1: 2017 회계년도, 2: 2016 회계년도\n",
    "> - revenue1(2): 매출액<br>\n",
    "> - salescost1(2): 매출원가<br>\n",
    "> - sga1(2): 판매비와 관리비<br>\n",
    "> - salary1(2): 급여<br>\n",
    "> - noi1(2): 영업외수익<br>\n",
    "> - noe1(2): 영업외비용<br>\n",
    "> - Interest1(2): 이자비용<br>\n",
    "> - ctax1(2): 법인세비용<br>\n",
    "> - Profit1(2): 당기순이익<br>\n",
    "> - liquidAsset1(2): 유동자산<br>\n",
    "> - quickAsset1(2): 당좌자산<br>\n",
    "> - receivableS1(2): 미수금(단기)<br>\n",
    "> - inventoryAsset1(2): 재고자산<br>\n",
    "> - nonCAsset1(2): 비유동자산<br>\n",
    "> - tanAsset1(2): 유형자산<br>\n",
    "> - OnonCAseet1(2): 기타 비유동자산<br>\n",
    "> - receivableL1(2): 장기미수금<br>\n",
    "> - debt1(2): 부채총계<br>\n",
    "> - liquidLiabilities1(2): 유동부채<br>\n",
    "> - shortLoan1(2): 단기차입금<br>\n",
    "> - NCLiabilities1(2): 비유동부채<br>\n",
    "> - longLoan1(2): 장기차입금<br>\n",
    "> - netAsset1(2): 순자산총계<br>\n",
    "> - surplus1(2): 이익잉여금\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the train and test files\n",
    "train_prod_df = pd.read_csv('data\\\\train.csv') # 학습데이터\n",
    "test_prod_df = pd.read_csv('data\\\\test_empty.csv') # 테스트데이터 (결과값 비어있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "      <th>sido</th>\n",
       "      <th>sgg</th>\n",
       "      <th>openDate</th>\n",
       "      <th>bedCount</th>\n",
       "      <th>instkind</th>\n",
       "      <th>revenue1</th>\n",
       "      <th>salescost1</th>\n",
       "      <th>sga1</th>\n",
       "      <th>...</th>\n",
       "      <th>debt2</th>\n",
       "      <th>liquidLiabilities2</th>\n",
       "      <th>shortLoan2</th>\n",
       "      <th>NCLiabilities2</th>\n",
       "      <th>longLoan2</th>\n",
       "      <th>netAsset2</th>\n",
       "      <th>surplus2</th>\n",
       "      <th>employee1</th>\n",
       "      <th>employee2</th>\n",
       "      <th>ownerChange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>open</td>\n",
       "      <td>choongnam</td>\n",
       "      <td>73</td>\n",
       "      <td>20071228</td>\n",
       "      <td>175.0</td>\n",
       "      <td>nursing_hospital</td>\n",
       "      <td>4.217530e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.961135e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>7.589937e+08</td>\n",
       "      <td>2.228769e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.361169e+08</td>\n",
       "      <td>3.900000e+08</td>\n",
       "      <td>2.619290e+09</td>\n",
       "      <td>1.271224e+09</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>open</td>\n",
       "      <td>gyeongnam</td>\n",
       "      <td>32</td>\n",
       "      <td>19970401</td>\n",
       "      <td>410.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>801.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>open</td>\n",
       "      <td>gyeonggi</td>\n",
       "      <td>89</td>\n",
       "      <td>20161228</td>\n",
       "      <td>468.0</td>\n",
       "      <td>nursing_hospital</td>\n",
       "      <td>1.004522e+09</td>\n",
       "      <td>515483669.0</td>\n",
       "      <td>4.472197e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>234.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>open</td>\n",
       "      <td>incheon</td>\n",
       "      <td>141</td>\n",
       "      <td>20000814</td>\n",
       "      <td>353.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>7.250734e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.067740e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.775501e+10</td>\n",
       "      <td>1.701860e+10</td>\n",
       "      <td>9.219427e+09</td>\n",
       "      <td>2.073641e+10</td>\n",
       "      <td>1.510000e+10</td>\n",
       "      <td>1.295427e+10</td>\n",
       "      <td>7.740829e+09</td>\n",
       "      <td>663.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>open</td>\n",
       "      <td>gyeongnam</td>\n",
       "      <td>32</td>\n",
       "      <td>20050901</td>\n",
       "      <td>196.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>4.904354e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.765605e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.143259e+10</td>\n",
       "      <td>3.007259e+10</td>\n",
       "      <td>1.759375e+10</td>\n",
       "      <td>2.136001e+10</td>\n",
       "      <td>1.410803e+10</td>\n",
       "      <td>5.561941e+06</td>\n",
       "      <td>9.025550e+09</td>\n",
       "      <td>206.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inst_id    OC       sido  sgg  openDate  bedCount          instkind  \\\n",
       "0        1  open  choongnam   73  20071228     175.0  nursing_hospital   \n",
       "1        3  open  gyeongnam   32  19970401     410.0  general_hospital   \n",
       "2        4  open   gyeonggi   89  20161228     468.0  nursing_hospital   \n",
       "3        7  open    incheon  141  20000814     353.0  general_hospital   \n",
       "4        9  open  gyeongnam   32  20050901     196.0  general_hospital   \n",
       "\n",
       "       revenue1   salescost1          sga1  ...         debt2  \\\n",
       "0  4.217530e+09          0.0  3.961135e+09  ...  7.589937e+08   \n",
       "1           NaN          NaN           NaN  ...           NaN   \n",
       "2  1.004522e+09  515483669.0  4.472197e+08  ...  0.000000e+00   \n",
       "3  7.250734e+10          0.0  7.067740e+10  ...  3.775501e+10   \n",
       "4  4.904354e+10          0.0  4.765605e+10  ...  5.143259e+10   \n",
       "\n",
       "   liquidLiabilities2    shortLoan2  NCLiabilities2     longLoan2  \\\n",
       "0        2.228769e+08  0.000000e+00    5.361169e+08  3.900000e+08   \n",
       "1                 NaN           NaN             NaN           NaN   \n",
       "2        0.000000e+00  0.000000e+00    0.000000e+00  0.000000e+00   \n",
       "3        1.701860e+10  9.219427e+09    2.073641e+10  1.510000e+10   \n",
       "4        3.007259e+10  1.759375e+10    2.136001e+10  1.410803e+10   \n",
       "\n",
       "      netAsset2      surplus2  employee1  employee2  ownerChange  \n",
       "0  2.619290e+09  1.271224e+09       62.0       64.0         same  \n",
       "1           NaN           NaN      801.0      813.0         same  \n",
       "2  0.000000e+00  0.000000e+00      234.0        1.0         same  \n",
       "3  1.295427e+10  7.740829e+09      663.0      663.0         same  \n",
       "4  5.561941e+06  9.025550e+09      206.0      197.0         same  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prod_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "      <th>sido</th>\n",
       "      <th>sgg</th>\n",
       "      <th>openDate</th>\n",
       "      <th>bedCount</th>\n",
       "      <th>instkind</th>\n",
       "      <th>revenue1</th>\n",
       "      <th>salescost1</th>\n",
       "      <th>sga1</th>\n",
       "      <th>...</th>\n",
       "      <th>debt2</th>\n",
       "      <th>liquidLiabilities2</th>\n",
       "      <th>shortLoan2</th>\n",
       "      <th>NCLiabilities2</th>\n",
       "      <th>longLoan2</th>\n",
       "      <th>netAsset2</th>\n",
       "      <th>surplus2</th>\n",
       "      <th>employee1</th>\n",
       "      <th>employee2</th>\n",
       "      <th>ownerChange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>incheon</td>\n",
       "      <td>139</td>\n",
       "      <td>19981125.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>6.682486e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.565709e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.540643e+10</td>\n",
       "      <td>5.068443e+10</td>\n",
       "      <td>3.714334e+10</td>\n",
       "      <td>4.720000e+09</td>\n",
       "      <td>4.690000e+09</td>\n",
       "      <td>1.608540e+10</td>\n",
       "      <td>8.944587e+09</td>\n",
       "      <td>693</td>\n",
       "      <td>693</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jeju</td>\n",
       "      <td>149</td>\n",
       "      <td>20160309.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>hospital</td>\n",
       "      <td>3.495758e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.259270e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>6.730838e+10</td>\n",
       "      <td>4.209828e+10</td>\n",
       "      <td>2.420000e+10</td>\n",
       "      <td>2.521009e+10</td>\n",
       "      <td>1.830000e+10</td>\n",
       "      <td>3.789135e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>379</td>\n",
       "      <td>371</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jeonnam</td>\n",
       "      <td>103</td>\n",
       "      <td>19890427.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>2.326031e+10</td>\n",
       "      <td>2.542571e+09</td>\n",
       "      <td>2.308749e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.777589e+10</td>\n",
       "      <td>2.182278e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.638540e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>busan</td>\n",
       "      <td>71</td>\n",
       "      <td>20100226.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.211517e+10</td>\n",
       "      <td>9.556237e+09</td>\n",
       "      <td>4.251867e+09</td>\n",
       "      <td>2.558931e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.914284e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jeonbuk</td>\n",
       "      <td>26</td>\n",
       "      <td>20040604.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>5.037025e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.855803e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>4.395973e+10</td>\n",
       "      <td>7.535567e+09</td>\n",
       "      <td>3.298427e+09</td>\n",
       "      <td>3.642417e+10</td>\n",
       "      <td>2.134712e+10</td>\n",
       "      <td>2.574488e+10</td>\n",
       "      <td>1.507269e+10</td>\n",
       "      <td>437</td>\n",
       "      <td>385</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inst_id  OC     sido  sgg    openDate  bedCount          instkind  \\\n",
       "0        2 NaN  incheon  139  19981125.0     300.0  general_hospital   \n",
       "1        5 NaN     jeju  149  20160309.0      44.0          hospital   \n",
       "2        6 NaN  jeonnam  103  19890427.0     276.0  general_hospital   \n",
       "3        8 NaN    busan   71  20100226.0     363.0  general_hospital   \n",
       "4       10 NaN  jeonbuk   26  20040604.0     213.0  general_hospital   \n",
       "\n",
       "       revenue1    salescost1          sga1  ...         debt2  \\\n",
       "0  6.682486e+10  0.000000e+00  6.565709e+10  ...  5.540643e+10   \n",
       "1  3.495758e+10  0.000000e+00  3.259270e+10  ...  6.730838e+10   \n",
       "2  2.326031e+10  2.542571e+09  2.308749e+10  ...  0.000000e+00   \n",
       "3  0.000000e+00  0.000000e+00  0.000000e+00  ...  1.211517e+10   \n",
       "4  5.037025e+10  0.000000e+00  4.855803e+10  ...  4.395973e+10   \n",
       "\n",
       "   liquidLiabilities2    shortLoan2  NCLiabilities2     longLoan2  \\\n",
       "0        5.068443e+10  3.714334e+10    4.720000e+09  4.690000e+09   \n",
       "1        4.209828e+10  2.420000e+10    2.521009e+10  1.830000e+10   \n",
       "2        2.777589e+10  2.182278e+10    0.000000e+00  0.000000e+00   \n",
       "3        9.556237e+09  4.251867e+09    2.558931e+09  0.000000e+00   \n",
       "4        7.535567e+09  3.298427e+09    3.642417e+10  2.134712e+10   \n",
       "\n",
       "      netAsset2      surplus2  employee1  employee2  ownerChange  \n",
       "0  1.608540e+10  8.944587e+09        693        693         same  \n",
       "1  3.789135e+09  0.000000e+00        379        371         same  \n",
       "2  0.000000e+00  1.638540e+10        NaN        NaN          NaN  \n",
       "3  3.914284e+10  0.000000e+00        760        760         same  \n",
       "4  2.574488e+10  1.507269e+10        437        385         same  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prod_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert 'employee' to numeric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the comma in the employee1 and 2 columns in the test dataset and replace it with empty space and convert it to float format.\n",
    "test_prod_df.employee1 = test_prod_df.employee1.astype('str').str.replace(\",\", \"\").astype('float')\n",
    "test_prod_df.employee2 = test_prod_df.employee2.astype('str').str.replace(\",\", \"\").astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the employee1 and 2 column as float in the train set as done for the test dataset\n",
    "train_prod_df.employee1 = train_prod_df.employee1.astype('float')\n",
    "train_prod_df.employee2 = train_prod_df.employee2.astype('float')\n",
    "train_prod_df.OC= train_prod_df.OC.astype('str').str.replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the empty values\n",
    "- Factor columns: Not_sure\n",
    "- Numeric columns: -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the train and test dataset\n",
    "train_test_prod = train_prod_df.append(test_prod_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428, 58)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_prod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the object and numeric columns seperately \n",
    "factor_columns = train_test_prod.select_dtypes(include = ['object']).columns\n",
    "numeric_columns = train_test_prod.columns.difference(factor_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OC', 'sido', 'instkind', 'ownerChange'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NCLiabilities1', 'NCLiabilities2', 'OnonCAsset1', 'OnonCAsset2',\n",
       "       'bedCount', 'ctax1', 'ctax2', 'debt1', 'debt2', 'employee1',\n",
       "       'employee2', 'inst_id', 'interest1', 'interest2', 'inventoryAsset1',\n",
       "       'inventoryAsset2', 'liquidAsset1', 'liquidAsset2', 'liquidLiabilities1',\n",
       "       'liquidLiabilities2', 'longLoan1', 'longLoan2', 'netAsset1',\n",
       "       'netAsset2', 'noe1', 'noe2', 'noi1', 'noi2', 'nonCAsset1', 'nonCAsset2',\n",
       "       'openDate', 'profit1', 'profit2', 'quickAsset1', 'quickAsset2',\n",
       "       'receivableL1', 'receivableL2', 'receivableS1', 'receivableS2',\n",
       "       'revenue1', 'revenue2', 'salary1', 'salary2', 'salescost1',\n",
       "       'salescost2', 'sga1', 'sga2', 'sgg', 'shortLoan1', 'shortLoan2',\n",
       "       'surplus1', 'surplus2', 'tanAsset1', 'tanAsset2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After analysis realized that the bed counts of these two hospitals may have had wrong entries.\n",
    "#Filling up the empty instkind and bedCount for hospital id 430 and 413\n",
    "train_test_prod.loc[train_test_prod.inst_id == 430, ['instkind']] = 'dental_clinic'\n",
    "train_test_prod.loc[train_test_prod.inst_id == 430, ['bedCount']] = 0\n",
    "train_test_prod.loc[train_test_prod.inst_id == 413, ['bedCount']] = -999\n",
    "\n",
    "#Fill the empty values in the object columns as \"Not sure\"\n",
    "train_test_prod[factor_columns] = train_test_prod[factor_columns].fillna('Not_sure')\n",
    "#Fill all the empty values in the numeric columns as -999\n",
    "train_test_prod[numeric_columns] = train_test_prod[numeric_columns].fillna(-999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the whole data into train and test set\n",
    "- dependent column: OC (0:close, 1:open)\n",
    "- independent columns: others\n",
    "\n",
    "\n",
    "- train_prod_X: train set with independent columns\n",
    "- train_prod_Y: train set with dependent column\n",
    "- test_prod_X: test set with independent columns\n",
    "- test_prod_Y: the objective of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#Convert all the object columns to numeric since the ML algorithms don't accept object features directly \n",
    "fac_le = LabelEncoder()\n",
    "train_test_prod[factor_columns] = train_test_prod.loc[:,factor_columns].apply(lambda x : fac_le.fit_transform(x))\n",
    "\n",
    "#Splitting back data to train prod and test prod\n",
    "#값이 있으면 train 데이터셋 값이 비어있으면 test 데이터셋 \n",
    "train_prod = train_test_prod.loc[train_test_prod.OC != 0,]\n",
    "test_prod = train_test_prod.loc[train_test_prod.OC == 0,]\n",
    "\n",
    "# 1,2 를 0,1로 바꾸기 (0이 폐업(close) 1이 폐업X(open))\n",
    "train_prod['OC'] = train_prod['OC'] - 1\n",
    "\n",
    "#Obtain the submission ID to create the submission file later\n",
    "sub_id = test_prod.inst_id\n",
    "\n",
    "#Get the dependent and independent column\n",
    "dep = 'OC'\n",
    "indep = train_prod.columns.difference([dep])\n",
    "\n",
    "train_prod_X = train_prod[indep]\n",
    "train_prod_Y = train_prod[dep]\n",
    "test_prod_X = test_prod[indep]\n",
    "#test_prod_Y = test_prod[dep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification Model(1) - Random Forest\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;분류/회귀예측에 이용되는 앙상블 기법 중 하나로, 대표적인 배깅 모형에 해당함<br><br>&nbsp;&nbsp;&nbsp;&nbsp;다수의 결정 트리를 구성한 뒤 평균 또는 과반수 투표 등을 이용하여 하나의 랜덤 포레스트로 결합함  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;A. Hyperparameter tuning of Random forest<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;B. Check the over-fitting of tuned model<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;C. Calculate the cut-off value for classification<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;D. Compare default model to tuned model<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Hyperparameter tuning of Random forest (using 3-fold cross validation)\n",
    "- n_estimators: The number of trees in the forest.\n",
    "- max_features: The number of features to consider when looking for the best split.\n",
    "- max_depth: The maximum depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 300, num = 10)] # Number of trees in random forest\n",
    "max_features = ['auto', 'sqrt'] # Number of features to consider at every split\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)] # Maximum number of levels in tree\n",
    "max_depth.append(None)\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 240 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100,\n",
       "                                       110, None],\n",
       "                         'max_features': ['auto', 'sqrt'],\n",
       "                         'n_estimators': [10, 42, 74, 106, 138, 171, 203, 235,\n",
       "                                          267, 300]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "np.random.seed(100)\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = GridSearchCV(estimator = rf, param_grid = random_grid, scoring = 'accuracy', cv = 3, verbose=2, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_prod_X, train_prod_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the best hyperparameter combination and train the random forest model with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'max_features': 'auto', 'n_estimators': 42}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>424</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>425</td>\n",
       "      <td>0.690476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>429</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>430</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>431</td>\n",
       "      <td>0.547619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     inst_id        OC\n",
       "0          2  0.952381\n",
       "1          5  0.785714\n",
       "2          6  0.619048\n",
       "3          8  0.833333\n",
       "4         10  0.952381\n",
       "..       ...       ...\n",
       "122      424  0.357143\n",
       "123      425  0.690476\n",
       "124      429  0.571429\n",
       "125      430  0.857143\n",
       "126      431  0.547619\n",
       "\n",
       "[127 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################################\n",
    "############ Random Forest with hyper-parameter tuning\n",
    "############################################################################\n",
    "estimators = rf_random.best_params_['n_estimators']\n",
    "max_depth_tune = rf_random.best_params_['max_depth']\n",
    "max_features_tune = rf_random.best_params_['max_features']\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "# 하이퍼파라미터 적용\n",
    "RF_prod_tune = RandomForestClassifier(n_estimators = estimators,\n",
    "                                max_depth = max_depth_tune,\n",
    "                                max_features = max_features_tune) \n",
    "\n",
    "# 훈련\n",
    "RF_prod_tune.fit(train_prod_X, train_prod_Y) \n",
    "\n",
    "# 결과: class가 0 or 1 \n",
    "RF_prod_predicted_tune = RF_prod_tune.predict(test_prod_X) \n",
    "\n",
    "# 결과: class 1에 속할 확률\n",
    "RF_prod_prediction_tune = RF_prod_tune.predict_proba(test_prod_X)[:,1] \n",
    "\n",
    "# 튜닝 후 예측 결과 출력\n",
    "sub_RF_tune = pd.DataFrame({'inst_id' : sub_id , 'OC' : RF_prod_prediction_tune })\n",
    "sub_RF_tune = sub_RF_tune[['inst_id', 'OC']]\n",
    "sub_RF_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Check the over-fitting of tuned model (using 5-fold cross validation)\n",
    "#### 하이퍼파라미터 튜닝 범위가 무작위로 설정되었기 때문에 튜닝 결과가 훈련 데이터에 과대적합되었을 가능성이 존재함<br><br>교차 검증을 통해 과대적합 여부를 확인한 결과, 모든 fold에서 적절한 분류 성능을 보이고 있었음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93442623 0.95       0.95       0.95       0.93333333]\n",
      "mean :  0.9435519125683062\n"
     ]
    }
   ],
   "source": [
    "# model, train, target, cross validation\n",
    "np.random.seed(10)\n",
    "scores = cross_val_score(RF_prod_tune, train_prod_X, train_prod_Y, cv=5) \n",
    "print(scores)\n",
    "print('mean : ',scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Calculate the cut-off value for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct the test set with real answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# 예측결과 0(close) 라벨링 \n",
    "close_idx = [5, 6, 24, 30 ,64, 123, 229, 258, 293, 341, 425, 429, 431]\n",
    "test_prod_labeled = test_prod[['inst_id', 'OC']] # 결과 라벨링 된 테스트 데이터프레임\n",
    "test_prod_labeled['OC'] = [0 if id in close_idx else 1 for id in test_prod['inst_id']] # 라벨링\n",
    "y_true = list(test_prod_labeled['OC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the optimal cut-off value (0.5~0.8 by 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 5\n",
    "end = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " cut-off value :  0.5\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.33      0.08      0.12        13\n",
      "       close       0.90      0.98      0.94       114\n",
      "\n",
      "    accuracy                           0.89       127\n",
      "   macro avg       0.62      0.53      0.53       127\n",
      "weighted avg       0.84      0.89      0.86       127\n",
      "\n",
      "0.889763779527559\n",
      "============================================================\n",
      " cut-off value :  0.6\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.67      0.46      0.55        13\n",
      "       close       0.94      0.97      0.96       114\n",
      "\n",
      "    accuracy                           0.92       127\n",
      "   macro avg       0.80      0.72      0.75       127\n",
      "weighted avg       0.91      0.92      0.91       127\n",
      "\n",
      "0.9212598425196851\n",
      "============================================================\n",
      " cut-off value :  0.7\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.77      0.77      0.77        13\n",
      "       close       0.97      0.97      0.97       114\n",
      "\n",
      "    accuracy                           0.95       127\n",
      "   macro avg       0.87      0.87      0.87       127\n",
      "weighted avg       0.95      0.95      0.95       127\n",
      "\n",
      "0.952755905511811\n",
      "============================================================\n",
      " cut-off value :  0.8\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.65      1.00      0.79        13\n",
      "       close       1.00      0.94      0.97       114\n",
      "\n",
      "    accuracy                           0.94       127\n",
      "   macro avg       0.82      0.97      0.88       127\n",
      "weighted avg       0.96      0.94      0.95       127\n",
      "\n",
      "0.9448818897637795\n"
     ]
    }
   ],
   "source": [
    "max_accuracy = -1\n",
    "coval_max = -1\n",
    "\n",
    "for i in range(start,end):\n",
    "    print('='*60)\n",
    "    coval = i/10\n",
    "    print(\" cut-off value : \" ,coval)\n",
    "    print('-'*22)\n",
    "\n",
    "    sub_RF_tune_ths = sub_RF_tune[['inst_id', 'OC']]\n",
    "    sub_RF_tune_ths['OC'] = [1 if oc>=coval else 0 for oc in sub_RF_tune_ths['OC']] # 확률값을 1,0으로 변환\n",
    "    y_prod = list(sub_RF_tune_ths['OC'])\n",
    "    \n",
    "    print(classification_report(y_true, y_prod, target_names=['open', 'close']))\n",
    "    print(accuracy_score(y_true,y_prod))\n",
    "        \n",
    "    if max_accuracy < accuracy_score(y_true,y_prod):\n",
    "        max_accuracy = accuracy_score(y_true,y_prod)\n",
    "        coval_max = coval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal cut-off value (according to 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_rf = coval_max\n",
    "cutoff_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Compare default model to tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defalut model\n",
    "- n_estimators: default\n",
    "- max_features: defalut\n",
    "- max_depth: defalut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ Random Forest\n",
    "############################################################################\n",
    "np.random.seed(100)\n",
    "RF_prod = RandomForestClassifier()\n",
    "RF_prod_model = RF_prod.fit(train_prod_X, train_prod_Y)\n",
    "RF_prod_prediction = RF_prod.predict_proba(test_prod_X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare 2 models with optimal cut-off value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_RF = pd.DataFrame({'inst_id' : sub_id , 'OC' : RF_prod_prediction })\n",
    "sub_RF = sub_RF[['inst_id', 'OC']]\n",
    "sub_RF['OC'] = [1 if oc>=cutoff_rf else 0 for oc in sub_RF['OC']]\n",
    "y_prod = list(sub_RF['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_RF_customized = sub_RF_tune[['inst_id', 'OC']]\n",
    "sub_RF_customized['OC'] = [1 if oc >= cutoff_rf else 0 for oc in sub_RF_customized['OC']] # 확률값을 1,0으로 변환\n",
    "y_prod_customized = list(sub_RF_customized['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Before tuned============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.75      0.69      0.72        13\n",
      "     class 1       0.97      0.97      0.97       114\n",
      "\n",
      "    accuracy                           0.94       127\n",
      "   macro avg       0.86      0.83      0.84       127\n",
      "weighted avg       0.94      0.94      0.94       127\n",
      "\n",
      "0.9448818897637795\n",
      "============After tuned============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.77      0.77      0.77        13\n",
      "     class 1       0.97      0.97      0.97       114\n",
      "\n",
      "    accuracy                           0.95       127\n",
      "   macro avg       0.87      0.87      0.87       127\n",
      "weighted avg       0.95      0.95      0.95       127\n",
      "\n",
      "0.952755905511811\n"
     ]
    }
   ],
   "source": [
    "# Before tuned\n",
    "print('============Before tuned============')\n",
    "print(classification_report(y_true, y_prod, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod))\n",
    "# After tuned\n",
    "print('============After tuned============')\n",
    "print(classification_report(y_true, y_prod_customized, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod_customized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification Model(2) - GBM\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;분류/회귀예측에 이용되는 앙상블 기법 중 하나로, 대표적인 부스팅 모형에 해당함<br><br>&nbsp;&nbsp;&nbsp;&nbsp;기존 타겟값과 그 residual을 예측하는 모형을 반복적으로 구성하고 결합함으로써 모형의 예측력을 높여가는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;A. Hyperparameter tuning of GBM<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;B. Check the over-fitting of tuned model<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;C. Calculate the cut-off value for classification<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;D. Compare default model to tuned model<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Hyperparameter tuning of GBM (using 5-fold cross validation)\n",
    "- n_estimators: The number of boosting stages to perform.\n",
    "- max_features: The number of features to consider when looking for the best split.\n",
    "- max_depth: The maximum depth of the individual estimators.\n",
    "- min_sample_split: The minimum number of samples required to split an internal node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=GradientBoostingClassifier(random_state=10,\n",
       "                                                  subsample=0.8),\n",
       "             iid=False, n_jobs=4,\n",
       "             param_grid={'max_depth': range(5, 9),\n",
       "                         'max_features': ['sqrt', 'auto'],\n",
       "                         'min_samples_split': range(2, 5),\n",
       "                         'n_estimators': range(1, 50, 10)},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'OC'\n",
    "IDcol = 'inst_id'\n",
    "\n",
    "predictors = [x for x in train_prod_X.columns if x not in [target, IDcol]]\n",
    "param_test1 = {'n_estimators':range(1,50,10), 'min_samples_split':range(2,5,1),'max_depth':range(5,9),'max_features':['sqrt','auto']}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, subsample=0.8,random_state=10), \n",
    "param_grid = param_test1, scoring='accuracy',n_jobs=4,iid=False, cv=5)\n",
    "\n",
    "gsearch1.fit(train_prod_X[predictors],train_prod_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the best hyperparameter combination and train the GBM model with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 11}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.980771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.306295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.970916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.983444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.980771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>424</td>\n",
       "      <td>0.288056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>425</td>\n",
       "      <td>0.615866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>429</td>\n",
       "      <td>0.592594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>430</td>\n",
       "      <td>0.983444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>431</td>\n",
       "      <td>0.592594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     inst_id        OC\n",
       "0          2  0.980771\n",
       "1          5  0.306295\n",
       "2          6  0.970916\n",
       "3          8  0.983444\n",
       "4         10  0.980771\n",
       "..       ...       ...\n",
       "122      424  0.288056\n",
       "123      425  0.615866\n",
       "124      429  0.592594\n",
       "125      430  0.983444\n",
       "126      431  0.592594\n",
       "\n",
       "[127 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################################\n",
    "############ GBM with hyper-parameter tuning\n",
    "############################################################################\n",
    "np.random.seed(100)\n",
    "estimators = gsearch1.best_estimator_.n_estimators\n",
    "max_depth=gsearch1.best_estimator_.max_depth\n",
    "max_features=gsearch1.best_estimator_.max_features\n",
    "min_samples_leaf=gsearch1.best_estimator_.min_samples_leaf\n",
    "n_estimators=gsearch1.best_estimator_.n_estimators\n",
    "random_state=gsearch1.best_estimator_.random_state\n",
    "\n",
    "GBM_prod_tune = GradientBoostingClassifier(n_estimators = estimators ,max_depth=max_depth, max_features=max_features,min_samples_leaf=min_samples_leaf,random_state = random_state )\n",
    "GBM_prod_model_tune = GBM_prod_tune.fit(train_prod_X, train_prod_Y)\n",
    "GBM_prod_prediction_tune = GBM_prod_tune.predict_proba(test_prod_X)[:,1]\n",
    "\n",
    "sub_GBM_tune = pd.DataFrame({'inst_id' : sub_id , 'OC' : GBM_prod_prediction_tune })\n",
    "sub_GBM_tune = sub_GBM_tune[['inst_id', 'OC']]\n",
    "sub_GBM_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Check the over-fitting of tuned model (using 5-fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM 함수를 만들고 교차 검증을 수행하는데 도움을 주는 함수\n",
    "def modelfit(alg, dtrain, predictors, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    global train_prod_Y\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors],train_prod_Y)\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    #Perform cross-validation:\n",
    "    if performCV:\n",
    "        cv_score = cross_val_score(alg, dtrain[predictors], train_prod_Y, cv=cv_folds, scoring='roc_auc')\n",
    "    \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % accuracy_score(train_prod_Y.values, dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % roc_auc_score(train_prod_Y, dtrain_predprob))\n",
    "    \n",
    "    if performCV:\n",
    "        print (\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "        \n",
    "    #Print Feature Importance:\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.9967\n",
      "AUC Score (Train): 1.000000\n",
      "CV Score : Mean - 0.6803589 | Std - 0.163908 | Min - 0.4912281 | Max - 0.9824561\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train_prod.columns if x not in [target,IDcol]]\n",
    "modelfit(GBM_prod_tune, train_prod_X, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Calculate the cut-off value for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the optimal cut-off value (0.5~0.8 by 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " cut-off value :  0.5\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.67      0.31      0.42        13\n",
      "       close       0.93      0.98      0.95       114\n",
      "\n",
      "    accuracy                           0.91       127\n",
      "   macro avg       0.80      0.65      0.69       127\n",
      "weighted avg       0.90      0.91      0.90       127\n",
      "\n",
      "0.9133858267716536\n",
      "============================================================\n",
      " cut-off value :  0.6\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.75      0.69      0.72        13\n",
      "       close       0.97      0.97      0.97       114\n",
      "\n",
      "    accuracy                           0.94       127\n",
      "   macro avg       0.86      0.83      0.84       127\n",
      "weighted avg       0.94      0.94      0.94       127\n",
      "\n",
      "0.9448818897637795\n",
      "============================================================\n",
      " cut-off value :  0.7\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.71      0.77      0.74        13\n",
      "       close       0.97      0.96      0.97       114\n",
      "\n",
      "    accuracy                           0.94       127\n",
      "   macro avg       0.84      0.87      0.85       127\n",
      "weighted avg       0.95      0.94      0.95       127\n",
      "\n",
      "0.9448818897637795\n",
      "============================================================\n",
      " cut-off value :  0.8\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.73      0.85      0.79        13\n",
      "       close       0.98      0.96      0.97       114\n",
      "\n",
      "    accuracy                           0.95       127\n",
      "   macro avg       0.86      0.91      0.88       127\n",
      "weighted avg       0.96      0.95      0.95       127\n",
      "\n",
      "0.952755905511811\n"
     ]
    }
   ],
   "source": [
    "max_accuracy = -1\n",
    "coval_max = -1\n",
    "\n",
    "for i in range(start,end):\n",
    "    print('='*60)\n",
    "    coval = i/10\n",
    "    print(\" cut-off value : \" ,coval)\n",
    "    print('-'*22)\n",
    "\n",
    "    sub_GBM_tune_ths = sub_GBM_tune[['inst_id', 'OC']]\n",
    "    sub_GBM_tune_ths['OC'] = [1 if oc>=coval else 0 for oc in sub_GBM_tune_ths['OC']]\n",
    "    y_prod = list(sub_GBM_tune_ths['OC'])\n",
    "    print(classification_report(y_true, y_prod, target_names=['open', 'close']))\n",
    "    print(accuracy_score(y_true,y_prod))\n",
    "\n",
    "    if max_accuracy < accuracy_score(y_true,y_prod):\n",
    "        max_accuracy = accuracy_score(y_true,y_prod)\n",
    "        coval_max = coval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal cut-off value (according to 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_GBM = coval_max\n",
    "cutoff_GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Compare orginal model to tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defalut model\n",
    "- n_estimators: default\n",
    "- max_features: default\n",
    "- max_depth: default\n",
    "- min_sample_split: default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ GBM\n",
    "############################################################################\n",
    "np.random.seed(100)\n",
    "GBM_prod = GradientBoostingClassifier()\n",
    "GBM_prod_model = GBM_prod.fit(train_prod_X, train_prod_Y)\n",
    "GBM_prod_prediction = GBM_prod.predict_proba(test_prod_X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare 2 models with optimal cut-off value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_GBM = pd.DataFrame({'inst_id' : sub_id , 'OC' : GBM_prod_prediction })\n",
    "sub_GBM = sub_GBM[['inst_id', 'OC']]\n",
    "sub_GBM['OC'] = [1 if oc>=cutoff_GBM else 0 for oc in sub_GBM['OC']]\n",
    "y_prod = list(sub_GBM['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_GBM_customized = sub_GBM_tune[['inst_id', 'OC']]\n",
    "sub_GBM_customized['OC'] = [1 if oc >= cutoff_GBM else 0 for oc in sub_GBM_customized['OC']] # 확률값을 1,0으로 변환\n",
    "y_prod_customized = list(sub_GBM_customized['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Before tuned============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.80      0.92      0.86        13\n",
      "     class 1       0.99      0.97      0.98       114\n",
      "\n",
      "    accuracy                           0.97       127\n",
      "   macro avg       0.90      0.95      0.92       127\n",
      "weighted avg       0.97      0.97      0.97       127\n",
      "\n",
      "0.968503937007874\n",
      "============After tuned============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.73      0.85      0.79        13\n",
      "     class 1       0.98      0.96      0.97       114\n",
      "\n",
      "    accuracy                           0.95       127\n",
      "   macro avg       0.86      0.91      0.88       127\n",
      "weighted avg       0.96      0.95      0.95       127\n",
      "\n",
      "0.952755905511811\n"
     ]
    }
   ],
   "source": [
    "# Before tuned\n",
    "print('============Before tuned============')\n",
    "print(classification_report(y_true, y_prod, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod))\n",
    "# After tuned\n",
    "print('============After tuned============')\n",
    "print(classification_report(y_true, y_prod_customized, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod_customized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification Model(3) -XGBOOST\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;GBM보다 속도와 성능이 향상된 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Hyperparameter tuning of XGBOOST (using 3-fold cross validation)\n",
    "- eta: The learning rate.\n",
    "- num_boost_round: The number of boosting rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_prod = xgb.DMatrix(data = train_prod_X, label = train_prod_Y)\n",
    "dtest_prod = xgb.DMatrix(data = test_prod_X)\n",
    "\n",
    "#Custom error function for the XGB model\n",
    "threshold = 0.5\n",
    "def eval_error(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = (preds > threshold ).astype('float')\n",
    "    return \"accuracy\", accuracy_score(labels, preds)\n",
    "    \n",
    "\n",
    "param_tmp = {'eta': [0.1, 0.2, 0.3, 0.4]}\n",
    "nrounds = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed:    2.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x0000022B7E6694A0>,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=1,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=4, param_grid={'eta': [0.1, 0.2, 0.3, 0.4]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier = XGBClassifier(objective='binary:logistic',nthread=1)\n",
    "skf = StratifiedKFold(n_splits=3, shuffle = True, random_state = 42)\n",
    "\n",
    "grid_search_XGB = GridSearchCV(xgb_classifier, param_grid = param_tmp, scoring='accuracy', n_jobs=4, cv=skf.split(train_prod_X, train_prod_Y), verbose=2)\n",
    "grid_search_XGB.fit(train_prod_X, train_prod_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the best hyperparameter combination and train the GBM model with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta': 0.3}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_XGB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ XGBOOST - tuning\n",
    "############################################################################\n",
    "np.random.seed(100)\n",
    "best_param = {'eta': grid_search_XGB.best_params_['eta']}\n",
    "\n",
    "xgb_model_tune = xgb.train(best_param, \n",
    "                      dtrain_prod, \n",
    "                      num_boost_round = nrounds ,\n",
    "                      feval = eval_error,\n",
    "                      #maximize = True,\n",
    "                      #early_stopping_rounds = 10,\n",
    "                      )\n",
    "\n",
    "XGB_prediction = xgb_model_tune.predict(dtest_prod)\n",
    "sub_XGB_tune= pd.DataFrame({'inst_id' : sub_id , 'OC' : XGB_prediction })\n",
    "sub_XGB_tune= sub_XGB_tune[['inst_id', 'OC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PLotting the feature importance\n",
    "xgb_Imp_tune = pd.DataFrame({'Features' : list(xgb_model_tune.get_score().keys()), \n",
    "                        'Importance' : list(xgb_model_tune.get_score().values())}).sort_values(['Importance'])\n",
    "plt.figure()\n",
    "sns.barplot(xgb_Imp_tune.Importance, xgb_Imp_tune.Features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Check the over-fitting of tuned model (using 5-fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95081967 0.95       0.95       0.95       0.95      ]\n",
      "mean :  0.9501639344262296\n"
     ]
    }
   ],
   "source": [
    "# model, train, target, cross validation\n",
    "np.random.seed(10)\n",
    "xgb_model_tune_clf = XGBClassifier(objective='binary:logistic',\n",
    "                                   learning_rate=grid_search_XGB.best_params_['eta'] )\n",
    "\n",
    "scores = cross_val_score(xgb_model_tune_clf, train_prod_X, train_prod_Y, cv=5) \n",
    "print(scores)\n",
    "print('mean : ',scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Calculate the cut-off value for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the optimal cut-off value (0.5~0.8 by 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " cut-off value :  0.5\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.75      0.92      0.83        13\n",
      "       close       0.99      0.96      0.98       114\n",
      "\n",
      "    accuracy                           0.96       127\n",
      "   macro avg       0.87      0.94      0.90       127\n",
      "weighted avg       0.97      0.96      0.96       127\n",
      "\n",
      "0.9606299212598425\n",
      "============================================================\n",
      " cut-off value :  0.6\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.67      0.92      0.77        13\n",
      "       close       0.99      0.95      0.97       114\n",
      "\n",
      "    accuracy                           0.94       127\n",
      "   macro avg       0.83      0.94      0.87       127\n",
      "weighted avg       0.96      0.94      0.95       127\n",
      "\n",
      "0.9448818897637795\n",
      "============================================================\n",
      " cut-off value :  0.7\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.57      1.00      0.72        13\n",
      "       close       1.00      0.91      0.95       114\n",
      "\n",
      "    accuracy                           0.92       127\n",
      "   macro avg       0.78      0.96      0.84       127\n",
      "weighted avg       0.96      0.92      0.93       127\n",
      "\n",
      "0.9212598425196851\n",
      "============================================================\n",
      " cut-off value :  0.8\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.10      1.00      0.19        13\n",
      "       close       0.00      0.00      0.00       114\n",
      "\n",
      "    accuracy                           0.10       127\n",
      "   macro avg       0.05      0.50      0.09       127\n",
      "weighted avg       0.01      0.10      0.02       127\n",
      "\n",
      "0.10236220472440945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "max_accuracy = -1\n",
    "coval_max = -1\n",
    "for i in range(start,end):\n",
    "    print('='*60)\n",
    "    coval = i/10\n",
    "    print(\" cut-off value : \" ,coval)\n",
    "    print('-'*22)\n",
    "\n",
    "    sub_XGB_tune_ths = sub_XGB_tune[['inst_id', 'OC']]\n",
    "    sub_XGB_tune_ths['OC'] = [1 if oc>=coval else 0 for oc in sub_XGB_tune_ths['OC']]\n",
    "    y_prod = list(sub_XGB_tune_ths['OC'])\n",
    "    print(classification_report(y_true, y_prod, target_names=['open', 'close']))\n",
    "    acc= accuracy_score(y_true,y_prod)\n",
    "    print(acc)\n",
    "    if max_accuracy < acc:\n",
    "        max_accuracy = acc\n",
    "        coval_max = coval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal cut-off value (according to 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_XGB = coval_max\n",
    "cutoff_XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Compare orginal model to tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defalut model\n",
    "- eta: default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ XGBOOST\n",
    "############################################################################\n",
    "XGB_prod = XGBClassifier()\n",
    "XGB_prod.fit(train_prod_X, train_prod_Y)\n",
    "XGB_prod_prediction = XGB_prod.predict_proba(test_prod_X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare 2 models with optimal cut-off value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_XGB= pd.DataFrame({'inst_id' : sub_id , 'OC' : XGB_prediction })\n",
    "sub_XGB= sub_XGB[['inst_id', 'OC']]\n",
    "sub_XGB['OC'] = [1 if oc>=cutoff_XGB else 0 for oc in sub_XGB['OC']]\n",
    "y_prod = list(sub_XGB['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_XGB_customized = sub_XGB_tune[['inst_id', 'OC']]\n",
    "sub_XGB_customized['OC'] = [1 if oc >= cutoff_XGB else 0 for oc in sub_XGB_customized['OC']] # 확률값을 1,0으로 변환\n",
    "y_prod_customized = list(sub_XGB_customized['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Before tuned============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.75      0.92      0.83        13\n",
      "     class 1       0.99      0.96      0.98       114\n",
      "\n",
      "    accuracy                           0.96       127\n",
      "   macro avg       0.87      0.94      0.90       127\n",
      "weighted avg       0.97      0.96      0.96       127\n",
      "\n",
      "0.9606299212598425\n",
      "============After tuned============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.75      0.92      0.83        13\n",
      "     class 1       0.99      0.96      0.98       114\n",
      "\n",
      "    accuracy                           0.96       127\n",
      "   macro avg       0.87      0.94      0.90       127\n",
      "weighted avg       0.97      0.96      0.96       127\n",
      "\n",
      "0.9606299212598425\n"
     ]
    }
   ],
   "source": [
    "# Before tuned\n",
    "print('============Before tuned============')\n",
    "print(classification_report(y_true, y_prod, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod))\n",
    "# After tuned\n",
    "print('============After tuned============')\n",
    "print(classification_report(y_true, y_prod_customized, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod_customized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고사이트   \n",
    "1. Random forest   \n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "2. GBM   \n",
    "https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "\n",
    "3. xgboost   \n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
