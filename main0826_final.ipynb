{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge shap\n",
    "# pip install xgboost\n",
    "# pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>병원 개/폐업 분류예측 프로젝트</h1></center><br>\n",
    "\n",
    "---\n",
    "<h4>1. 주제 및 목표</h4>\n",
    "- 병원 폐업 여부를 예측하여 대출 승인여부 결정\n",
    "\n",
    "<h4>2. 배경</h4>\n",
    "- 한국 핀테크 기업 모우다(MOUDA): 상환기간 동안의 계속 경영 여부를 예측하여 병원들에게 금융 기회를 제공\n",
    "- 일반적으로 병원 대출 시 신용점수 또는 담보물을 위주로 평가를 진행했던 기존 금융기관과의 차별점\n",
    "- 신용 점수가 낮거나 담보를 가지지 못하는 우수 병원들에게도 금융 기회를 제공하자는 취지\n",
    "\n",
    "<h4>3. 활용 데이터</h4>\n",
    "- 의료기관의 폐업 여부가 포함된 최근 2개년의 재무정보와 병원 기본정보 \n",
    "- (출처) Dacon 병원 개/폐업 분류 예측 경진대회 (https://dacon.io/competitions/official/9565/data/)\n",
    "- 데이터 설명\n",
    "> - <병원 기본정보>\n",
    "> - inst_id: 병원 고유 번호<br>\n",
    "> - OC: 영업/폐업 분류<br>\n",
    "> - sido: 병원의 광역 지역 정보<br>\n",
    "> - sgg: 병원의 시군구 자료<br>\n",
    "> - openDate: 병원 설립일<br> \n",
    "> - bedcount: 병원이 갖추고 있는 병상의 수<br>\n",
    "> - instkind: 병원, 의원, 요양병원, 한의원, 종합병원 등 병원의 종류<br><br>\n",
    "> - <재무정보> 1: 2017 회계년도, 2: 2016 회계년도\n",
    "> - revenue1(2): 매출액<br>\n",
    "> - salescost1(2): 매출원가<br>\n",
    "> - sga1(2): 판매비와 관리비<br>\n",
    "> - salary1(2): 급여<br>\n",
    "> - noi1(2): 영업외수익<br>\n",
    "> - noe1(2): 영업외비용<br>\n",
    "> - Interest1(2): 이자비용<br>\n",
    "> - ctax1(2): 법인세비용<br>\n",
    "> - Profit1(2): 당기순이익<br>\n",
    "> - liquidAsset1(2): 유동자산<br>\n",
    "> - quickAsset1(2): 당좌자산<br>\n",
    "> - receivableS1(2): 미수금(단기)<br>\n",
    "> - inventoryAsset1(2): 재고자산<br>\n",
    "> - nonCAsset1(2): 비유동자산<br>\n",
    "> - tanAsset1(2): 유형자산<br>\n",
    "> - OnonCAseet1(2): 기타 비유동자산<br>\n",
    "> - receivableL1(2): 장기미수금<br>\n",
    "> - debt1(2): 부채총계<br>\n",
    "> - liquidLiabilities1(2): 유동부채<br>\n",
    "> - shortLoan1(2): 단기차입금<br>\n",
    "> - NCLiabilities1(2): 비유동부채<br>\n",
    "> - longLoan1(2): 장기차입금<br>\n",
    "> - netAsset1(2): 순자산총계<br>\n",
    "> - surplus1(2): 이익잉여금\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.core._multiarray_umath'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._multiarray_umath'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the train and test files\n",
    "train_prod_df = pd.read_csv('data\\\\train.csv') # 학습데이터\n",
    "test_prod_df = pd.read_csv('data\\\\test_empty.csv') # 테스트데이터 (결과값 비어있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "      <th>sido</th>\n",
       "      <th>sgg</th>\n",
       "      <th>openDate</th>\n",
       "      <th>bedCount</th>\n",
       "      <th>instkind</th>\n",
       "      <th>revenue1</th>\n",
       "      <th>salescost1</th>\n",
       "      <th>sga1</th>\n",
       "      <th>...</th>\n",
       "      <th>debt2</th>\n",
       "      <th>liquidLiabilities2</th>\n",
       "      <th>shortLoan2</th>\n",
       "      <th>NCLiabilities2</th>\n",
       "      <th>longLoan2</th>\n",
       "      <th>netAsset2</th>\n",
       "      <th>surplus2</th>\n",
       "      <th>employee1</th>\n",
       "      <th>employee2</th>\n",
       "      <th>ownerChange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>open</td>\n",
       "      <td>choongnam</td>\n",
       "      <td>73</td>\n",
       "      <td>20071228</td>\n",
       "      <td>175.0</td>\n",
       "      <td>nursing_hospital</td>\n",
       "      <td>4.217530e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.961135e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>7.589937e+08</td>\n",
       "      <td>2.228769e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.361169e+08</td>\n",
       "      <td>3.900000e+08</td>\n",
       "      <td>2.619290e+09</td>\n",
       "      <td>1.271224e+09</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>open</td>\n",
       "      <td>gyeongnam</td>\n",
       "      <td>32</td>\n",
       "      <td>19970401</td>\n",
       "      <td>410.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>801.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>open</td>\n",
       "      <td>gyeonggi</td>\n",
       "      <td>89</td>\n",
       "      <td>20161228</td>\n",
       "      <td>468.0</td>\n",
       "      <td>nursing_hospital</td>\n",
       "      <td>1.004522e+09</td>\n",
       "      <td>515483669.0</td>\n",
       "      <td>4.472197e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>234.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>open</td>\n",
       "      <td>incheon</td>\n",
       "      <td>141</td>\n",
       "      <td>20000814</td>\n",
       "      <td>353.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>7.250734e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.067740e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.775501e+10</td>\n",
       "      <td>1.701860e+10</td>\n",
       "      <td>9.219427e+09</td>\n",
       "      <td>2.073641e+10</td>\n",
       "      <td>1.510000e+10</td>\n",
       "      <td>1.295427e+10</td>\n",
       "      <td>7.740829e+09</td>\n",
       "      <td>663.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>open</td>\n",
       "      <td>gyeongnam</td>\n",
       "      <td>32</td>\n",
       "      <td>20050901</td>\n",
       "      <td>196.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>4.904354e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.765605e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.143259e+10</td>\n",
       "      <td>3.007259e+10</td>\n",
       "      <td>1.759375e+10</td>\n",
       "      <td>2.136001e+10</td>\n",
       "      <td>1.410803e+10</td>\n",
       "      <td>5.561941e+06</td>\n",
       "      <td>9.025550e+09</td>\n",
       "      <td>206.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inst_id    OC       sido  sgg  openDate  bedCount          instkind  \\\n",
       "0        1  open  choongnam   73  20071228     175.0  nursing_hospital   \n",
       "1        3  open  gyeongnam   32  19970401     410.0  general_hospital   \n",
       "2        4  open   gyeonggi   89  20161228     468.0  nursing_hospital   \n",
       "3        7  open    incheon  141  20000814     353.0  general_hospital   \n",
       "4        9  open  gyeongnam   32  20050901     196.0  general_hospital   \n",
       "\n",
       "       revenue1   salescost1          sga1     ...              debt2  \\\n",
       "0  4.217530e+09          0.0  3.961135e+09     ...       7.589937e+08   \n",
       "1           NaN          NaN           NaN     ...                NaN   \n",
       "2  1.004522e+09  515483669.0  4.472197e+08     ...       0.000000e+00   \n",
       "3  7.250734e+10          0.0  7.067740e+10     ...       3.775501e+10   \n",
       "4  4.904354e+10          0.0  4.765605e+10     ...       5.143259e+10   \n",
       "\n",
       "   liquidLiabilities2    shortLoan2  NCLiabilities2     longLoan2  \\\n",
       "0        2.228769e+08  0.000000e+00    5.361169e+08  3.900000e+08   \n",
       "1                 NaN           NaN             NaN           NaN   \n",
       "2        0.000000e+00  0.000000e+00    0.000000e+00  0.000000e+00   \n",
       "3        1.701860e+10  9.219427e+09    2.073641e+10  1.510000e+10   \n",
       "4        3.007259e+10  1.759375e+10    2.136001e+10  1.410803e+10   \n",
       "\n",
       "      netAsset2      surplus2  employee1  employee2  ownerChange  \n",
       "0  2.619290e+09  1.271224e+09       62.0       64.0         same  \n",
       "1           NaN           NaN      801.0      813.0         same  \n",
       "2  0.000000e+00  0.000000e+00      234.0        1.0         same  \n",
       "3  1.295427e+10  7.740829e+09      663.0      663.0         same  \n",
       "4  5.561941e+06  9.025550e+09      206.0      197.0         same  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prod_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "      <th>sido</th>\n",
       "      <th>sgg</th>\n",
       "      <th>openDate</th>\n",
       "      <th>bedCount</th>\n",
       "      <th>instkind</th>\n",
       "      <th>revenue1</th>\n",
       "      <th>salescost1</th>\n",
       "      <th>sga1</th>\n",
       "      <th>...</th>\n",
       "      <th>debt2</th>\n",
       "      <th>liquidLiabilities2</th>\n",
       "      <th>shortLoan2</th>\n",
       "      <th>NCLiabilities2</th>\n",
       "      <th>longLoan2</th>\n",
       "      <th>netAsset2</th>\n",
       "      <th>surplus2</th>\n",
       "      <th>employee1</th>\n",
       "      <th>employee2</th>\n",
       "      <th>ownerChange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>incheon</td>\n",
       "      <td>139</td>\n",
       "      <td>19981125.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>6.682486e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.565709e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.540643e+10</td>\n",
       "      <td>5.068443e+10</td>\n",
       "      <td>3.714334e+10</td>\n",
       "      <td>4.720000e+09</td>\n",
       "      <td>4.690000e+09</td>\n",
       "      <td>1.608540e+10</td>\n",
       "      <td>8.944587e+09</td>\n",
       "      <td>693</td>\n",
       "      <td>693</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jeju</td>\n",
       "      <td>149</td>\n",
       "      <td>20160309.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>hospital</td>\n",
       "      <td>3.495758e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.259270e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>6.730838e+10</td>\n",
       "      <td>4.209828e+10</td>\n",
       "      <td>2.420000e+10</td>\n",
       "      <td>2.521009e+10</td>\n",
       "      <td>1.830000e+10</td>\n",
       "      <td>3.789135e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>379</td>\n",
       "      <td>371</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jeonnam</td>\n",
       "      <td>103</td>\n",
       "      <td>19890427.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>2.326031e+10</td>\n",
       "      <td>2.542571e+09</td>\n",
       "      <td>2.308749e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.777589e+10</td>\n",
       "      <td>2.182278e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.638540e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>busan</td>\n",
       "      <td>71</td>\n",
       "      <td>20100226.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.211517e+10</td>\n",
       "      <td>9.556237e+09</td>\n",
       "      <td>4.251867e+09</td>\n",
       "      <td>2.558931e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.914284e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jeonbuk</td>\n",
       "      <td>26</td>\n",
       "      <td>20040604.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>5.037025e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.855803e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>4.395973e+10</td>\n",
       "      <td>7.535567e+09</td>\n",
       "      <td>3.298427e+09</td>\n",
       "      <td>3.642417e+10</td>\n",
       "      <td>2.134712e+10</td>\n",
       "      <td>2.574488e+10</td>\n",
       "      <td>1.507269e+10</td>\n",
       "      <td>437</td>\n",
       "      <td>385</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inst_id  OC     sido  sgg    openDate  bedCount          instkind  \\\n",
       "0        2 NaN  incheon  139  19981125.0     300.0  general_hospital   \n",
       "1        5 NaN     jeju  149  20160309.0      44.0          hospital   \n",
       "2        6 NaN  jeonnam  103  19890427.0     276.0  general_hospital   \n",
       "3        8 NaN    busan   71  20100226.0     363.0  general_hospital   \n",
       "4       10 NaN  jeonbuk   26  20040604.0     213.0  general_hospital   \n",
       "\n",
       "       revenue1    salescost1          sga1     ...              debt2  \\\n",
       "0  6.682486e+10  0.000000e+00  6.565709e+10     ...       5.540643e+10   \n",
       "1  3.495758e+10  0.000000e+00  3.259270e+10     ...       6.730838e+10   \n",
       "2  2.326031e+10  2.542571e+09  2.308749e+10     ...       0.000000e+00   \n",
       "3  0.000000e+00  0.000000e+00  0.000000e+00     ...       1.211517e+10   \n",
       "4  5.037025e+10  0.000000e+00  4.855803e+10     ...       4.395973e+10   \n",
       "\n",
       "   liquidLiabilities2    shortLoan2  NCLiabilities2     longLoan2  \\\n",
       "0        5.068443e+10  3.714334e+10    4.720000e+09  4.690000e+09   \n",
       "1        4.209828e+10  2.420000e+10    2.521009e+10  1.830000e+10   \n",
       "2        2.777589e+10  2.182278e+10    0.000000e+00  0.000000e+00   \n",
       "3        9.556237e+09  4.251867e+09    2.558931e+09  0.000000e+00   \n",
       "4        7.535567e+09  3.298427e+09    3.642417e+10  2.134712e+10   \n",
       "\n",
       "      netAsset2      surplus2  employee1  employee2  ownerChange  \n",
       "0  1.608540e+10  8.944587e+09        693        693         same  \n",
       "1  3.789135e+09  0.000000e+00        379        371         same  \n",
       "2  0.000000e+00  1.638540e+10        NaN        NaN          NaN  \n",
       "3  3.914284e+10  0.000000e+00        760        760         same  \n",
       "4  2.574488e+10  1.507269e+10        437        385         same  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prod_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert 'employee' to numeric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the comma in the employee1 and 2 columns in the test dataset and replace it with empty space and convert it to float format.\n",
    "test_prod_df.employee1 = test_prod_df.employee1.astype('str').str.replace(\",\", \"\").astype('float')\n",
    "test_prod_df.employee2 = test_prod_df.employee2.astype('str').str.replace(\",\", \"\").astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the employee1 and 2 column as float in the train set as done for the test dataset\n",
    "train_prod_df.employee1 = train_prod_df.employee1.astype('float')\n",
    "train_prod_df.employee2 = train_prod_df.employee2.astype('float')\n",
    "train_prod_df.OC= train_prod_df.OC.astype('str').str.replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the empty values\n",
    "- Factor columns: Not_sure\n",
    "- Numeric columns: -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the train and test dataset\n",
    "train_test_prod = train_prod_df.append(test_prod_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428, 58)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_prod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the object and numeric columns seperately \n",
    "factor_columns = train_test_prod.select_dtypes(include = ['object']).columns\n",
    "numeric_columns = train_test_prod.columns.difference(factor_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OC', 'sido', 'instkind', 'ownerChange'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NCLiabilities1', 'NCLiabilities2', 'OnonCAsset1', 'OnonCAsset2',\n",
       "       'bedCount', 'ctax1', 'ctax2', 'debt1', 'debt2', 'employee1',\n",
       "       'employee2', 'inst_id', 'interest1', 'interest2', 'inventoryAsset1',\n",
       "       'inventoryAsset2', 'liquidAsset1', 'liquidAsset2', 'liquidLiabilities1',\n",
       "       'liquidLiabilities2', 'longLoan1', 'longLoan2', 'netAsset1',\n",
       "       'netAsset2', 'noe1', 'noe2', 'noi1', 'noi2', 'nonCAsset1', 'nonCAsset2',\n",
       "       'openDate', 'profit1', 'profit2', 'quickAsset1', 'quickAsset2',\n",
       "       'receivableL1', 'receivableL2', 'receivableS1', 'receivableS2',\n",
       "       'revenue1', 'revenue2', 'salary1', 'salary2', 'salescost1',\n",
       "       'salescost2', 'sga1', 'sga2', 'sgg', 'shortLoan1', 'shortLoan2',\n",
       "       'surplus1', 'surplus2', 'tanAsset1', 'tanAsset2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After analysis realized that the bed counts of these two hospitals may have had wrong entries.\n",
    "#Filling up the empty instkind and bedCount for hospital id 430 and 413\n",
    "train_test_prod.loc[train_test_prod.inst_id == 430, ['instkind']] = 'dental_clinic'\n",
    "train_test_prod.loc[train_test_prod.inst_id == 430, ['bedCount']] = 0\n",
    "train_test_prod.loc[train_test_prod.inst_id == 413, ['bedCount']] = -999\n",
    "\n",
    "#Fill the empty values in the object columns as \"Not sure\"\n",
    "train_test_prod[factor_columns] = train_test_prod[factor_columns].fillna('Not_sure')\n",
    "#Fill all the empty values in the numeric columns as -999\n",
    "train_test_prod[numeric_columns] = train_test_prod[numeric_columns].fillna(-999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the whole data into train and test set\n",
    "- dependent column: OC (0:close, 1:open)\n",
    "- independent columns: others\n",
    "\n",
    "\n",
    "- train_prod_X: train set with independent columns\n",
    "- train_prod_Y: train set with dependent column\n",
    "- test_prod_X: test set with independent columns\n",
    "- test_prod_Y: the objective of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Convert all the object columns to numeric since the ML algorithms don't accept object features directly \n",
    "fac_le = LabelEncoder()\n",
    "train_test_prod[factor_columns] = train_test_prod.loc[:,factor_columns].apply(lambda x : fac_le.fit_transform(x))\n",
    "\n",
    "#Splitting back data to train prod and test prod\n",
    "#값이 있으면 train 데이터셋 값이 비어있으면 test 데이터셋 \n",
    "train_prod = train_test_prod.loc[train_test_prod.OC != 0,]\n",
    "test_prod = train_test_prod.loc[train_test_prod.OC == 0,]\n",
    "\n",
    "# 1,2 를 0,1로 바꾸기 (0이 폐업(close) 1이 폐업X(open))\n",
    "train_prod['OC'] = train_prod['OC'] - 1\n",
    "\n",
    "#Obtain the submission ID to create the submission file later\n",
    "sub_id = test_prod.inst_id\n",
    "\n",
    "#Get the dependent and independent column\n",
    "dep = 'OC'\n",
    "indep = train_prod.columns.difference([dep])\n",
    "\n",
    "train_prod_X = train_prod[indep]\n",
    "train_prod_Y = train_prod[dep]\n",
    "test_prod_X = test_prod[indep]\n",
    "#test_prod_Y = test_prod[dep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification Model(1) - Random Forest\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;분류/회귀예측에 이용되는 앙상블 기법 중 하나로, 대표적인 배깅 모형에 해당함<br><br>&nbsp;&nbsp;&nbsp;&nbsp;다수의 결정 트리를 구성한 뒤 평균 또는 과반수 투표 등을 이용하여 하나의 랜덤 포레스트로 결합함  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;A. Hyperparameter tuning of Random forest<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;B. Check the over-fitting of tuned model<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;C. Calculate the cut-off value for classification<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;D. Compare default model to tuned model<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Hyperparameter tuning of Random forest (using 3-fold cross validation)\n",
    "- n_estimators: The number of trees in the forest.\n",
    "- max_features: The number of features to consider when looking for the best split.\n",
    "- max_depth: The maximum depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 300, num = 10)] # Number of trees in random forest\n",
    "max_features = ['auto', 'sqrt'] # Number of features to consider at every split\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)] # Maximum number of levels in tree\n",
    "max_depth.append(None)\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 240 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [10, 42, 74, 106, 138, 171, 203, 235, 267, 300], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "np.random.seed(100)\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = GridSearchCV(estimator = rf, param_grid = random_grid, scoring = 'accuracy', cv = 3, verbose=2, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_prod_X, train_prod_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the best hyperparameter combination and train the random forest model with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20, 'max_features': 'auto', 'n_estimators': 10}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>46</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>66</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>76</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>78</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>79</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>80</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>85</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>336</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>337</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>341</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>343</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>348</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>368</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>370</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>374</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>380</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>382</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>387</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>388</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>389</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>394</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>395</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>396</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>397</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>398</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>401</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>403</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>404</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>410</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>413</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>421</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>424</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>425</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>429</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>430</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>431</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     inst_id   OC\n",
       "0          2  0.8\n",
       "1          5  0.8\n",
       "2          6  0.6\n",
       "3          8  0.8\n",
       "4         10  0.9\n",
       "5         12  1.0\n",
       "6         13  1.0\n",
       "7         20  1.0\n",
       "8         21  0.7\n",
       "9         23  1.0\n",
       "10        24  0.7\n",
       "11        28  1.0\n",
       "12        29  1.0\n",
       "13        30  0.8\n",
       "14        31  0.8\n",
       "15        32  1.0\n",
       "16        40  1.0\n",
       "17        41  1.0\n",
       "18        43  1.0\n",
       "19        46  0.9\n",
       "20        48  1.0\n",
       "21        54  1.0\n",
       "22        64  0.1\n",
       "23        66  0.7\n",
       "24        68  1.0\n",
       "25        76  1.0\n",
       "26        78  1.0\n",
       "27        79  0.9\n",
       "28        80  0.9\n",
       "29        85  1.0\n",
       "..       ...  ...\n",
       "97       336  1.0\n",
       "98       337  1.0\n",
       "99       341  0.4\n",
       "100      343  1.0\n",
       "101      348  1.0\n",
       "102      368  1.0\n",
       "103      370  1.0\n",
       "104      374  1.0\n",
       "105      377  1.0\n",
       "106      380  1.0\n",
       "107      382  0.9\n",
       "108      387  1.0\n",
       "109      388  0.8\n",
       "110      389  1.0\n",
       "111      394  1.0\n",
       "112      395  1.0\n",
       "113      396  1.0\n",
       "114      397  1.0\n",
       "115      398  1.0\n",
       "116      401  1.0\n",
       "117      403  1.0\n",
       "118      404  1.0\n",
       "119      410  1.0\n",
       "120      413  0.4\n",
       "121      421  1.0\n",
       "122      424  0.3\n",
       "123      425  0.7\n",
       "124      429  0.7\n",
       "125      430  0.9\n",
       "126      431  0.6\n",
       "\n",
       "[127 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################################\n",
    "############ Random Forest with hyper-parameter tuning\n",
    "############################################################################\n",
    "estimators = rf_random.best_params_['n_estimators']\n",
    "max_depth_tune = rf_random.best_params_['max_depth']\n",
    "max_features_tune = rf_random.best_params_['max_features']\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "# 하이퍼파라미터 적용\n",
    "RF_prod_tune = RandomForestClassifier(n_estimators = estimators,\n",
    "                                max_depth = max_depth_tune,\n",
    "                                max_features = max_features_tune) \n",
    "\n",
    "# 훈련\n",
    "RF_prod_tune.fit(train_prod_X, train_prod_Y) \n",
    "\n",
    "# 결과: class가 0 or 1 \n",
    "RF_prod_predicted_tune = RF_prod_tune.predict(test_prod_X) \n",
    "\n",
    "# 결과: class 1에 속할 확률\n",
    "RF_prod_prediction_tune = RF_prod_tune.predict_proba(test_prod_X)[:,1] \n",
    "\n",
    "# 튜닝 후 예측 결과 출력\n",
    "sub_RF_tune = pd.DataFrame({'inst_id' : sub_id , 'OC' : RF_prod_prediction_tune })\n",
    "sub_RF_tune = sub_RF_tune[['inst_id', 'OC']]\n",
    "sub_RF_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Check the over-fitting of tuned model (using 5-fold cross validation)\n",
    "#### 하이퍼파라미터 튜닝 범위가 무작위로 설정되었기 때문에 튜닝 결과가 훈련 데이터에 과대적합되었을 가능성이 존재함<br><br>교차 검증을 통해 과대적합 여부를 확인한 결과, 모든 fold에서 적절한 분류 성능을 보이고 있었음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93442623 0.93333333 0.95       0.96666667 0.96666667]\n",
      "mean :  0.9502185792349728\n"
     ]
    }
   ],
   "source": [
    "# model, train, target, cross validation\n",
    "np.random.seed(10)\n",
    "scores = cross_val_score(RF_prod_tune, train_prod_X, train_prod_Y, cv=5) \n",
    "print(scores)\n",
    "print('mean : ',scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Calculate the cut-off value for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct the test set with real answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# 예측결과 0(close) 라벨링 \n",
    "close_idx = [5, 6, 24, 30 ,64, 123, 229, 258, 293, 341, 425, 429, 431]\n",
    "test_prod_labeled = test_prod[['inst_id', 'OC']] # 결과 라벨링 된 테스트 데이터프레임\n",
    "test_prod_labeled['OC'] = [0 if id in close_idx else 1 for id in test_prod['inst_id']] # 라벨링\n",
    "y_true = list(test_prod_labeled['OC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the optimal cut-off value (0.5~0.8 by 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 5\n",
    "end = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " cut-off value :  0.5\n",
      "----------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       open       0.50      0.15      0.24        13\n",
      "      close       0.91      0.98      0.95       114\n",
      "\n",
      "avg / total       0.87      0.90      0.87       127\n",
      "\n",
      "0.8976377952755905\n",
      "============================================================\n",
      " cut-off value :  0.6\n",
      "----------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       open       0.50      0.15      0.24        13\n",
      "      close       0.91      0.98      0.95       114\n",
      "\n",
      "avg / total       0.87      0.90      0.87       127\n",
      "\n",
      "0.8976377952755905\n",
      "============================================================\n",
      " cut-off value :  0.7\n",
      "----------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       open       0.67      0.46      0.55        13\n",
      "      close       0.94      0.97      0.96       114\n",
      "\n",
      "avg / total       0.91      0.92      0.91       127\n",
      "\n",
      "0.9212598425196851\n",
      "============================================================\n",
      " cut-off value :  0.8\n",
      "----------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       open       0.61      0.85      0.71        13\n",
      "      close       0.98      0.94      0.96       114\n",
      "\n",
      "avg / total       0.94      0.93      0.93       127\n",
      "\n",
      "0.9291338582677166\n"
     ]
    }
   ],
   "source": [
    "max_accuracy = -1\n",
    "coval_max = -1\n",
    "\n",
    "for i in range(start,end):\n",
    "    print('='*60)\n",
    "    coval = i/10\n",
    "    print(\" cut-off value : \" ,coval)\n",
    "    print('-'*22)\n",
    "\n",
    "    sub_RF_tune_ths = sub_RF_tune[['inst_id', 'OC']]\n",
    "    sub_RF_tune_ths['OC'] = [1 if oc>=coval else 0 for oc in sub_RF_tune_ths['OC']] # 확률값을 1,0으로 변환\n",
    "    y_prod = list(sub_RF_tune_ths['OC'])\n",
    "    \n",
    "    print(classification_report(y_true, y_prod, target_names=['open', 'close']))\n",
    "    print(accuracy_score(y_true,y_prod))\n",
    "        \n",
    "    if max_accuracy < accuracy_score(y_true,y_prod):\n",
    "        max_accuracy = accuracy_score(y_true,y_prod)\n",
    "        coval_max = coval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal cut-off value (according to 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_rf = coval_max\n",
    "cutoff_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Compare default model to tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defalut model\n",
    "- n_estimators: default\n",
    "- max_features: defalut\n",
    "- max_depth: defalut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ Random Forest\n",
    "############################################################################\n",
    "np.random.seed(100)\n",
    "RF_prod = RandomForestClassifier()\n",
    "RF_prod_model = RF_prod.fit(train_prod_X, train_prod_Y)\n",
    "RF_prod_prediction = RF_prod.predict_proba(test_prod_X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare 2 models with optimal cut-off value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_RF = pd.DataFrame({'inst_id' : sub_id , 'OC' : RF_prod_prediction })\n",
    "sub_RF = sub_RF[['inst_id', 'OC']]\n",
    "sub_RF['OC'] = [1 if oc>=cutoff_rf else 0 for oc in sub_RF['OC']]\n",
    "y_prod = list(sub_RF['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_RF_customized = sub_RF_tune[['inst_id', 'OC']]\n",
    "sub_RF_customized['OC'] = [1 if oc >= cutoff_rf else 0 for oc in sub_RF_customized['OC']] # 확률값을 1,0으로 변환\n",
    "y_prod_customized = list(sub_RF_customized['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Before tuned============\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.61      0.85      0.71        13\n",
      "    class 1       0.98      0.94      0.96       114\n",
      "\n",
      "avg / total       0.94      0.93      0.93       127\n",
      "\n",
      "0.9291338582677166\n",
      "============After tuned============\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.61      0.85      0.71        13\n",
      "    class 1       0.98      0.94      0.96       114\n",
      "\n",
      "avg / total       0.94      0.93      0.93       127\n",
      "\n",
      "0.9291338582677166\n"
     ]
    }
   ],
   "source": [
    "# Before tuned\n",
    "print('============Before tuned============')\n",
    "print(classification_report(y_true, y_prod, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod))\n",
    "# After tuned\n",
    "print('============After tuned============')\n",
    "print(classification_report(y_true, y_prod_customized, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod_customized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification Model(2) - GBM\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;분류/회귀예측에 이용되는 앙상블 기법 중 하나로, 대표적인 부스팅 모형에 해당함<br><br>&nbsp;&nbsp;&nbsp;&nbsp;기존 타겟값과 그 residual을 예측하는 모형을 반복적으로 구성하고 결합함으로써 모형의 예측력을 높여가는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;A. Hyperparameter tuning of GBM<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;B. Check the over-fitting of tuned model<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;C. Calculate the cut-off value for classification<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;D. Compare default model to tuned model<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Hyperparameter tuning of GBM (using 5-fold cross validation)\n",
    "- n_estimators: The number of boosting stages to perform.\n",
    "- max_features: The number of features to consider when looking for the best split.\n",
    "- max_depth: The maximum depth of the individual estimators.\n",
    "- min_sample_split: The minimum number of samples required to split an internal node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=10, subsample=0.8, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=False, n_jobs=4,\n",
       "       param_grid={'n_estimators': range(1, 50, 10), 'min_samples_split': range(2, 5), 'max_depth': range(5, 9), 'max_features': ['sqrt', 'auto']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'OC'\n",
    "IDcol = 'inst_id'\n",
    "\n",
    "predictors = [x for x in train_prod_X.columns if x not in [target, IDcol]]\n",
    "param_test1 = {'n_estimators':range(1,50,10), 'min_samples_split':range(2,5,1),'max_depth':range(5,9),'max_features':['sqrt','auto']}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, subsample=0.8,random_state=10), \n",
    "param_grid = param_test1, scoring='accuracy',n_jobs=4,iid=False, cv=5)\n",
    "\n",
    "gsearch1.fit(train_prod_X[predictors],train_prod_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the best hyperparameter combination and train the GBM model with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 11}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.615517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.901856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "      <td>0.983472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24</td>\n",
       "      <td>0.586665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28</td>\n",
       "      <td>0.983457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>0.313113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>40</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>41</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>43</td>\n",
       "      <td>0.983448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>46</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>48</td>\n",
       "      <td>0.760924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>54</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>64</td>\n",
       "      <td>0.735791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>66</td>\n",
       "      <td>0.967837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>68</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>76</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>78</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>79</td>\n",
       "      <td>0.935457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>80</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>85</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>336</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>337</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>341</td>\n",
       "      <td>0.251132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>343</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>348</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>368</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>370</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>374</td>\n",
       "      <td>0.979706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>377</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>380</td>\n",
       "      <td>0.983457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>382</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>387</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>388</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>389</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>394</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>395</td>\n",
       "      <td>0.980122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>396</td>\n",
       "      <td>0.980122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>397</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>398</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>401</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>403</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>404</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>410</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>413</td>\n",
       "      <td>0.251132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>421</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>424</td>\n",
       "      <td>0.251132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>425</td>\n",
       "      <td>0.545959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>429</td>\n",
       "      <td>0.763796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>430</td>\n",
       "      <td>0.983441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>431</td>\n",
       "      <td>0.819661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     inst_id        OC\n",
       "0          2  0.983441\n",
       "1          5  0.615517\n",
       "2          6  0.901856\n",
       "3          8  0.983441\n",
       "4         10  0.983441\n",
       "5         12  0.983441\n",
       "6         13  0.983441\n",
       "7         20  0.983441\n",
       "8         21  0.983472\n",
       "9         23  0.983441\n",
       "10        24  0.586665\n",
       "11        28  0.983457\n",
       "12        29  0.983441\n",
       "13        30  0.313113\n",
       "14        31  0.983441\n",
       "15        32  0.983441\n",
       "16        40  0.983441\n",
       "17        41  0.983441\n",
       "18        43  0.983448\n",
       "19        46  0.983441\n",
       "20        48  0.760924\n",
       "21        54  0.983441\n",
       "22        64  0.735791\n",
       "23        66  0.967837\n",
       "24        68  0.983441\n",
       "25        76  0.983441\n",
       "26        78  0.983441\n",
       "27        79  0.935457\n",
       "28        80  0.983441\n",
       "29        85  0.983441\n",
       "..       ...       ...\n",
       "97       336  0.983441\n",
       "98       337  0.983441\n",
       "99       341  0.251132\n",
       "100      343  0.983441\n",
       "101      348  0.983441\n",
       "102      368  0.983441\n",
       "103      370  0.983441\n",
       "104      374  0.979706\n",
       "105      377  0.983441\n",
       "106      380  0.983457\n",
       "107      382  0.983441\n",
       "108      387  0.983441\n",
       "109      388  0.983441\n",
       "110      389  0.983441\n",
       "111      394  0.983441\n",
       "112      395  0.980122\n",
       "113      396  0.980122\n",
       "114      397  0.983441\n",
       "115      398  0.983441\n",
       "116      401  0.983441\n",
       "117      403  0.983441\n",
       "118      404  0.983441\n",
       "119      410  0.983441\n",
       "120      413  0.251132\n",
       "121      421  0.983441\n",
       "122      424  0.251132\n",
       "123      425  0.545959\n",
       "124      429  0.763796\n",
       "125      430  0.983441\n",
       "126      431  0.819661\n",
       "\n",
       "[127 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################################\n",
    "############ GBM with hyper-parameter tuning\n",
    "############################################################################\n",
    "np.random.seed(100)\n",
    "estimators = gsearch1.best_estimator_.n_estimators\n",
    "max_depth=gsearch1.best_estimator_.max_depth\n",
    "max_features=gsearch1.best_estimator_.max_features\n",
    "min_samples_leaf=gsearch1.best_estimator_.min_samples_leaf\n",
    "n_estimators=gsearch1.best_estimator_.n_estimators\n",
    "random_state=gsearch1.best_estimator_.random_state\n",
    "\n",
    "GBM_prod_tune = GradientBoostingClassifier(n_estimators = estimators ,max_depth=max_depth, max_features=max_features,min_samples_leaf=min_samples_leaf,random_state = random_state )\n",
    "GBM_prod_model_tune = GBM_prod_tune.fit(train_prod_X, train_prod_Y)\n",
    "GBM_prod_prediction_tune = GBM_prod_tune.predict_proba(test_prod_X)[:,1]\n",
    "\n",
    "sub_GBM_tune = pd.DataFrame({'inst_id' : sub_id , 'OC' : GBM_prod_prediction_tune })\n",
    "sub_GBM_tune = sub_GBM_tune[['inst_id', 'OC']]\n",
    "sub_GBM_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Check the over-fitting of tuned model (using 5-fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM 함수를 만들고 교차 검증을 수행하는데 도움을 주는 함수\n",
    "def modelfit(alg, dtrain, predictors, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    global train_prod_Y\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors],train_prod_Y)\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    #Perform cross-validation:\n",
    "    if performCV:\n",
    "        cv_score = cross_val_score(alg, dtrain[predictors], train_prod_Y, cv=cv_folds, scoring='roc_auc')\n",
    "    \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % accuracy_score(train_prod_Y.values, dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % roc_auc_score(train_prod_Y, dtrain_predprob))\n",
    "    \n",
    "    if performCV:\n",
    "        print (\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "        \n",
    "    #Print Feature Importance:\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 1\n",
      "AUC Score (Train): 1.000000\n",
      "CV Score : Mean - 0.7118572 | Std - 0.1704452 | Min - 0.4824561 | Max - 0.9824561\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x207f8179438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train_prod.columns if x not in [target,IDcol]]\n",
    "modelfit(GBM_prod_tune, train_prod_X, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Calculate the cut-off value for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the optimal cut-off value (0.5~0.8 by 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " cut-off value :  0.5\n",
      "----------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       open       0.57      0.31      0.40        13\n",
      "      close       0.93      0.97      0.95       114\n",
      "\n",
      "avg / total       0.89      0.91      0.89       127\n",
      "\n",
      "0.905511811023622\n",
      "============================================================\n",
      " cut-off value :  0.6\n",
      "----------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       open       0.70      0.54      0.61        13\n",
      "      close       0.95      0.97      0.96       114\n",
      "\n",
      "avg / total       0.92      0.93      0.92       127\n",
      "\n",
      "0.9291338582677166\n",
      "============================================================\n",
      " cut-off value :  0.7\n",
      "----------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       open       0.62      0.62      0.62        13\n",
      "      close       0.96      0.96      0.96       114\n",
      "\n",
      "avg / total       0.92      0.92      0.92       127\n",
      "\n",
      "0.9212598425196851\n",
      "============================================================\n",
      " cut-off value :  0.8\n",
      "----------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       open       0.62      0.77      0.69        13\n",
      "      close       0.97      0.95      0.96       114\n",
      "\n",
      "avg / total       0.94      0.93      0.93       127\n",
      "\n",
      "0.9291338582677166\n"
     ]
    }
   ],
   "source": [
    "max_accuracy = -1\n",
    "coval_max = -1\n",
    "\n",
    "for i in range(start,end):\n",
    "    print('='*60)\n",
    "    coval = i/10\n",
    "    print(\" cut-off value : \" ,coval)\n",
    "    print('-'*22)\n",
    "\n",
    "    sub_GBM_tune_ths = sub_GBM_tune[['inst_id', 'OC']]\n",
    "    sub_GBM_tune_ths['OC'] = [1 if oc>=coval else 0 for oc in sub_GBM_tune_ths['OC']]\n",
    "    y_prod = list(sub_GBM_tune_ths['OC'])\n",
    "    print(classification_report(y_true, y_prod, target_names=['open', 'close']))\n",
    "    print(accuracy_score(y_true,y_prod))\n",
    "\n",
    "    if max_accuracy < accuracy_score(y_true,y_prod):\n",
    "        max_accuracy = accuracy_score(y_true,y_prod)\n",
    "        coval_max = coval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal cut-off value (according to 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_GBM = coval_max\n",
    "cutoff_GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Compare orginal model to tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defalut model\n",
    "- n_estimators: default\n",
    "- max_features: default\n",
    "- max_depth: default\n",
    "- min_sample_split: default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ GBM\n",
    "############################################################################\n",
    "np.random.seed(100)\n",
    "GBM_prod = GradientBoostingClassifier()\n",
    "GBM_prod_model = GBM_prod.fit(train_prod_X, train_prod_Y)\n",
    "GBM_prod_prediction = GBM_prod.predict_proba(test_prod_X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare 2 models with optimal cut-off value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_GBM = pd.DataFrame({'inst_id' : sub_id , 'OC' : GBM_prod_prediction })\n",
    "sub_GBM = sub_GBM[['inst_id', 'OC']]\n",
    "sub_GBM['OC'] = [1 if oc>=cutoff_GBM else 0 for oc in sub_GBM['OC']]\n",
    "y_prod = list(sub_GBM['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_GBM_customized = sub_GBM_tune[['inst_id', 'OC']]\n",
    "sub_GBM_customized['OC'] = [1 if oc >= cutoff_GBM else 0 for oc in sub_GBM_customized['OC']] # 확률값을 1,0으로 변환\n",
    "y_prod_customized = list(sub_GBM_customized['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Before tuned============\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.80      0.92      0.86        13\n",
      "    class 1       0.99      0.97      0.98       114\n",
      "\n",
      "avg / total       0.97      0.97      0.97       127\n",
      "\n",
      "0.968503937007874\n",
      "============After tuned============\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.70      0.54      0.61        13\n",
      "    class 1       0.95      0.97      0.96       114\n",
      "\n",
      "avg / total       0.92      0.93      0.92       127\n",
      "\n",
      "0.9291338582677166\n"
     ]
    }
   ],
   "source": [
    "# Before tuned\n",
    "print('============Before tuned============')\n",
    "print(classification_report(y_true, y_prod, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod))\n",
    "# After tuned\n",
    "print('============After tuned============')\n",
    "print(classification_report(y_true, y_prod_customized, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod_customized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification Model(3) -XGBOOST\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;GBM보다 속도와 성능이 향상된 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Hyperparameter tuning of XGBOOST (using 3-fold cross validation)\n",
    "- eta: The learning rate.\n",
    "- num_boost_round: The number of boosting rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_prod = xgb.DMatrix(data = train_prod_X, label = train_prod_Y)\n",
    "dtest_prod = xgb.DMatrix(data = test_prod_X)\n",
    "\n",
    "#Custom error function for the XGB model\n",
    "threshold = 0.5\n",
    "def eval_error(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = (preds > threshold ).astype('float')\n",
    "    return \"accuracy\", accuracy_score(labels, preds)\n",
    "    \n",
    "\n",
    "param_tmp = {'eta': [0.1, 0.2, 0.3, 0.4]}\n",
    "nrounds = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed:   59.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed:   59.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x00000207F813C620>,\n",
       "       error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "       colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "       gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "       learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "       min_child_w..._pos_weight=None, subsample=None,\n",
       "       tree_method=None, validate_parameters=None, verbosity=None),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'eta': [0.1, 0.2, 0.3, 0.4]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='accuracy',\n",
       "       verbose=2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier = XGBClassifier(objective='binary:logistic',nthread=1)\n",
    "skf = StratifiedKFold(n_splits=3, shuffle = True, random_state = 42)\n",
    "\n",
    "grid_search_XGB = GridSearchCV(xgb_classifier, param_grid = param_tmp, scoring='accuracy', n_jobs=4, cv=skf.split(train_prod_X, train_prod_Y), verbose=2)\n",
    "grid_search_XGB.fit(train_prod_X, train_prod_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the best hyperparameter combination and train the GBM model with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta': 0.1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_XGB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ XGBOOST - tuning\n",
    "############################################################################\n",
    "np.random.seed(100)\n",
    "best_param = {'eta': grid_search_XGB.best_params_['eta']}\n",
    "\n",
    "xgb_model_tune = xgb.train(best_param, \n",
    "                      dtrain_prod, \n",
    "                      num_boost_round = nrounds ,\n",
    "                      feval = eval_error,\n",
    "                      #maximize = True,\n",
    "                      #early_stopping_rounds = 10,\n",
    "                      )\n",
    "\n",
    "XGB_prediction = xgb_model_tune.predict(dtest_prod)\n",
    "sub_XGB_tune= pd.DataFrame({'inst_id' : sub_id , 'OC' : XGB_prediction })\n",
    "sub_XGB_tune= sub_XGB_tune[['inst_id', 'OC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwgAAAEKCAYAAAC2UnI1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xu0XVV59/HvD8ItEMJVRZAGUwSBYoBAlYuiIK1ULSoU8QatFS8gBUtbrS1Shg6heHl91aqRKqjUCwHUUspFhQBRLgmEcNciqBEq8iIkoNyf94+9st0ek5yT5Oyzzs75fsbY46w111xzPmsNJfvZc861UlVIkiRJEsBabQcgSZIkafwwQZAkSZLUZYIgSZIkqcsEQZIkSVKXCYIkSZKkLhMESZIkSV0mCJIkSZK6TBAkSZIkdZkgSJIkSeqa1HYAE90WW2xR06ZNazsMSZIkreHmz59/f1VtOVw9E4SWTZs2jXnz5rUdhiRJktZwSX4yknpOMZIkSZLU5QhCy25b9P/Y4+++1HYYA2v+6W9pOwRJkqQ1iiMIkiRJkrpMECRJkiR1mSBIkiRJ6jJBkCRJktRlgiBJkiSpywRhBJLsmGRBkhuSTE/y/aZ8WpI39NTbPMllSR5O8qn2IpYkSZJWjQlCI8naKzh8CPCtqtqtqu6sqr2b8mnAG3rqPQr8M3Bif6KUJEmS+mtCJAjNL/23JzkrycIks5NMTnJ3kpOSXAUclmRGkqubOucn2TTJwcDxwF8nuaxp7+Gm6VOB/ZrRhROq6pGquopOoiBJkiQNnAmRIDR2AGZV1a7AYuBdTfmjVbVvVX0N+BLwD02dm4APVNWFwGeBj1fVS4e0+V7gyqqaUVUfH2kgSY5OMi/JvCd/vWR1r0uSJEkaNRMpQfhZVc1ttr8C7Ntsfx0gyVRgk6qa05SfBby4H4FU1ayqmllVMydNntKPLiRJkqRVMpEShFrO/iNjHYgkSZI0Xk2kBGHbJC9qto8Aruo9WFUPAb9Ksl9T9GZgDiu2BHAIQJIkSWuMiZQg3AYcmWQhsBnwmWXUORI4vakzAzhlmDYXAk8muTHJCQBJ7gY+BhyVZFGSnUbrAiRJkqR+m9R2AGPo6ap6x5Cyab07VbUAeOHQE6vq5CH7GzV/nwAOGHLsd9qUJEmSBslEGkGQJEmSNIwJMYJQVXcDu7QdhyRJkjTeOYIgSZIkqcsEQZIkSVLXhJhiNJ49f5vNmXf6W9oOQ5IkSQIcQZAkSZLUwwRBkiRJUpcJgiRJkqQuEwRJkiRJXS5Sbtnj997CT0/5o7bDGFjbnnRT2yFIkiStURxBkCRJktRlgiBJkiSpywRBkiRJUpcJgiRJkqQuEwRJkiRJXX1PEJJsk+RbSX6U5M4kn0iybh/6eUuSm5PckuTWJCf2HJuU5P4kHx7lPqcleUPP/uZJLkvycJJPjWZfkiRJ0ljoa4KQJMB5wDeranvgecBGwIdGuZ9XAMcDB1XVzsDuwEM9VQ4C7gD+oolptEwD3tCz/yjwz8CJy6wtSZIkjXP9HkF4GfBoVX0RoKqeAk4A/irJu5Kcl+SiZnThX5eelOSIJDc1IwKn9ZQ/nORDSW5McnWSZzaH3gecWFX3NP08WlWf74njCOATwE+BF/a0d2oz2rAwyUeassOafm9MckVTtnaS05Nc19R9e9PEqcB+SRYkOaGqHqmqq+gkCpIkSdLA6feL0nYG5vcWVNXiJD9t+p4B7AY8BtyR5JPAU8BpwB7Ar4BLkhxSVd8ENgSurqr3NwnF24APArsM7WepJBsABwBvBzahkyz8IMlmwGuAHauqkmzSnHIS8CdV9fOesrcCD1XVnknWA+YmuQR4L53E5JWreZ8kSZKkcaHfIwgBagXl362qh6rqUeBW4A+APYHLq+qXVfUkcDbw4ua8x4ELmu35dKb4DOeVwGVV9WvgXOA1SdYGFtP5pf+MJK8Fft3UnwucmeRtwNpN2UHAW5IsAK4BNge2H0Hfy5Tk6CTzksx74JGnVrUZSZIkadT1O0G4BZjZW5BkY+A5dEYKHus59BSdUYUVrRF4oqpqSP2l/eyxnHOOAA5McjedpGJz4KVN8rEXnaThEOAigKp6B/BPTYwLkmzexPTuqprRfLarqkuGufblqqpZVTWzqmZutuHaw58gSZIkjZF+JwjfBSYneQt05vIDHwXO5Le/2A91DfCSJFs09Y8A5gzTz4eBf03yrKaf9ZIc1yQj+wLbVtW0qpoGHAMckWQjYGpVXUhngfOM5tzpVXVNVZ0E3E8nUbgYeGeSdZo6z0uyIbAEmLLSd0WSJEkap/qaIDS/9r8GOCzJj4Af0pnW848rOOdeOouOLwNuBK6vqm8N08+FwKeB7yS5hc5IwSTgtcD3qqp3pOJbwKvpjCRckGQhnQTkhOb46UsXSANXNDGcQWcK1PVN+eea9hcCTzYLmk8AaEYqPgYclWRRkp2Gv1OSJEnS+JDfzthRG3bdeoO64O1/2HYYA2vbk25qOwRJkqSBkGR+Vc0crp5vUpYkSZLUZYIgSZIkqcsEQZIkSVKXCYIkSZKkrn6/SVnDWHerndn2pHlthyFJkiQBjiBIkiRJ6mGCIEmSJKnLBEGSJElSlwmCJEmSpC4XKbfs9vtuZ59P7tN2GJqg5r57btshSJKkccYRBEmSJEldJgiSJEmSukwQJEmSJHWZIEiSJEnqMkGQJEmS1GWCMAJJdkyyIMkNSaYn+X5TPi3JG3rqvTzJ/CQ3NX9f1l7UkiRJ0sozQWgkWXsFhw8BvlVVu1XVnVW1d1M+DXhDT737gVdV1R8BRwJf7kuwkiRJUp9MiASh+aX/9iRnJVmYZHaSyUnuTnJSkquAw5LMSHJ1U+f8JJsmORg4HvjrJJc17T3cNH0qsF8zunBCVd1QVfc0x24B1k+y3phfsCRJkrSKJkSC0NgBmFVVuwKLgXc15Y9W1b5V9TXgS8A/NHVuAj5QVRcCnwU+XlUvHdLme4Erq2pGVX18yLHXATdU1WP9uiBJkiRptE2kBOFnVbX0tbFfAfZttr8OkGQqsElVzWnKzwJevCodJdkZOA14+3KOH51kXpJ5Tzz8xKp0IUmSJPXFREoQajn7j4xmJ0m2Ac4H3lJVdy4zkKpZVTWzqmaus9E6o9m9JEmStFomUoKwbZIXNdtHAFf1Hqyqh4BfJdmvKXozMIcVWwJMWbqTZBPgv4D39YxWSJIkSQNjIiUItwFHJlkIbAZ8Zhl1jgROb+rMAE4Zps2FwJNJbkxyAnAs8IfAPzcLlxckecboXYIkSZLUX5PaDmAMPV1V7xhSNq13p6oWAC8cemJVnTxkf6Pm7xPAAUOqf3B1A5UkSZLaMpFGECRJkiQNY0KMIFTV3cAubcchSZIkjXeOIEiSJEnqMkGQJEmS1DUhphiNZzs+Y0fmvtsnokqSJGl8cARBkiRJUpcJgiRJkqQuEwRJkiRJXSYIkiRJkrpcpNyyJXfcwZwXv6TtMDRBveSKOW2HIEmSxhlHECRJkiR1mSBIkiRJ6jJBkCRJktRlgiBJkiSpywRBkiRJUlffEoQkleSjPfsnJjm5Z/8tSW5OckuSW5Oc2JSfmeTQIW09O8nsYfrbP8kFyzl2YZJNmu2Hh7aZZEaSg3vqvzrJe1f6ojvnXpTkweXFIkmSJI1n/RxBeAx4bZIthh5I8grgeOCgqtoZ2B14aHkNVdU9VXXo8o4Pp6oOrqoHV9DmDODgnmPfrqpTV7G704E3r+K5kiRJUqv6mSA8CcwCTljGsfcBJ1bVPQBV9WhVfX55DSWZluTmnu0rk1zffPbuqbpxkvObEYnPJlmrOefuoYnK0jaTrAucAhyeZEGSw5McleRTTb0tk5yb5Lrms09T/pKm/oIkNySZ0lzLd4Elq3bLJEmSpHb1ew3Cp4E3Jpk6pHwXYP4qtnkf8PKq2h04HPi/Pcf2Av4W+CNgOvDa4RqrqseBk4CvV9WMqvr6kCqfAD5eVXsCrwPOaMpPBI6pqhnAfsBvVvF6JEmSpHGjr29SrqrFSb4EHMfofYFeB/hUkhnAU8Dzeo5dW1U/BkjyVWBfYIVrF0bgQGCnJEv3N25GC+YCH0tyNnBeVS0aaYNJjgaOBnjmeuutZniSJEnS6BmLpxj9H+CtwIY9ZbcAe6xieycAvwBeAMwE1u05VkPqDt1fFWsBL2pGF2ZU1dZVtaRZo/DXwAbA1Ul2HGmDVTWrqmZW1cyp66wzCiFKkiRJo6PvCUJVPQB8g06SsNSHgX9N8iyAJOslOW6ETU4F7q2qp+ksBl6759heSbZr1h4cDlw1wjaXAFOWc+wS4NilO83IBUmmV9VNVXUaMA8YcYIgSZIkjVdj9R6EjwLdRcJVdSGd9QnfSXILnfUIvdOdPpdkUfP5wZC2/g04MsnVdKYXPdJz7AfAqcDNwF3A+SOM7zI604gWJDl8yLHjgJlJFia5FXhHU358s8j5RjrTp/4bIMmVwDnAAU38fzLCGCRJkqTWpWrlZuEk2RR4TlUt7E9IE8sOU6bUrN12bzsMTVAvuWJO2yFIkqQxkmR+Vc0crt6IRhCSXJ5k4ySbATcCX0zysdUNUpIkSdL4MtIpRlOrajGdx4Z+sar2oPN0H0mSJElrkJEmCJOSbAX8BXBBH+ORJEmS1KKRJginABcDd1bVdUmeC/yof2FJkiRJasOIXpRWVefQeTLP0v0f03mrsCRJkqQ1yIgShCTPAz4DPLOqdkmyK/DqqvpgX6ObAKbssINPkpEkSdK4MdIpRp8H3gc8AdA84vT1/QpKkiRJUjtGmiBMrqprh5Q9OdrBSJIkSWrXSBOE+5NMBwogyaHAvX2LSpIkSVIrRrQGATgGmAXsmOTnwF3AG/sW1QRy36KH+NTf/mfbYWiCOvajr2o7BEmSNM4MmyAkWQuYWVUHJtkQWKuqlvQ/NEmSJEljbdgpRlX1NHBss/2IyYEkSZK05hrpGoRLk5yY5DlJNlv66WtkkiRJksbcSNcg/FXz95iesgKeO7rhSJIkSWrTSN+kvF2/A5EkSZLUvpG+Sfktyyqvqi+Nbjj9keThqtpoDPp5DvAl4FnA08CsqvpEv/uVJEmSRstIpxjt2bO9PnAAcD2dL8P6rSeBv62q65NMAeYnubSqbm07MEmSJGkkRrRIuare3fN5G7AbsG4/AkrypiTXJlmQ5HNJ1k7ycJLTksxP8p0keyW5PMmPk7y6Oe+oJN9KclGSO5J8YBltJ8npSW5OclOSw5vyLyf58556Zyd5ddP36UmuS7Iwydt76vxdT/m/NPfp3qq6vtleAtwGbN2P+yRJkiT1w0ifYjTUr4HtRzMQgCTPBw4H9qmqGcBTdF7ItiFweVXtASwBPgi8HHgNcEpPE3s19WcAhyWZOaSL1zbHXgAcCJyeZCvgDOAvmximAnsDFwJvBR6qqj3pjKK8Lcl2SQ6ic/17Ne3tkeTFQ65lGp1E6prVuyuSJEnS2BnpGoT/pPPUIugkFTsB5/QhngOAPYDrkgBsANwHPA5c1NS5CXisqp5IchMwref8S6vq/zUxnwfsC8zrOb4v8NWqegr4RZI5wJ5V9e0kn07yDDpJxLlV9WSTCOya5NDm/Kl0EoODms8NTflGTfkVTd8bAecCx1fV4qEXmeRo4GiATadsufJ3SZIkSeqTka5B+EjP9pPAT6pqUR/iCXBWVb3vdwqTE6tqaYLyNPAYdF7ilqT3GorfNXQ/K+j7y3RGH17Pbx/rGuDdVXXxkHj+BPhwVX3u9y4gWYdOcnB2VZ23rI6qahYwC2DbZ20/NEZJkiSpNSOdYnRwVc1pPnOralGS0/oQz3eBQ5tf8mleyPYHK3H+y5tzNgAOAeYOOX4FcHiztmBL4MXAtc2xM4HjAarqlqbsYuCdzZd+kjwvyYZN+V81IwUk2TrJM9IZ9vh34Laq+thKXbkkSZI0Dow0QXj5MspeMZqBADRP+/kn4JIkC4FLga1Woomr6IwELKAzTWjekOPnAwuBG4HvAX9fVf/b9P0LOouKv9hT/wzgVuD6JDcDnwMmVdUlwH8AP2imOc0GpgD7AG8GXtYssl6Q5OCViF+SJElqVX47c2cZB5N3Au+i88bkO3sOTQHmVtWb+hveyCU5CphZVceu4vmT6axv2L2qHhrN2FZk22dtX3//Rgcb1I5jP/qqtkOQJEljJMn8qhr6EJ/fM9wahP8A/hv4MPDenvIlVfXAasQ3riQ5EPgC8LGxTA4kSZKk8WaFCULzZfkh4AiAZm3A+sBGSTaqqp/2P8SRqaoz6awjWJVzvwNsO5rxSJIkSYNoRGsQkrwqyY+Au4A5wN10RhYkSZIkrUFGukj5g8ALgR9W1XZ03lcw9AlBkiRJkgbcSBOEJ5oXkK2VZK2quozOG4QlSZIkrUFG+qK0B5tn/l8JnJ3kPjovTNNqesY2U32SjCRJksaNkY4g/DnwazovEruIziNP/VYrSZIkrWFGNIJQVY80bzTevqrOat4ZsHZ/Q5MkSZI01kb6FKO30Xlb8Oeaoq2Bb/YrKEmSJEntGOkUo2OAfYDFAFX1I+AZ/QpKkiRJUjtGukj5sap6PAkASSYB1beoJpB777qTD73p0LbD0AT1/q/MbjsESZI0zox0BGFOkn8ENkjycuAc4D/7F5YkSZKkNow0QXgv8EvgJuDtwIXAP/UrKEmSJEntWOEUoyTbVtVPq+pp4PPNR5IkSdIaargRhO6TipKc2+dYJEmSJLVsuAQhPdvP7WcgkiRJkto3XIJQy9luVZLvj6DO8c0L3foZx4wkB/fs75jkB0keS3JiP/uWJEmS+mG4BOEFSRYnWQLs2mwvTrIkyeKxCHBZqmrvEVQ7HlipBCHJyr4degZwcM/+A8BxwEdWsh1JkiRpXFhhglBVa1fVxlU1paomNdtL9zceqyCHSvJw83f/JJcnmZ3k9iRnp+M44NnAZUkua+oe1Py6f32Sc5Js1JTfneSkJFcBhyWZnuSiJPOTXJlkx6beYUluTnJjkiuSrAucAhyeZEGSw6vqvqq6DniijfsiSZIkra6RvihtPNsN2Bm4B5gL7FNV/zfJe4CXVtX9Sbag81jWA6vqkST/ALyHzhd8gEeral+AJN8F3lFVP0ryx8C/AS8DTgL+pKp+nmST5sVxJwEzq+rYlQk4ydHA0QBTJ2+wmpcvSZIkjZ41IUG4tqoWASRZAEwDrhpS54XATsDc5m3Q6wI/6Dn+9eb8jYC9gXOWvjUaWK/5Oxc4M8k3gPNWJ+CqmgXMAth6803HzdoOSZIkaU1IEB7r2X6KZV9TgEur6ojltPFI83ct4MGqmjG0QlW9oxlR+DNgQZLfqyNJkiQNupG+SXkQLQGmNNtXA/sk+UOAJJOTPG/oCVW1GLgryWFNvSR5QbM9vaquqaqTgPuB5wzpQ5IkSRp4a3KCMAv47ySXVdUvgaOAryZZSCdh2HE5570ReGuSG4FbgD9vyk9PclOSm4ErgBuBy4Cdli5STvKsJIvorG/4pySLkrS2mFuSJElaWalyCnybtt5803rXKw5oOwxNUO//yuy2Q5AkSWMkyfyqmjlcvTV5BEGSJEnSSjJBkCRJktRlgiBJkiSpywRBkiRJUtea8B6EgbbVdtNdKCpJkqRxwxEESZIkSV0mCJIkSZK6TBAkSZIkdZkgSJIkSepykXLLHr13Cbd96Htth6EJ6vnvf1nbIUiSpHHGEQRJkiRJXSYIkiRJkrpMECRJkiR1mSBIkiRJ6jJBkCRJktRlggAk2T/JQ0luSHJHkiuSvHKE5+09FjFKkiRJY8HHnP7WlVX1SoAkM4BvJvlNVX13BefsDzwMfH8M4pMkSZL6bmBGEJK8J8nNzef4JNOS3J7krCQLk8xOMrmpu0eSOUnmJ7k4yVZN+eVJTktybZIfJtlvWX1V1QLgFODY5rxXJbmmGWH4TpJnJpkGvAM4IcmCJPsl2TLJuUmuaz77jMW9kSRJkkbLQCQISfYA/hL4Y+CFwNuATYEdgFlVtSuwGHhXknWATwKHVtUewBeAD/U0N6mq9gKOBz6wgm6vB3Zstq8CXlhVuwFfA/6+qu4GPgt8vKpmVNWVwCea/T2B1wFnLOd6jk4yL8m8Bx55cCXvhiRJktQ/gzLFaF/g/Kp6BCDJecB+wM+qam5T5yvAccBFwC7ApUkA1gbu7WnrvObvfGDaCvpMz/Y2wNebkYh1gbuWc86BwE5NvwAbJ5lSVUt6K1XVLGAWwC5b71AriEGSJEkaU4OSIGQ55UO/XFdT95aqetFyznms+fsUK77+3YDbmu1PAh+rqm8n2R84eTnnrAW8qKp+s4J2JUmSpHFrIKYYAVcAhySZnGRD4DXAlcC2SZYmAkfQmQp0B7Dl0vIk6yTZeWU6S7Ir8M/Ap5uiqcDPm+0je6ouAab07F9Cs26haWfGyvQrSZIktW0gEoSquh44E7gWuIbO3P5f0fmF/8gkC4HNgM9U1ePAocBpSW4EFgAjeRTpfksfc0onMTiu5wlGJwPnJLkSuL/nnP8EXrN0kTKdKU4zm0XTt9JZxCxJkiQNjFQN5hT45ilCF1TVLi2Hslp22XqHOuddn2k7DE1Qz3//y9oOQZIkjZEk86tq5nD1BmIEQZIkSdLYGJRFyr+neczoQI8eSJIkSeONIwiSJEmSukwQJEmSJHUN7BSjNcX6W01xoagkSZLGDUcQJEmSJHWZIEiSJEnqMkGQJEmS1GWCIEmSJKnLRcotu+eeezj55JPbDkPSKvD/u5KkNZEjCJIkSZK6TBAkSZIkdZkgSJIkSeoyQZAkSZLUZYIgSZIkqcsEQZIkSVLXhEkQknx/Fc87JMlOw9Q5JcmByyjfP8kFq9KvJEmS1IYJkyBU1d6reOohwAoThKo6qaq+s4rtS5IkSePGhEkQkjzc/N0/yeVJZie5PcnZSdIcOzXJrUkWJvlIkr2BVwOnJ1mQZPpy2j4zyaHN9p827V4FvHaMLk+SJEkaFRP1Tcq7ATsD9wBzgX2S3Aq8BtixqirJJlX1YJJvAxdU1ezhGk2yPvB54GXA/wBfX069o4GjAaZOnToa1yNJkiSNigkzgjDEtVW1qKqeBhYA04DFwKPAGUleC/x6FdrdEbirqn5UVQV8ZVmVqmpWVc2sqpmTJ09etSuQJEmS+mCiJgiP9Ww/BUyqqieBvYBz6aw7uGgV267VjE2SJElqzUSdYvR7kmwETK6qC5NcTWeKEMASYMoIm7kd2C7J9Kq6EziiD6FKkiRJfTNRRxCWZQpwQZKFwBzghKb8a8DfJblheYuUl6qqR+msLfivZpHyT/oZsCRJkjTaJswIQlVt1Py9HLi8p/zYnmp7LeO8uQz/mNOjerYvorMWQZIkSRo4jiBIkiRJ6powIwijIcmngX2GFH+iqr7YRjySJEnSaDNBWAlVdUzbMUiSJEn9lM7j+tWWmTNn1rx589oOQ5IkSWu4JPOrauZw9VyDIEmSJKnLBEGSJElSlwmCJEmSpC4TBEmSJEldPsWoZb/61W1845zfez+bJEmS1jB/cdi1bYcwIo4gSJIkSeoyQZAkSZLUZYIgSZIkqcsEQZIkSVKXCYIkSZKkroFJEJJMS3LzaJybZK8kVyS5I8ntSc5IMnn0ooUkRyV59mi2KUmSJPXbwCQIoyXJM4FzgH+oqh2A5wMXAVNGuaujABMESZIkDZRBSxAmJTkrycIks5NMTrJHkjlJ5ie5OMlWAE35jUl+ABzT08YxwFlV9QOA6phdVb9IslmSbzbtX51k16atk5OcuLSBJDc3oxLTktyW5PNJbklySZINkhwKzATOTrIgyQZjdockSZKk1TBoCcIOwKyq2hVYTOfL/ieBQ6tqD+ALwIeaul8EjquqFw1pYxdg/nLa/xfghqb9fwS+NIKYtgc+XVU7Aw8Cr6uq2cA84I1VNaOqfjPiK5QkSZJaNGhvUv5ZVc1ttr9C50v8LsClSQDWBu5NMhXYpKrmNHW/DLxiBO3vC7wOoKq+l2Tzpq0VuauqFjTb84Fpw3WS5GjgaIAttlh3BGFJkiRJY2PQEoQasr8EuGXoKEGSTZZRd6lbgD2Aby3jWJbT55P87mjL+j3bj/VsPwUMO52oqmYBswCmT99weXFKkiRJY27Qphhtm2RpMnAEcDWw5dKyJOsk2bmqHgQeSrJvU/eNPW18CjgyyR8vLUjypiTPAq5YWjfJ/sD9VbUYuBvYvSnfHdhuBLEuYfQXPkuSJEl9NWgJwm10vtwvBDajWX8AnJbkRmABsHdT9y+BTzeLlLtrAKrqF8DrgY80jzm9DdiPzpqGk4GZTfunAkc2p50LbJZkAfBO4IcjiPVM4LMuUpYkSdIgSZUzXNo0ffqG9eFTd247DEmSJPXZXxx2bav9J5lfVTOHqzdoIwiSJEmS+sgEQZIkSVKXCYIkSZKkLhMESZIkSV2D9h6ENc6mmz6/9QUrkiRJ0lKOIEiSJEnqMkGQJEmS1OV7EFqWZAlwR9txDLAtgPvbDmKAef9Wj/dv1XnvVo/3b/V4/1ad9271tH3//qCqthyukmsQ2nfHSF5YoWVLMs/7t+q8f6vH+7fqvHerx/u3erx/q857t3oG5f45xUiSJElSlwmCJEmSpC4ThPbNajuAAef9Wz3ev9Xj/Vt13rvV4/1bPd6/Vee9Wz0Dcf9cpCxJkiSpyxEESZIkSV0mCC1K8qdJ7kjyP0ne23Y8gyTJF5Lcl+TmtmMZNEmek+SyJLcluSXJ37Qd0yBJsn6Sa5Pc2Ny/f2k7pkGUZO0kNyS5oO1YBk2Su5PclGRBknltxzNIkmySZHaS25v/Br6o7ZgGRZIdmv/NLf0sTnJ823ENkiQnNP9u3Jzkq0nWbzum5XGKUUuSrA38EHg5sAi4Djiiqm5tNbABkeTFwMPAl6pql7bjGSRJtgK2qqrrk0wB5gOH+L+9kUkSYMOqejjJOsBVwN9U1dUthzZQkrwHmAlsXFWvbDueQZLkbmBmVfks+pWU5Czgyqo6I8m6wOSqerDtuAZN8x3m58AfV9VP2o5nECTZms6/FztV1W+SfAO4sKrObDeyZXMEoT17Af9TVT+uqseBrwF/3nJMA6OqrgAeaDuOQVRV91bV9c0Z8z2dAAAFXUlEQVT2EuA2YOt2oxoc1fFws7tO8/GXlpWQZBvgz4Az2o5FE0eSjYEXA/8OUFWPmxyssgOAO00OVtokYIMkk4DJwD0tx7NcJgjt2Rr4Wc/+IvySpjGWZBqwG3BNu5EMlmZ6zALgPuDSqvL+rZz/A/w98HTbgQyoAi5JMj/J0W0HM0CeC/wS+GIzve2MJBu2HdSAej3w1baDGCRV9XPgI8BPgXuBh6rqknajWj4ThPZkGWX+Cqkxk2Qj4Fzg+Kpa3HY8g6SqnqqqGcA2wF5JnOY2QkleCdxXVfPbjmWA7VNVuwOvAI5pplxqeJOA3YHPVNVuwCOA6/9WUjM169XAOW3HMkiSbEpnpsh2wLOBDZO8qd2ols8EoT2LgOf07G/DOB5q0pqlmTt/LnB2VZ3XdjyDqpmecDnwpy2HMkj2AV7dzKP/GvCyJF9pN6TBUlX3NH/vA86nM2VVw1sELOoZ8ZtNJ2HQynkFcH1V/aLtQAbMgcBdVfXLqnoCOA/Yu+WYlssEoT3XAdsn2a7Jxl8PfLvlmDQBNIts/x24rao+1nY8gybJlkk2abY3oPMf/dvbjWpwVNX7qmqbqppG579736uqcfsr2niTZMPm4QI002MOAnya2whU1f8CP0uyQ1N0AODDGVbeETi9aFX8FHhhksnNv8MH0FkDOC5NajuAiaqqnkxyLHAxsDbwhaq6peWwBkaSrwL7A1skWQR8oKr+vd2oBsY+wJuBm5p59AD/WFUXthjTINkKOKt5isdawDeqykd1aqw8Ezi/8/2CScB/VNVF7YY0UN4NnN38MPdj4C9bjmegJJlM5+mLb287lkFTVdckmQ1cDzwJ3MA4fquyjzmVJEmS1OUUI0mSJEldJgiSJEmSukwQJEmSJHWZIEiSJEnqMkGQJEmS1GWCIEkaFUkeHuP+piV5w1j2KUkTgQmCJGngJJkETANMECRplPmiNEnSqEqyP/AvwC+AGcB5wE3A3wAbAIdU1Z1JzgQeBXam8wKw91TVBUnWBz4DzKTzQqH3VNVlSY4C/gxYH9gQmAw8v3nh31nA+cCXm2MAx1bV95t4TgbuB3YB5gNvqqpKsifwieacx+i83fTXwKl0Xsa4HvDpqvrcaN8nSRqvTBAkSf3wAuD5wAN03lh7RlXtleRv6LzN9vim3jTgJcB04LIkfwgcA1BVf5RkR+CSJM9r6r8I2LWqHmi++J9YVa+E377ltaoeTbI98FU6SQbAbnQSkXuAucA+Sa4Fvg4cXlXXJdkY+A3wVuChqtozyXrA3CSXVNVdfbhPkjTumCBIkvrhuqq6FyDJncAlTflNwEt76n2jqp4GfpTkx8COwL7AJwGq6vYkPwGWJgiXVtUDy+lzHeBTSWYAT/WcA3BtVS1q4llAJzF5CLi3qq5r+lrcHD8I2DXJoc25U4HtARMESROCCYIkqR8e69l+umf/aX73354acl4BWUG7j6zg2Al0pjW9gM4au0eXE89TTQxZRv805e+uqotX0JckrbFcpCxJatNhSdZKMh14LnAHcAXwRoBmatG2TflQS4ApPftT6YwIPA28GVh7mL5vB57drEMgyZRm8fPFwDuTrLM0hiQbrqAdSVqjOIIgSWrTHcAcOouU39GsH/g34LNJbqKzSPmoqnos+b2BhYXAk0luBM4E/g04N8lhwGWseLSBqno8yeHAJ5NsQGf9wYHAGXSmIF2fTqe/BA4ZjYuVpEGQqmWNrkqS1F/NU4wuqKrZbcciSfotpxhJkiRJ6nIEQZIkSVKXIwiSJEmSukwQJEmSJHWZIEiSJEnqMkGQJEmS1GWCIEmSJKnLBEGSJElS1/8HlhGb1GJnKpIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x207f824fb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PLotting the feature importance\n",
    "xgb_Imp_tune = pd.DataFrame({'Features' : list(xgb_model_tune.get_score().keys()), \n",
    "                        'Importance' : list(xgb_model_tune.get_score().values())}).sort_values(['Importance'])\n",
    "plt.figure()\n",
    "sns.barplot(xgb_Imp_tune.Importance, xgb_Imp_tune.Features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Check the over-fitting of tuned model (using 5-fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95081967 0.95       0.95       0.95       0.95      ]\n",
      "mean :  0.9501639344262296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n"
     ]
    }
   ],
   "source": [
    "# model, train, target, cross validation\n",
    "np.random.seed(10)\n",
    "xgb_model_tune_clf = XGBClassifier(objective='binary:logistic',\n",
    "                                   learning_rate=grid_search_XGB.best_params_['eta'] )\n",
    "\n",
    "scores = cross_val_score(xgb_model_tune_clf, train_prod_X, train_prod_Y, cv=5) \n",
    "print(scores)\n",
    "print('mean : ',scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Calculate the cut-off value for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the optimal cut-off value (0.5~0.8 by 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " cut-off value :  0.5\n",
      "----------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       open       0.80      0.92      0.86        13\n",
      "      close       0.99      0.97      0.98       114\n",
      "\n",
      "avg / total       0.97      0.97      0.97       127\n",
      "\n",
      "0.968503937007874\n",
      "============================================================\n",
      " cut-off value :  0.6\n",
      "----------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       open       0.10      1.00      0.19        13\n",
      "      close       0.00      0.00      0.00       114\n",
      "\n",
      "avg / total       0.01      0.10      0.02       127\n",
      "\n",
      "0.10236220472440945\n",
      "============================================================\n",
      " cut-off value :  0.7\n",
      "----------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       open       0.10      1.00      0.19        13\n",
      "      close       0.00      0.00      0.00       114\n",
      "\n",
      "avg / total       0.01      0.10      0.02       127\n",
      "\n",
      "0.10236220472440945\n",
      "============================================================\n",
      " cut-off value :  0.8\n",
      "----------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       open       0.10      1.00      0.19        13\n",
      "      close       0.00      0.00      0.00       114\n",
      "\n",
      "avg / total       0.01      0.10      0.02       127\n",
      "\n",
      "0.10236220472440945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n"
     ]
    }
   ],
   "source": [
    "max_accuracy = -1\n",
    "coval_max = -1\n",
    "for i in range(start,end):\n",
    "    print('='*60)\n",
    "    coval = i/10\n",
    "    print(\" cut-off value : \" ,coval)\n",
    "    print('-'*22)\n",
    "\n",
    "    sub_XGB_tune_ths = sub_XGB_tune[['inst_id', 'OC']]\n",
    "    sub_XGB_tune_ths['OC'] = [1 if oc>=coval else 0 for oc in sub_XGB_tune_ths['OC']]\n",
    "    y_prod = list(sub_XGB_tune_ths['OC'])\n",
    "    print(classification_report(y_true, y_prod, target_names=['open', 'close']))\n",
    "    acc= accuracy_score(y_true,y_prod)\n",
    "    print(acc)\n",
    "    if max_accuracy < acc:\n",
    "        max_accuracy = acc\n",
    "        coval_max = coval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal cut-off value (according to 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_XGB = coval_max\n",
    "cutoff_XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Compare orginal model to tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defalut model\n",
    "- eta: default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ XGBOOST\n",
    "############################################################################\n",
    "XGB_prod = XGBClassifier()\n",
    "XGB_prod.fit(train_prod_X, train_prod_Y)\n",
    "XGB_prod_prediction = XGB_prod.predict_proba(test_prod_X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare 2 models with optimal cut-off value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_XGB= pd.DataFrame({'inst_id' : sub_id , 'OC' : XGB_prediction })\n",
    "sub_XGB= sub_XGB[['inst_id', 'OC']]\n",
    "sub_XGB['OC'] = [1 if oc>=cutoff_XGB else 0 for oc in sub_XGB['OC']]\n",
    "y_prod = list(sub_XGB['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_XGB_customized = sub_XGB_tune[['inst_id', 'OC']]\n",
    "sub_XGB_customized['OC'] = [1 if oc >= cutoff_XGB else 0 for oc in sub_XGB_customized['OC']] # 확률값을 1,0으로 변환\n",
    "y_prod_customized = list(sub_XGB_customized['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Before tuned============\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.80      0.92      0.86        13\n",
      "    class 1       0.99      0.97      0.98       114\n",
      "\n",
      "avg / total       0.97      0.97      0.97       127\n",
      "\n",
      "0.968503937007874\n",
      "============After tuned============\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.80      0.92      0.86        13\n",
      "    class 1       0.99      0.97      0.98       114\n",
      "\n",
      "avg / total       0.97      0.97      0.97       127\n",
      "\n",
      "0.968503937007874\n"
     ]
    }
   ],
   "source": [
    "# Before tuned\n",
    "print('============Before tuned============')\n",
    "print(classification_report(y_true, y_prod, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod))\n",
    "# After tuned\n",
    "print('============After tuned============')\n",
    "print(classification_report(y_true, y_prod_customized, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod_customized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고사이트   \n",
    "1. Random forest   \n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "2. GBM   \n",
    "https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "\n",
    "3. xgboost   \n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
