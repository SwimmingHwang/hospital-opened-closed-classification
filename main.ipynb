{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge shap\n",
    "# pip install xgboost\n",
    "# pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 순서\n",
    "1. 파일읽기\n",
    "2. 모델링 및 모델 분석\n",
    "    1. Randomforest\n",
    "    1. GBM\n",
    "    1. XGBoost\n",
    "3. 결론 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일 읽기  Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the train and test files\n",
    "train_prod_df = pd.read_csv('data\\\\train.csv') # 학습데이터\n",
    "test_prod_df = pd.read_csv('data\\\\test_empty.csv') # 테스트데이터 (결과값 비어있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "      <th>sido</th>\n",
       "      <th>sgg</th>\n",
       "      <th>openDate</th>\n",
       "      <th>bedCount</th>\n",
       "      <th>instkind</th>\n",
       "      <th>revenue1</th>\n",
       "      <th>salescost1</th>\n",
       "      <th>sga1</th>\n",
       "      <th>...</th>\n",
       "      <th>debt2</th>\n",
       "      <th>liquidLiabilities2</th>\n",
       "      <th>shortLoan2</th>\n",
       "      <th>NCLiabilities2</th>\n",
       "      <th>longLoan2</th>\n",
       "      <th>netAsset2</th>\n",
       "      <th>surplus2</th>\n",
       "      <th>employee1</th>\n",
       "      <th>employee2</th>\n",
       "      <th>ownerChange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>open</td>\n",
       "      <td>choongnam</td>\n",
       "      <td>73</td>\n",
       "      <td>20071228</td>\n",
       "      <td>175.0</td>\n",
       "      <td>nursing_hospital</td>\n",
       "      <td>4.217530e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.961135e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>7.589937e+08</td>\n",
       "      <td>2.228769e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.361169e+08</td>\n",
       "      <td>3.900000e+08</td>\n",
       "      <td>2.619290e+09</td>\n",
       "      <td>1.271224e+09</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>open</td>\n",
       "      <td>gyeongnam</td>\n",
       "      <td>32</td>\n",
       "      <td>19970401</td>\n",
       "      <td>410.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>801.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>open</td>\n",
       "      <td>gyeonggi</td>\n",
       "      <td>89</td>\n",
       "      <td>20161228</td>\n",
       "      <td>468.0</td>\n",
       "      <td>nursing_hospital</td>\n",
       "      <td>1.004522e+09</td>\n",
       "      <td>515483669.0</td>\n",
       "      <td>4.472197e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>234.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>open</td>\n",
       "      <td>incheon</td>\n",
       "      <td>141</td>\n",
       "      <td>20000814</td>\n",
       "      <td>353.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>7.250734e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.067740e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.775501e+10</td>\n",
       "      <td>1.701860e+10</td>\n",
       "      <td>9.219427e+09</td>\n",
       "      <td>2.073641e+10</td>\n",
       "      <td>1.510000e+10</td>\n",
       "      <td>1.295427e+10</td>\n",
       "      <td>7.740829e+09</td>\n",
       "      <td>663.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>open</td>\n",
       "      <td>gyeongnam</td>\n",
       "      <td>32</td>\n",
       "      <td>20050901</td>\n",
       "      <td>196.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>4.904354e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.765605e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.143259e+10</td>\n",
       "      <td>3.007259e+10</td>\n",
       "      <td>1.759375e+10</td>\n",
       "      <td>2.136001e+10</td>\n",
       "      <td>1.410803e+10</td>\n",
       "      <td>5.561941e+06</td>\n",
       "      <td>9.025550e+09</td>\n",
       "      <td>206.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inst_id    OC       sido  sgg  openDate  bedCount          instkind  \\\n",
       "0        1  open  choongnam   73  20071228     175.0  nursing_hospital   \n",
       "1        3  open  gyeongnam   32  19970401     410.0  general_hospital   \n",
       "2        4  open   gyeonggi   89  20161228     468.0  nursing_hospital   \n",
       "3        7  open    incheon  141  20000814     353.0  general_hospital   \n",
       "4        9  open  gyeongnam   32  20050901     196.0  general_hospital   \n",
       "\n",
       "       revenue1   salescost1          sga1  ...         debt2  \\\n",
       "0  4.217530e+09          0.0  3.961135e+09  ...  7.589937e+08   \n",
       "1           NaN          NaN           NaN  ...           NaN   \n",
       "2  1.004522e+09  515483669.0  4.472197e+08  ...  0.000000e+00   \n",
       "3  7.250734e+10          0.0  7.067740e+10  ...  3.775501e+10   \n",
       "4  4.904354e+10          0.0  4.765605e+10  ...  5.143259e+10   \n",
       "\n",
       "   liquidLiabilities2    shortLoan2  NCLiabilities2     longLoan2  \\\n",
       "0        2.228769e+08  0.000000e+00    5.361169e+08  3.900000e+08   \n",
       "1                 NaN           NaN             NaN           NaN   \n",
       "2        0.000000e+00  0.000000e+00    0.000000e+00  0.000000e+00   \n",
       "3        1.701860e+10  9.219427e+09    2.073641e+10  1.510000e+10   \n",
       "4        3.007259e+10  1.759375e+10    2.136001e+10  1.410803e+10   \n",
       "\n",
       "      netAsset2      surplus2  employee1  employee2  ownerChange  \n",
       "0  2.619290e+09  1.271224e+09       62.0       64.0         same  \n",
       "1           NaN           NaN      801.0      813.0         same  \n",
       "2  0.000000e+00  0.000000e+00      234.0        1.0         same  \n",
       "3  1.295427e+10  7.740829e+09      663.0      663.0         same  \n",
       "4  5.561941e+06  9.025550e+09      206.0      197.0         same  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prod_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "      <th>sido</th>\n",
       "      <th>sgg</th>\n",
       "      <th>openDate</th>\n",
       "      <th>bedCount</th>\n",
       "      <th>instkind</th>\n",
       "      <th>revenue1</th>\n",
       "      <th>salescost1</th>\n",
       "      <th>sga1</th>\n",
       "      <th>...</th>\n",
       "      <th>debt2</th>\n",
       "      <th>liquidLiabilities2</th>\n",
       "      <th>shortLoan2</th>\n",
       "      <th>NCLiabilities2</th>\n",
       "      <th>longLoan2</th>\n",
       "      <th>netAsset2</th>\n",
       "      <th>surplus2</th>\n",
       "      <th>employee1</th>\n",
       "      <th>employee2</th>\n",
       "      <th>ownerChange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>incheon</td>\n",
       "      <td>139</td>\n",
       "      <td>19981125.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>6.682486e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.565709e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.540643e+10</td>\n",
       "      <td>5.068443e+10</td>\n",
       "      <td>3.714334e+10</td>\n",
       "      <td>4.720000e+09</td>\n",
       "      <td>4.690000e+09</td>\n",
       "      <td>1.608540e+10</td>\n",
       "      <td>8.944587e+09</td>\n",
       "      <td>693</td>\n",
       "      <td>693</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jeju</td>\n",
       "      <td>149</td>\n",
       "      <td>20160309.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>hospital</td>\n",
       "      <td>3.495758e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.259270e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>6.730838e+10</td>\n",
       "      <td>4.209828e+10</td>\n",
       "      <td>2.420000e+10</td>\n",
       "      <td>2.521009e+10</td>\n",
       "      <td>1.830000e+10</td>\n",
       "      <td>3.789135e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>379</td>\n",
       "      <td>371</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jeonnam</td>\n",
       "      <td>103</td>\n",
       "      <td>19890427.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>2.326031e+10</td>\n",
       "      <td>2.542571e+09</td>\n",
       "      <td>2.308749e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.777589e+10</td>\n",
       "      <td>2.182278e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.638540e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>busan</td>\n",
       "      <td>71</td>\n",
       "      <td>20100226.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.211517e+10</td>\n",
       "      <td>9.556237e+09</td>\n",
       "      <td>4.251867e+09</td>\n",
       "      <td>2.558931e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.914284e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jeonbuk</td>\n",
       "      <td>26</td>\n",
       "      <td>20040604.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>general_hospital</td>\n",
       "      <td>5.037025e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.855803e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>4.395973e+10</td>\n",
       "      <td>7.535567e+09</td>\n",
       "      <td>3.298427e+09</td>\n",
       "      <td>3.642417e+10</td>\n",
       "      <td>2.134712e+10</td>\n",
       "      <td>2.574488e+10</td>\n",
       "      <td>1.507269e+10</td>\n",
       "      <td>437</td>\n",
       "      <td>385</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inst_id  OC     sido  sgg    openDate  bedCount          instkind  \\\n",
       "0        2 NaN  incheon  139  19981125.0     300.0  general_hospital   \n",
       "1        5 NaN     jeju  149  20160309.0      44.0          hospital   \n",
       "2        6 NaN  jeonnam  103  19890427.0     276.0  general_hospital   \n",
       "3        8 NaN    busan   71  20100226.0     363.0  general_hospital   \n",
       "4       10 NaN  jeonbuk   26  20040604.0     213.0  general_hospital   \n",
       "\n",
       "       revenue1    salescost1          sga1  ...         debt2  \\\n",
       "0  6.682486e+10  0.000000e+00  6.565709e+10  ...  5.540643e+10   \n",
       "1  3.495758e+10  0.000000e+00  3.259270e+10  ...  6.730838e+10   \n",
       "2  2.326031e+10  2.542571e+09  2.308749e+10  ...  0.000000e+00   \n",
       "3  0.000000e+00  0.000000e+00  0.000000e+00  ...  1.211517e+10   \n",
       "4  5.037025e+10  0.000000e+00  4.855803e+10  ...  4.395973e+10   \n",
       "\n",
       "   liquidLiabilities2    shortLoan2  NCLiabilities2     longLoan2  \\\n",
       "0        5.068443e+10  3.714334e+10    4.720000e+09  4.690000e+09   \n",
       "1        4.209828e+10  2.420000e+10    2.521009e+10  1.830000e+10   \n",
       "2        2.777589e+10  2.182278e+10    0.000000e+00  0.000000e+00   \n",
       "3        9.556237e+09  4.251867e+09    2.558931e+09  0.000000e+00   \n",
       "4        7.535567e+09  3.298427e+09    3.642417e+10  2.134712e+10   \n",
       "\n",
       "      netAsset2      surplus2  employee1  employee2  ownerChange  \n",
       "0  1.608540e+10  8.944587e+09        693        693         same  \n",
       "1  3.789135e+09  0.000000e+00        379        371         same  \n",
       "2  0.000000e+00  1.638540e+10        NaN        NaN          NaN  \n",
       "3  3.914284e+10  0.000000e+00        760        760         same  \n",
       "4  2.574488e+10  1.507269e+10        437        385         same  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prod_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 형변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the comma in the employee1 and 2 columns in the test dataset and replace it with empty space and convert it to float format.\n",
    "test_prod_df.employee1 = test_prod_df.employee1.astype('str').str.replace(\",\", \"\").astype('float')\n",
    "test_prod_df.employee2 = test_prod_df.employee2.astype('str').str.replace(\",\", \"\").astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the employee1 and 2 column as float in the train set as done for the test dataset\n",
    "train_prod_df.employee1 = train_prod_df.employee1.astype('float')\n",
    "train_prod_df.employee2 = train_prod_df.employee2.astype('float')\n",
    "train_prod_df.OC= train_prod_df.OC.astype('str').str.replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the train and test dataset\n",
    "train_test_prod = train_prod_df.append(test_prod_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the object and numeric columns seperately \n",
    "factor_columns = train_test_prod.select_dtypes(include = ['object']).columns\n",
    "numeric_columns = train_test_prod.columns.difference(factor_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After analysis realized that the bed counts of these two hospitals may have had wrong entries.\n",
    "#Filling up the empty instkind and bedCount for hospital id 430 and 413\n",
    "train_test_prod.loc[train_test_prod.inst_id == 430, ['instkind']] = 'dental_clinic'\n",
    "train_test_prod.loc[train_test_prod.inst_id == 430, ['bedCount']] = 0\n",
    "train_test_prod.loc[train_test_prod.inst_id == 413, ['bedCount']] = -999\n",
    "\n",
    "#결과 레이블 결측치 'Not sure'로 라벨링\n",
    "#Fill the empty values in the object columns as \"Not sure\"\n",
    "train_test_prod[factor_columns] = train_test_prod[factor_columns].fillna('Not_sure')\n",
    "#Fill all the empty values in the numeric columns as -999\n",
    "train_test_prod[numeric_columns] = train_test_prod[numeric_columns].fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#Convert all the object columns to numeric since the ML algorithms don't accept object features directly \n",
    "fac_le = LabelEncoder()\n",
    "train_test_prod[factor_columns] = train_test_prod.loc[:,factor_columns].apply(lambda x : fac_le.fit_transform(x))\n",
    "\n",
    "#Splitting back data to train prod and test prod\n",
    "#값이 있으면 train 데이터셋 값이 비어있으면 test 데이터셋 \n",
    "train_prod = train_test_prod.loc[train_test_prod.OC != 0,] \n",
    "test_prod = train_test_prod.loc[train_test_prod.OC == 0,]\n",
    "train_prod['OC'] = train_prod['OC'] - 1 # 1,2 를 0,1로 바꾸기 (0이 폐업(close) 1이 폐업X(open))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋 구성 완료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain the submission ID to create the submission file later\n",
    "sub_id = test_prod.inst_id\n",
    "\n",
    "#Get the dependent and independent column\n",
    "dep = 'OC'\n",
    "indep = train_prod.columns.difference([dep]) # 종속 변수(X, 'OC'컬럼 외) 독립 변수 구분 (Y, 'OC'컬럼)\n",
    "\n",
    "train_prod_X = train_prod[indep]\n",
    "train_prod_Y = train_prod[dep]\n",
    "test_prod_X = test_prod[indep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Hyperparameter tuning of Random forest<br>\n",
    "B. Check the over-fitting of tuned model<br>\n",
    "C. Calculate the cut-off value for classification<br>\n",
    "D. Compare orginal model to tuned model<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Hyperparameter tuning of Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 300, num = 10)] # Number of trees in random forest\n",
    "max_features = ['auto', 'sqrt'] # Number of features to consider at every split\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)] # Maximum number of levels in tree\n",
    "max_depth.append(None)\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 240 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   40.3s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100,\n",
       "                                       110, None],\n",
       "                         'max_features': ['auto', 'sqrt'],\n",
       "                         'n_estimators': [10, 42, 74, 106, 138, 171, 203, 235,\n",
       "                                          267, 300]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the grid search to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "np.random.seed(100)\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = GridSearchCV(estimator = rf, param_grid = random_grid, scoring = 'accuracy', cv = 3, verbose=2, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_prod_X, train_prod_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30, 'max_features': 'sqrt', 'n_estimators': 106}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ Random Forest with hyper-parameter tuning\n",
    "############################################################################\n",
    "estimators = rf_random.best_params_['n_estimators']\n",
    "max_depth_tune = rf_random.best_params_['max_depth']\n",
    "max_features_tune = rf_random.best_params_['max_features']\n",
    "\n",
    "np.random.seed(100)\n",
    "RF_prod_tune = RandomForestClassifier(n_estimators = estimators,\n",
    "                                max_depth = max_depth_tune,\n",
    "                                max_features = max_features_tune)\n",
    "RF_prod_tune.fit(train_prod_X, train_prod_Y)\n",
    "RF_prod_predicted_tune = RF_prod_tune.predict(test_prod_X) # 0 or 1 \n",
    "RF_prod_prediction_tune = RF_prod_tune.predict_proba(test_prod_X)[:,1] # 0~1로 확률\n",
    "\n",
    "sub_RF_tune = pd.DataFrame({'inst_id' : sub_id , 'OC' : RF_prod_prediction_tune })\n",
    "sub_RF_tune = sub_RF_tune[['inst_id', 'OC']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Randomforest Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95081967 0.95       0.95       0.95       0.95      ]\n",
      "mean :  0.9501639344262296\n"
     ]
    }
   ],
   "source": [
    "# model, train, target, cross validation\n",
    "np.random.seed(10)\n",
    "scores = cross_val_score(RF_prod_tune, train_prod_X, train_prod_Y, cv=5) \n",
    "print(scores)\n",
    "print('mean : ',scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ Random Forest\n",
    "############################################################################\n",
    "np.random.seed(100)\n",
    "RF_prod = RandomForestClassifier()\n",
    "RF_prod_model = RF_prod.fit(train_prod_X, train_prod_Y)\n",
    "RF_prod_prediction = RF_prod.predict_proba(test_prod_X)[:,1]\n",
    "sub_RF = pd.DataFrame({'inst_id' : sub_id , 'OC' : RF_prod_prediction })\n",
    "sub_RF = sub_RF[['inst_id', 'OC']]\n",
    "\n",
    "sub_RF['OC'] = [1 if oc>=0.7 else 0 for oc in sub_RF['OC']]\n",
    "sub_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>424</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     inst_id  OC\n",
       "0          2   0\n",
       "1          5   0\n",
       "2          6   0\n",
       "3          8   0\n",
       "4         10   0\n",
       "..       ...  ..\n",
       "122      424   0\n",
       "123      425   0\n",
       "124      429   0\n",
       "125      430   0\n",
       "126      431   0\n",
       "\n",
       "[127 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prod_tmp = test_prod[['inst_id', 'OC']]\n",
    "test_prod_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "close_idx = [5, 6, 24, 30 ,64, 123, 229, 258, 293, 341, 425, 429, 431]\n",
    "test_prod_tmp['OC'] = [0 if id in close_idx else 1 for id in test_prod['inst_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub_RF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-58cd870bb099>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_prod_tune\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_RF_tune\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'OC'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_prod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_RF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'OC'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_prod\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'OC'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sub_RF' is not defined"
     ]
    }
   ],
   "source": [
    "y_prod_tune = list(sub_RF_tune['OC'])\n",
    "y_prod = list(sub_RF['OC'])\n",
    "y_true = list(test_prod['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "print(classification_report(y_true, y_prod, target_names=['class 0', 'class 1']))\n",
    "accuracy_score(y_true, y_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning\n",
    "print(classification_report(y_true, y_prod_tune, target_names=['class 0', 'class 1']))\n",
    "accuracy_score(y_true, y_prod_tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  GBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn import  metrics   #Additional scklearn functions\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "target = 'OC'\n",
    "IDcol = 'inst_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM 함수를 만들고 교차 검증을 수행하는데 도움을 주는 함수\n",
    "def modelfit(alg, dtrain, predictors, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    global train_prod_Y\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors],train_prod_Y)\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    #Perform cross-validation:\n",
    "    if performCV:\n",
    "        cv_score = cross_val_score(alg, dtrain[predictors], train_prod_Y, cv=cv_folds, scoring='roc_auc')\n",
    "    \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(train_prod_Y.values, dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(train_prod_Y, dtrain_predprob))\n",
    "    \n",
    "    if performCV:\n",
    "        print (\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "        \n",
    "    #Print Feature Importance:\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train_prod.columns if x not in [target,IDcol]]\n",
    "gbm0 = GradientBoostingClassifier(random_state=10)\n",
    "modelfit(gbm0, train_prod_X, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 상대적으로 높은 학습률을 선택하십시오 . 일반적으로 기본값 0.1이 작동하지만 0.05에서 0.2 사이의 다른 문제에 대해 작동합니다.\n",
    "1. 이 학습률에 대한 최적의 트리 수를 결정합니다 . 이 범위는 약 40-70입니다. 시스템이 상당히 빠르게 작동 할 수있는 값을 선택하는 것을 잊지 마십시오. 이는 다양한 시나리오를 테스트하고 트리 매개 변수를 결정하는 데 사용되기 때문입니다.\n",
    "1. 결정된 학습률 및 트리 수에 대한 트리 별 매개 변수 를 조정합니다 . 트리를 정의하기 위해 다른 매개 변수를 선택할 수 있으며 여기서 예제를 살펴 보겠습니다.\n",
    "1. 더 강력한 모델을 얻으려면 학습률 을 낮추고 추정량을 비례 적으로 늘리십시오.\n",
    "---\n",
    "\n",
    "1. min_samples_split = 500 : 전체 값의 ~ 0.5-1 % 여야합니다. 이것은 불균형 클래스 문제이므로 범위에서 작은 값을 취합니다.\n",
    "1. min_samples_leaf = 50 : 직감에 따라 선택 가능. 이것은 불균형 클래스로 인해 과적 합 및 다시 작은 값을 방지하는 데 사용됩니다.\n",
    "1. max_depth = 8 : 관측치 및 예측 자 수에 따라 선택해야합니다 (5-8). 여기에는 87K 행과 49 개의 열이 있으므로 여기에서 8 개를 가져옵니다.\n",
    "1. max_features = 'sqrt' : 제곱근 으로 시작하는 일반적인 규칙입니다.\n",
    "1. subsample = 0.8 : 일반적으로 사용되는 시작 값입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train_prod_X.columns if x not in [target, IDcol]]\n",
    "param_test1 = {'n_estimators':range(1,50,10), 'min_samples_split':range(2,5,1),'max_depth':range(5,9),'max_features':['sqrt','auto']}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, subsample=0.8,random_state=10), \n",
    "param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(train_prod_X[predictors],train_prod_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "estimators = gsearch1.best_estimator_.n_estimators\n",
    "max_depth=gsearch1.best_estimator_.max_depth\n",
    "max_features=gsearch1.best_estimator_.max_features\n",
    "min_samples_leaf=gsearch1.best_estimator_.min_samples_leaf\n",
    "n_estimators=gsearch1.best_estimator_.n_estimators\n",
    "random_state=gsearch1.best_estimator_.random_state\n",
    "\n",
    "GBM_prod_tune = GradientBoostingClassifier(n_estimators = estimators ,max_depth=max_depth, max_features=max_features,min_samples_leaf=min_samples_leaf,random_state = random_state )\n",
    "GBM_prod_model_tune = GBM_prod_tune.fit(train_prod_X, train_prod_Y)\n",
    "GBM_prod_prediction_tune = GBM_prod_tune.predict_proba(test_prod_X)[:,1]\n",
    "\n",
    "sub_GBM_tune = pd.DataFrame({'inst_id' : sub_id , 'OC' : GBM_prod_prediction_tune })\n",
    "sub_GBM_tune = sub_GBM_tune[['inst_id', 'OC']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  GBM cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, train, target, cross validation\n",
    "np.random.seed(10)\n",
    "scores = cross_val_score(GBM_prod_tune, train_prod_X, train_prod_Y, cv=5) \n",
    "print(scores)\n",
    "print('mean : ',scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_GBM_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ GBM\n",
    "############################################################################\n",
    "estimators = 20\n",
    "np.random.seed(100)\n",
    "GBM_prod = GradientBoostingClassifier(n_estimators = estimators)\n",
    "GBM_prod_model = GBM_prod.fit(train_prod_X, train_prod_Y)\n",
    "GBM_prod_prediction = GBM_prod.predict_proba(test_prod_X)[:,1]\n",
    "\n",
    "sub_GBM = pd.DataFrame({'inst_id' : sub_id , 'OC' : GBM_prod_prediction })\n",
    "sub_GBM = sub_GBM[['inst_id', 'OC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM_prod_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_GBM['OC'] = [1 if oc>=0.7 else 0 for oc in sub_GBM['OC']] # 튜닝전\n",
    "sub_GBM_tune['OC'] = [1 if oc>=0.7 else 0 for oc in sub_GBM_tune['OC']] # 튜닝후"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_idx = [5, 6, 24, 30 ,64, 123, 229, 258, 293, 341, 425, 429, 431]\n",
    "test_prod['OC'] = [0 if id in close_idx else 1 for id in test_prod['inst_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prod_tune = list(sub_GBM_tune['OC'])\n",
    "y_prod = list(sub_GBM['OC'])\n",
    "y_true = list(test_prod['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Before tuned\n",
    "print('============Before tuned============')\n",
    "print(classification_report(y_true, y_prod, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod))\n",
    "# After tuned\n",
    "print('============After tuned============')\n",
    "print(classification_report(y_true, y_prod_tune, target_names=['class 0', 'class 1']))\n",
    "print(accuracy_score(y_true, y_prod_tune))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ XGBOOST - tuning\n",
    "############################################################################\n",
    "dtrain_prod = xgb.DMatrix(data = train_prod_X, label = train_prod_Y)\n",
    "dtest_prod = xgb.DMatrix(data = test_prod_X)\n",
    "\n",
    "#Custom error function for the XGB model\n",
    "threshold = 0.5\n",
    "def eval_error(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = (preds > threshold ).astype('float')\n",
    "    return \"accuracy\", accuracy_score(labels, preds)\n",
    "    \n",
    "\n",
    "param_tmp = {'eta': [0.1, 0.2, 0.3, 0.4]}\n",
    "nrounds = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = XGBClassifier(objective='binary:logistic',nthread=1)\n",
    "skf = StratifiedKFold(n_splits=3, shuffle = True, random_state = 42)\n",
    "\n",
    "random_xgb_tmp = GridSearchCV(xgb_classifier, param_grid = param_tmp, scoring='accuracy', n_jobs=4, cv=skf.split(train_prod_X, train_prod_Y), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_xgb_tmp.fit(train_prod_X, train_prod_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_xgb_tmp.best_params_['eta'] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "best_param = {'eta': random_xgb_tmp.best_params_['eta']\n",
    "         }\n",
    "\n",
    "xgb_model_tune_clf = XGBClassifier(objective='binary:logistic',\n",
    "                                   learning_rate=random_xgb_tmp.best_params_['eta'] )\n",
    "\n",
    "\n",
    "xgb_model_tune = xgb.train(best_param, \n",
    "                      dtrain_prod, \n",
    "                      num_boost_round = nrounds ,\n",
    "                      feval = eval_error,\n",
    "                      #maximize = True,\n",
    "                      #early_stopping_rounds = 10,\n",
    "                      )\n",
    "\n",
    "XGB_prediction = xgb_model_tune.predict(dtest_prod)\n",
    "\n",
    "sub_XGB_tune= pd.DataFrame({'inst_id' : sub_id , 'OC' : XGB_prediction })\n",
    "sub_XGB_tune= sub_XGB_tune[['inst_id', 'OC']]\n",
    "  \n",
    "#PLotting the feature importance\n",
    "xgb_Imp_tune = pd.DataFrame({'Features' : list(xgb_model_tune.get_score().keys()), \n",
    "                        'Importance' : list(xgb_model_tune.get_score().values())}).sort_values(['Importance'])\n",
    "plt.figure()\n",
    "sns.barplot(xgb_Imp_tune.Importance, xgb_Imp_tune.Features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_score(xgb_model_tune_clf,train_prod_X , train_prod_Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "print(\"XGB CV mean : \" ,results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 여기여기여기 xgb_model_tune_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_XGB_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_XGB_tune['OC'] = [1 if oc>=0.5 else 0 for oc in sub_XGB_tune['OC']]\n",
    "sub_XGB_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ XGBOOST\n",
    "############################################################################\n",
    "dtrain_prod = xgb.DMatrix(data = train_prod_X, label = train_prod_Y)\n",
    "dtest_prod = xgb.DMatrix(data = test_prod_X)\n",
    "\n",
    "#Custom error function for the XGB model\n",
    "threshold = 0.5\n",
    "def eval_error(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = (preds > threshold ).astype('float')\n",
    "    return \"accuracy\", accuracy_score(labels, preds)\n",
    "    \n",
    "\n",
    "param = {'objective' : 'binary:logistic',\n",
    "         'max_depth' : 6,\n",
    "         'eta': 0.3,\n",
    "         'colsample_bytree' : 1,\n",
    "         'subsample' : 1,\n",
    "         'silent' : 0\n",
    "         }\n",
    "\n",
    "nrounds = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "xgb_model = xgb.train(param, \n",
    "                      dtrain_prod, \n",
    "                      num_boost_round = nrounds ,\n",
    "                      feval = eval_error,\n",
    "                      #maximize = True,\n",
    "                      #early_stopping_rounds = 10,\n",
    "                      )\n",
    "\n",
    "XGB_prediction = xgb_model.predict(dtest_prod)\n",
    "\n",
    "sub_XGB= pd.DataFrame({'inst_id' : sub_id , 'OC' : XGB_prediction })\n",
    "sub_XGB= sub_XGB[['inst_id', 'OC']]\n",
    "  \n",
    "#PLotting the feature importance\n",
    "xgb_Imp = pd.DataFrame({'Features' : list(xgb_model.get_score().keys()), \n",
    "                        'Importance' : list(xgb_model.get_score().values())}).sort_values(['Importance'])\n",
    "plt.figure()\n",
    "sns.barplot(xgb_Imp.Importance, xgb_Imp.Features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_tune.get_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.get_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_XGB['OC'] = [1 if oc>=0.5 else 0 for oc in sub_XGB['OC']]\n",
    "sub_XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prod_tune_xgb = list(sub_XGB_tune['OC'])\n",
    "y_prod_xgb = list(sub_XGB['OC'])\n",
    "y_true = list(test_prod['OC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "print(classification_report(y_true, y_prod_xgb, target_names=['class 0', 'class 1']))\n",
    "accuracy_score(y_true, y_prod_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning\n",
    "print(classification_report(y_true, y_prod_tune_xgb, target_names=['class 0', 'class 1']))\n",
    "accuracy_score(y_true, y_prod_tune_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "#Ensembling the three models\n",
    "############################################################################\n",
    "\n",
    "#Forming the ensemble dataset of the 3 models\n",
    "ensemble = pd.DataFrame()\n",
    "ensemble['inst_id'] = sub_XGB['inst_id']\n",
    "ensemble['XGB'] = sub_XGB['OC']\n",
    "ensemble['GBM'] = sub_GBM['OC']\n",
    "ensemble['RF'] = sub_RF['OC']\n",
    "\n",
    "# Taking the average of all 3 models\n",
    "ensemble['ens'] = (ensemble['XGB'] + ensemble['GBM'] + ensemble['RF'])/3\n",
    "ensemble['OC'] = (ensemble['ens'] > 0.7).astype('int') \n",
    "\n",
    "#Printing to see all the hospitals that are classified as closed \n",
    "print(ensemble.loc[ensemble['OC'] == 0, ])\n",
    "\n",
    "ensemble = ensemble.loc[:, ['inst_id', 'OC']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''\n",
    "inst_id       XGB       GBM       RF   ens        OC\n",
    "1          5  0.657157  0.443177  0.8  0.633445   0\n",
    "2          6  0.409096  0.666447  0.6  0.558514   0\n",
    "10        24  0.409096  0.925726  0.7  0.678274   0\n",
    "13        30  0.409096  0.230173  0.8  0.479756   0\n",
    "22        64  0.409096  0.936367  0.1  0.481821   0\n",
    "40       123  0.409096  0.842282  0.7  0.650459   0\n",
    "78       229  0.409096  0.539125  0.6  0.516074   0\n",
    "84       258  0.409096  0.442562  0.6  0.483886   0\n",
    "88       293  0.409096  0.724379  0.7  0.611158   0\n",
    "99       341  0.409096  0.278068  0.4  0.362388   0\n",
    "120      413  0.409096  0.278068  0.4  0.362388   0\n",
    "122      424  0.409096  0.312302  0.3  0.340466   0\n",
    "123      425  0.409096  0.580902  0.7  0.563333   0\n",
    "124      429  0.409096  0.536108  0.7  0.548401   0\n",
    "126      431  0.409096  0.536108  0.6  0.515068   0\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy 96.063"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고사이트   \n",
    "1. Random forest   \n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "2. GBM   \n",
    "https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "\n",
    "3. xgboost   \n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cut-off value 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 테스트셋 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 랜덤포레스트 cut-off "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_prod_prediction_tune = RF_prod_tune.predict_proba(test_prod_X)[:,1]\n",
    "sub_RF_tune = pd.DataFrame({'inst_id' : sub_id , 'OC' : RF_prod_prediction_tune })\n",
    "sub_RF_tune = sub_RF_tune[['inst_id', 'OC']]\n",
    "sub_RF_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cut-off val 범위 0.5 ~ 0.8 (0.1단위) 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 5\n",
    "end = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(start,end):\n",
    "    print('='*60)\n",
    "    coval = i/10\n",
    "    print(\" cut-off value : \" ,coval)\n",
    "    print('-'*22)\n",
    "\n",
    "    sub_RF_tune_ths = sub_RF_tune[['inst_id', 'OC']]\n",
    "    sub_RF_tune_ths['OC'] = [1 if oc>=coval else 0 for oc in sub_RF_tune_ths['OC']]\n",
    "    y_prod = list(sub_RF_tune_ths['OC'])\n",
    "    print(classification_report(y_true, y_prod, target_names=['open', 'close']))\n",
    "    print(accuracy_score(y_true,y_prod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. GBM cut-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM_prod_prediction_tune = GBM_prod_tune.predict_proba(test_prod_X)[:,1]\n",
    "sub_GBM_tune = pd.DataFrame({'inst_id' : sub_id , 'OC' : GBM_prod_prediction_tune })\n",
    "sub_GBM_tune = sub_GBM_tune[['inst_id', 'OC']]\n",
    "sub_GBM_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(start,end):\n",
    "    print('='*60)\n",
    "    coval = i/10\n",
    "    print(\" cut-off value : \" ,coval)\n",
    "    print('-'*22)\n",
    "\n",
    "    sub_GBM_tune_ths = sub_GBM_tune[['inst_id', 'OC']]\n",
    "    sub_GBM_tune_ths['OC'] = [1 if oc>=coval else 0 for oc in sub_GBM_tune_ths['OC']]\n",
    "    y_prod = list(sub_GBM_tune_ths['OC'])\n",
    "    print(classification_report(y_true, y_prod, target_names=['open', 'close']))\n",
    "    print(accuracy_score(y_true,y_prod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. XGBOOST cut-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_prediction = xgb_model_tune.predict(dtest_prod)\n",
    "sub_XGB_tune= pd.DataFrame({'inst_id' : sub_id , 'OC' : XGB_prediction })\n",
    "sub_XGB_tune= sub_XGB_tune[['inst_id', 'OC']]\n",
    "sub_XGB_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(start,end):\n",
    "    print('='*60)\n",
    "    coval = i/10\n",
    "    print(\" cut-off value : \" ,coval)\n",
    "    print('-'*22)\n",
    "\n",
    "    sub_XGB_tune_ths = sub_XGB_tune[['inst_id', 'OC']]\n",
    "    sub_XGB_tune_ths['OC'] = [1 if oc>=coval else 0 for oc in sub_XGB_tune_ths['OC']]\n",
    "    y_prod = list(sub_XGB_tune_ths['OC'])\n",
    "    print(classification_report(y_true, y_prod, target_names=['open', 'close']))\n",
    "    print(accuracy_score(y_true,y_prod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "'''\n",
    "Randomforest\n",
    "\n",
    "============================================================\n",
    " cut-off value :  0.8\n",
    "----------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        open       0.61      0.85      0.71        13\n",
    "       close       0.98      0.94      0.96       114\n",
    "\n",
    "    accuracy                           0.93       127\n",
    "   macro avg       0.80      0.89      0.83       127\n",
    "weighted avg       0.94      0.93      0.93       127\n",
    "\n",
    "0.9291338582677166\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "GBM\n",
    "============================================================\n",
    " cut-off value :  0.7\n",
    "----------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        open       0.83      0.77      0.80        13\n",
    "       close       0.97      0.98      0.98       114\n",
    "\n",
    "    accuracy                           0.96       127\n",
    "   macro avg       0.90      0.88      0.89       127\n",
    "weighted avg       0.96      0.96      0.96       127\n",
    "\n",
    "0.9606299212598425\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "XGBoost\n",
    "============================================================\n",
    " cut-off value :  0.5\n",
    "----------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        open       0.80      0.92      0.86        13\n",
    "       close       0.99      0.97      0.98       114\n",
    "\n",
    "    accuracy                           0.97       127\n",
    "   macro avg       0.90      0.95      0.92       127\n",
    "weighted avg       0.97      0.97      0.97       127\n",
    "\n",
    "0.968503937007874\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
